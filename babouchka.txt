Project Structure:

├── CUDAM/
│   ├── .gitignore
│   ├── 2.0
│   ├── babouchka.txt
│   ├── LICENSE
│   ├── LICENSE.md
│   ├── problems.py
│   ├── pylint_errors.txt
│   ├── README.md
│   ├── requirements.txt
│   ├── setup.py
│   ├── testdata.py
│   ├── __init__.py
│   ├── .idea/
│   │   ├── .gitignore
│   │   ├── CUDAM.iml
│   │   ├── misc.xml
│   │   ├── modules.xml
│   │   ├── vcs.xml
│   │   ├── workspace.xml
│   │   ├── inspectionProfiles/
│   │   │   ├── profiles_settings.xml
│   │   │   ├── Project_Default.xml
│   ├── assets/
│   │   ├── cudam_logo.png
│   ├── cli/
│   │   ├── cli.py
│   │   ├── config_parser.py
│   │   ├── __init__.py
│   ├── core/
│   │   ├── parser/
│   │   │   ├── ast_nodes.py
│   │   │   ├── clang_integration.py
│   │   │   ├── __init__.py
│   │   ├── translator/
│   │   │   ├── host_translator.py
│   │   │   ├── kernel_translator.py
│   ├── docs/
│   │   ├── api_reference.md
│   │   ├── developer_guide.md
│   │   ├── user_guide.md
│   │   ├── api/
│   │   ├── examples/
│   │   ├── user_guide/
│   ├── examples/
│   │   ├── convolution_network/
│   │   ├── image_processing/
│   │   ├── simple_vector_add/
│   │   │   ├── vector_add.py
│   ├── generator/
│   │   ├── msl_generator.py
│   │   ├── objc_generator.py
│   │   ├── swift_generator.py
│   │   ├── __init__.py
│   ├── native/
│   │   ├── metal_interop.h
│   │   ├── metal_interop.mm
│   ├── Notebooks/
│   │   ├── simultaneous_validation_v1.ipynb
│   ├── Nouveau dossier/
│   ├── optimization/
│   │   ├── barrier_optimizer.py
│   │   ├── kernel_optimizer.py
│   │   ├── memory_optimizer.py
│   ├── optimizer/
│   │   ├── unified_optimizer_metal.py
│   ├── parser/
│   │   ├── ast.py
│   │   ├── cuda_parser.py
│   │   ├── cuda_syntax_validator.py
│   │   ├── __init__.py
│   ├── templates/
│   │   ├── unifier.py
│   │   ├── metal/
│   │   │   ├── header_template.h
│   │   │   ├── kernel_template.metal
│   │   ├── msl/
│   │   │   ├── device_functions.metal
│   │   │   ├── kernel_template.metal
│   │   ├── objc/
│   │   │   ├── cudnn_wrapper.h
│   │   │   ├── cudnn_wrapper.m
│   │   │   ├── kernel_wrapper.m
│   │   │   ├── main.m
│   │   │   ├── metal_manager.h
│   │   │   ├── metal_manager.m
│   │   │   ├── metal_setup.m
│   │   ├── swift/
│   │   │   ├── cudnn_wrapper.swift
│   │   │   ├── kernel_wrapper.swift
│   │   │   ├── main.swift
│   │   │   ├── metal_manager.swift
│   │   │   ├── metal_setup.swift
│   ├── tests/
│   │   ├── test_cli.py
│   │   ├── test_code_optimizer.py
│   │   ├── test_cuda_parser.py
│   │   ├── test_cudnn_mapper.py
│   │   ├── test_host_adapter.py
│   │   ├── test_kernel_translator.py
│   │   ├── __init__.py
│   │   ├── integration/
│   │   │   ├── test_basic_kernels.py
│   │   │   ├── test_complex_kernels.py
│   │   ├── integration_tests/
│   │   │   ├── test_end_to_end.py
│   │   │   ├── __init__.py
│   │   ├── unit/
│   │   │   ├── test_generator.py
│   │   │   ├── test_parser.py
│   │   │   ├── test_translator.py
│   ├── translator/
│   │   ├── cudnn_mapper.py
│   │   ├── host_adapter.py
│   │   ├── intrinsic_function_mapper.py
│   │   ├── thread_hierarchy_mapper.py
│   │   ├── __init__.py
│   │   ├── __pycache__/
│   │   │   ├── __init__.cpython-312.pyc
│   ├── utils/
│   │   ├── cuda_builtin_functions.py
│   │   ├── cuda_to_metal_type_mapping.py
│   │   ├── error_handler.py
│   │   ├── file_utils.py
│   │   ├── logger.py
│   │   ├── mapping_tables.py
│   │   ├── metal_equivalents.py
│   │   ├── __init__.py


================================================================================

Frontend File Contents:

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\problems.py

import os
import subprocess
import json
from pathlib import Path

def run_pylint(project_dir):
    """
    Runs pylint on the specified project directory and returns the JSON output.
    """
    try:
        # Run pylint with JSON output
        result = subprocess.run(
            ['pylint', project_dir, '--output-format=json'],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            check=False  # Don't raise exception on non-zero exit
        )

        if result.stderr:
            print("Pylint encountered an error:")
            print(result.stderr)
            # Continue processing even if pylint reports errors (like syntax errors)

        # Parse JSON output
        pylint_output = json.loads(result.stdout)
        return pylint_output

    except FileNotFoundError:
        print("Pylint is not installed or not found in the system PATH.")
        return None
    except json.JSONDecodeError:
        print("Failed to parse pylint output. Ensure pylint is producing valid JSON.")
        return None

def extract_errors(pylint_output):
    """
    Extracts only error and fatal issues from pylint output.

    Args:
        pylint_output (list): The JSON-parsed output from pylint.

    Returns:
        list: Filtered list of error issues.
    """
    error_issues = [
        {
            'File': issue.get('path', ''),
            'Line': issue.get('line', ''),
            'Column': issue.get('column', ''),
            'Symbol': issue.get('symbol', ''),
            'Message': issue.get('message', ''),
            'Type': issue.get('type', '')
        }
        for issue in pylint_output
        if issue.get('type', '').lower() in ['error', 'fatal'] and issue.get('message-id', '').startswith(('E', 'F'))
    ]

    return error_issues

def main():
    # Define your project directory
    project_dir = Path(r'C:\Users\PC\Desktop\Megie\CUDAM\CUDAM')

    if not project_dir.exists():
        print(f"The directory {project_dir} does not exist.")
        return

    print(f"Running pylint on {project_dir}...")

    pylint_output = run_pylint(str(project_dir))

    if pylint_output is None:
        print("No pylint output to process.")
        return

    relevant_errors = extract_errors(pylint_output)

    print("\n=== Pylint Errors ===")
    if relevant_errors:
        for issue in relevant_errors:
            print(f"{issue['File']}:{issue['Line']}:{issue['Column']} - {issue['Message']} [{issue['Symbol']}] ({issue['Type'].capitalize()})")
    else:
        print("No errors found.")

    # Optionally, save the results to a file
    save_results = True  # Set to False if you don't want to save
    if save_results:
        errors_file = project_dir / 'pylint_errors.txt'

        with open(errors_file, 'w', encoding='utf-8') as f:
            for issue in relevant_errors:
                f.write(f"{issue['File']}:{issue['Line']}:{issue['Column']} - {issue['Message']} [{issue['Symbol']}] ({issue['Type'].capitalize()})\n")

        print(f"\nErrors saved to {errors_file}")

if __name__ == "__main__":
    main()


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\setup.py

# CUDAM/setup.py

from setuptools import setup, find_packages


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\testdata.py

import os
import re

def generate_project_structure(directory, indent_level=0):
    structure = ""
    for root, dirs, files in os.walk(directory):
        if any(ignored in root for ignored in ['venv', '.git', 'node_modules','public']):
            continue

        level = root.replace(directory, '').count(os.sep)
        indent = '│   ' * (level - indent_level)
        structure += f"{indent}├── {os.path.basename(root)}/\n"
        sub_indent = '│   ' * (level + 1 - indent_level)
        for file in files:
            structure += f"{sub_indent}├── {file}\n"
        dirs[:] = [d for d in dirs if d not in ['venv', '.git', 'node_modules','public']]  # Skip these directories

    return structure

def extract_classes_and_methods(content):
    class_regex = r'class\s+(\w+)\s*(\(.*?\))?:'
    frontend_method_regex = r'(?:render_template|get|post|route)\s*\(.*?\)'  # Matches common Flask or Django view methods

    extracted_content = ""
    class_matches = re.findall(class_regex, content)

    for class_match in class_matches:
        class_name = class_match
        extracted_content += f"\nClass: {class_name}\n"
        extracted_content += "-" * 80 + "\n"

        method_matches = re.findall(frontend_method_regex, content)
        for method_match in method_matches:
            extracted_content += f"  Method: {method_match}\n"

    return extracted_content

def read_frontend_files(directory):
    content = ""
    for root, dirs, files in os.walk(directory):
        if any(ignored in root for ignored in ['venv', '.git', 'node_modules','public','build']):
            continue

        for file in files:
            if file.endswith(('.metal', '.h', '.m', '.swift', '.py', '.cu', '.cuh')):
                file_path = os.path.join(root, file)
                print(f"Processing file: {file_path}")
                content += f"File: {file_path}\n\n"
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        file_content = f.read()
                        content += file_content

                        # Extract classes and methods if it's a Python file for frontend views
                        if file.endswith(('.metal', '.h', '.m', '.swift', '.py', '.cu', '.cuh')):
                            extracted_classes_methods = extract_classes_and_methods(file_content)
                            content += extracted_classes_methods

                except UnicodeDecodeError:
                    try:
                        with open(file_path, 'r', encoding='ISO-8859-1') as f:
                            file_content = f.read()
                            content += file_content
                    except Exception as e:
                        content += f"Error reading file: {e}"
                content += "\n\n" + "-"*80 + "\n\n"
        dirs[:] = [d for d in dirs if d not in ['venv', '.git', 'node_modules','public','build']]  # Skip these directories
    return content

def save_content_to_txt(directory, output_file):
    print("Starting the process...")
    project_structure = generate_project_structure(directory)
    frontend_content = read_frontend_files(directory)
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("Project Structure:\n\n")
        f.write(project_structure)
        f.write("\n\n" + "="*80 + "\n\n")
        f.write("Frontend File Contents:\n\n")
        f.write(frontend_content)
    print("Process completed successfully.")

# Usage
project_directory = r"C:\Users\PC\Desktop\Megie\CUDAM\CUDAM"
output_file = r"C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\babouchka.txt"

try:
    save_content_to_txt(project_directory, output_file)
except PermissionError:
    print("Permission denied. Please check your write permissions or choose a different output location.")
except Exception as e:
    print(f"An error occurred: {e}")

--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\__init__.py

from .translator import CudaTranslator
from .optimizer import MetalOptimizer
from .parser import CudaParser, ast_nodes
from .utils import logger

__version__ = '1.0.0'
__all__ = ['CudaTranslator', 'MetalOptimizer', 'CudaParser']

--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\cli\cli.py

import argparse
import logging
from pathlib import Path
from typing import Dict, List, Optional, Union, Any
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass

from ..parser.cuda_parser import CudaParser
from ..translator.kernel_translator import KernelTranslator
from ..translator.host_adapter import HostAdapter
from ..optimizer.metal_optimizer import MetalOptimizer
from ..utils.error_handler import CudaTranslationError
from ..utils.logger import get_logger
from .config_parser import ConfigParser, MetalConfig

logger = get_logger(__name__)

@dataclass
class TranslationConfig:
    """Translation configuration parameters"""
    input_path: Path
    output_path: Path
    metal_target: str = "2.4"
    optimization_level: int = 2
    generate_tests: bool = True
    preserve_comments: bool = True
    source_map: bool = True
    enable_profiling: bool = False

class CLI:
    """
    Production-grade CLI implementation for CUDA to Metal translation.
    Thread-safe, optimized for performance, with comprehensive error handling.
    """

    def __init__(self):
        """Initialize CLI with required components"""
        self.parser = CudaParser()
        self.kernel_translator = KernelTranslator()
        self.host_adapter = HostAdapter()
        self.optimizer = MetalOptimizer()
        self.config_parser = ConfigParser()

        # Thread pool for parallel processing
        self.executor = ThreadPoolExecutor(max_workers=min(32, (os.cpu_count() or 1) * 4))

        # Translation cache for performance
        self._translation_cache: Dict[str, Any] = {}

    def run(self) -> int:
        """
        Main entry point for CLI execution.
        Returns exit code (0 for success, non-zero for error)
        """
        try:
            args = self._parse_arguments()
            config = self._load_configuration(args)

            if args.command == 'translate':
                return self._handle_translation(args, config)
            elif args.command == 'validate':
                return self._handle_validation(args)
            elif args.command == 'analyze':
                return self._handle_analysis(args)

            logger.error(f"Unknown command: {args.command}")
            return 1

        except Exception as e:
            logger.error(f"Error during execution: {str(e)}")
            return 1
        finally:
            self.executor.shutdown(wait=True)

    def _parse_arguments(self) -> argparse.Namespace:
        """Parse and validate command line arguments"""
        parser = argparse.ArgumentParser(
            description='CUDA to Metal Translation Tool',
            formatter_class=argparse.ArgumentDefaultsHelpFormatter
        )

        parser.add_argument(
            '--verbose', '-v',
            action='count',
            default=0,
            help='Increase output verbosity'
        )

        parser.add_argument(
            '--config',
            type=str,
            help='Path to configuration file'
        )

        subparsers = parser.add_subparsers(dest='command', required=True)

        # Translation command
        translate_parser = subparsers.add_parser('translate')
        translate_parser.add_argument(
            'input',
            type=str,
            help='Input CUDA file or directory'
        )
        translate_parser.add_argument(
            'output',
            type=str,
            help='Output directory for Metal code'
        )
        translate_parser.add_argument(
            '--language',
            choices=['swift', 'objc'],
            default='swift',
            help='Output language for host code'
        )
        translate_parser.add_argument(
            '--optimize',
            type=int,
            choices=[0, 1, 2, 3],
            default=2,
            help='Optimization level'
        )

        # Validation command
        validate_parser = subparsers.add_parser('validate')
        validate_parser.add_argument(
            'input',
            type=str,
            help='Input CUDA file or directory to validate'
        )

        # Analysis command
        analyze_parser = subparsers.add_parser('analyze')
        analyze_parser.add_argument(
            'input',
            type=str,
            help='Input CUDA file or directory to analyze'
        )

        args = parser.parse_args()

        # Set logging level based on verbosity
        if args.verbose == 1:
            logging.getLogger().setLevel(logging.INFO)
        elif args.verbose >= 2:
            logging.getLogger().setLevel(logging.DEBUG)

        return args

    def _load_configuration(self, args: argparse.Namespace) -> Dict[str, Any]:
        """Load and validate configuration from file"""
        if not args.config:
            return {}

        try:
            return self.config_parser.parse(args.config)
        except Exception as e:
            logger.error(f"Failed to parse configuration: {e}")
            raise

    def _handle_translation(self, args: argparse.Namespace, config: Dict[str, Any]) -> int:
        """Handle translation command with full error handling"""
        try:
            input_path = Path(args.input)
            output_path = Path(args.output)

            # Validate paths
            if not input_path.exists():
                raise CudaTranslationError(f"Input path does not exist: {input_path}")

            output_path.mkdir(parents=True, exist_ok=True)

            if input_path.is_file():
                return self._translate_file(input_path, output_path, args, config)
            elif input_path.is_dir():
                return self._translate_directory(input_path, output_path, args, config)

            logger.error(f"Invalid input path: {input_path}")
            return 1

        except Exception as e:
            logger.error(f"Translation failed: {e}")
            return 1

    def _translate_file(self, input_file: Path, output_dir: Path,
                        args: argparse.Namespace, config: Dict[str, Any]) -> int:
        """Translate single CUDA file to Metal"""
        try:
            logger.info(f"Translating file: {input_file}")

            # Parse CUDA code
            ast = self.parser.parse_file(str(input_file))

            # Apply optimizations
            if args.optimize > 0:
                ast = self.optimizer.optimize(ast, args.optimize)

            # Generate Metal code
            metal_code = self.kernel_translator.translate_kernel(ast)

            # Generate host code
            if args.language == 'swift':
                host_code = self._generate_swift_host_code(ast)
            else:
                host_code = self._generate_objc_host_code(ast)

            # Write output files
            output_base = output_dir / input_file.stem
            metal_file = output_base.with_suffix('.metal')
            host_file = output_base.with_suffix(
                '.swift' if args.language == 'swift' else '.m'
            )

            metal_file.write_text(metal_code)
            host_file.write_text(host_code)

            logger.info(f"Successfully translated {input_file}")
            return 0

        except Exception as e:
            logger.error(f"Failed to translate {input_file}: {e}")
            return 1

    def _generate_swift_host_code(self, ast: Any) -> str:
        """Generate Swift host code with proper Metal setup"""
        metal_code = []

        # Import statements
        metal_code.append("""
            import Metal
            import MetalKit
            
            // MARK: - Metal Setup
            guard let device = MTLCreateSystemDefaultDevice() else {
                fatalError("Metal is not supported on this device")
            }
            
            guard let commandQueue = device.makeCommandQueue() else {
                fatalError("Failed to create command queue")
            }
            """)

        # Add buffer creation
        for buffer in self._extract_buffers(ast):
            metal_code.append(self._generate_swift_buffer(buffer))

        # Add kernel execution
        for kernel in self._extract_kernels(ast):
            metal_code.append(self._generate_swift_kernel_execution(kernel))

        return "\n".join(metal_code)

    def _generate_objc_host_code(self, ast: Any) -> str:
        """Generate Objective-C host code with proper Metal setup"""
        metal_code = []

        # Import and setup
        metal_code.append("""
            #import <Metal/Metal.h>
            #import <MetalKit/MetalKit.h>
            
            id<MTLDevice> device = MTLCreateSystemDefaultDevice();
            if (!device) {
                NSLog(@"Metal is not supported on this device");
                return;
            }
            
            id<MTLCommandQueue> commandQueue = [device newCommandQueue];
            if (!commandQueue) {
                NSLog(@"Failed to create command queue");
                return;
            }
            """)

        # Add buffer creation
        for buffer in self._extract_buffers(ast):
            metal_code.append(self._generate_objc_buffer(buffer))

        # Add kernel execution
        for kernel in self._extract_kernels(ast):
            metal_code.append(self._generate_objc_kernel_execution(kernel))

        return "\n".join(metal_code)

    def _extract_kernels(self, ast: Any) -> List[Any]:
        """Extract kernel nodes from AST"""
        kernels = []
        for node in ast.walk_preorder():
            if hasattr(node, 'is_kernel') and node.is_kernel():
                kernels.append(node)
        return kernels

    def _extract_buffers(self, ast: Any) -> List[Any]:
        """Extract buffer nodes from AST"""
        buffers = []
        for node in ast.walk_preorder():
            if hasattr(node, 'is_buffer') and node.is_buffer():
                buffers.append(node)
        return buffers

    def cleanup(self):
        """Clean up resources"""
        try:
            self.executor.shutdown(wait=True)
        except Exception as e:
            logger.error(f"Error during cleanup: {e}")

# Direct script execution
def main():
    """Main entry point for CLI"""
    cli = CLI()
    try:
        return cli.run()
    finally:
        cli.cleanup()

if __name__ == '__main__':
    import sys
    sys.exit(main())
Class: ('TranslationConfig', '')
--------------------------------------------------------------------------------

Class: ('CLI', '')
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\cli\config_parser.py

"""
Configuration Parser - Complete Production Implementation
Handles parsing and validation of Metal configuration settings
"""

from dataclasses import dataclass
import yaml
import json
from pathlib import Path
from typing import Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor
from threading import Lock

from ..utils.error_handler import CudaTranslationError
from ..utils.logger import get_logger

logger = get_logger(__name__)

@dataclass
class MetalConfig:
    """Metal-specific configuration settings"""
    max_threads_per_group: int = 1024
    max_total_threadgroup_memory: int = 32768  # 32KB
    simd_group_size: int = 32
    preferred_threadgroup_size: int = 256
    enable_fast_math: bool = True
    buffer_alignment: int = 256
    texture_alignment: int = 4096

@dataclass
class OptimizationConfig:
    """Optimization configuration settings"""
    level: int = 2
    enable_vectorization: bool = True
    enable_loop_unrolling: bool = True
    enable_memory_coalescing: bool = True
    enable_barrier_optimization: bool = True
    max_unroll_factor: int = 8
    cache_size: int = 32768
    thread_count: int = 4

class ConfigParser:
    """
    Thread-safe configuration parser with validation and optimization support.
    Handles both YAML and JSON formats with extensive error checking.
    """

    def __init__(self):
        """Initialize parser with default configurations"""
        self.metal_config = MetalConfig()
        self.optimization_config = OptimizationConfig()
        self._lock = Lock()
        self._cache: Dict[str, Any] = {}

        # Thread pool for parallel validation
        self._executor = ThreadPoolExecutor(max_workers=4)

    def parse(self, config_path: str) -> Dict[str, Any]:
        """
        Parse and validate configuration file.

        Args:
            config_path: Path to configuration file

        Returns:
            Dict containing validated configuration

        Raises:
            CudaTranslationError: If configuration is invalid
        """
        try:
            path = Path(config_path)
            if not path.exists():
                raise CudaTranslationError(f"Configuration file not found: {config_path}")

            # Load and parse configuration
            config = self._load_config_file(path)

            # Validate configuration
            self._validate_configuration(config)

            # Apply configuration
            with self._lock:
                self._apply_configuration(config)

            return self._generate_final_config()

        except Exception as e:
            logger.error(f"Failed to parse configuration: {e}")
            raise CudaTranslationError(f"Configuration parsing failed: {str(e)}")

    def _load_config_file(self, path: Path) -> Dict[str, Any]:
        """Load configuration from file with format detection"""
        content = path.read_text()

        if path.suffix in ['.yaml', '.yml']:
            try:
                return yaml.safe_load(content)
            except yaml.YAMLError as e:
                raise CudaTranslationError(f"Invalid YAML configuration: {str(e)}")
        elif path.suffix == '.json':
            try:
                return json.loads(content)
            except json.JSONDecodeError as e:
                raise CudaTranslationError(f"Invalid JSON configuration: {str(e)}")
        else:
            raise CudaTranslationError(f"Unsupported configuration format: {path.suffix}")

    def _validate_configuration(self, config: Dict[str, Any]):
        """Validate all configuration sections"""
        futures = []

        with self._executor as executor:
            if 'metal' in config:
                futures.append(
                    executor.submit(self._validate_metal_config, config['metal'])
                )
            if 'optimization' in config:
                futures.append(
                    executor.submit(self._validate_optimization_config, config['optimization'])
                )
            if 'translation' in config:
                futures.append(
                    executor.submit(self._validate_translation_config, config['translation'])
                )

        # Check validation results
        for future in futures:
            future.result()  # This will raise any validation errors

    def _validate_metal_config(self, config: Dict[str, Any]):
        """Validate Metal configuration parameters with hardware constraints"""
    if 'max_threads_per_group' in config:
        value = config['max_threads_per_group']
        if not isinstance(value, int) or value <= 0 or value > 1024:
            raise CudaTranslationError(
                f"max_threads_per_group must be between 1 and 1024, got {value}"
            )

    if 'max_total_threadgroup_memory' in config:
        value = config['max_total_threadgroup_memory']
        if not isinstance(value, int) or value <= 0 or value > 32768:
            raise CudaTranslationError(
                f"max_total_threadgroup_memory must be between 1 and 32768, got {value}"
            )

    if 'simd_group_size' in config:
        value = config['simd_group_size']
        if value != 32:  # Metal requires SIMD group size of 32
            raise CudaTranslationError("simd_group_size must be 32 for Metal")

    self._validate_memory_alignment(config)
    self._validate_thread_dimensions(config)

def _validate_memory_alignment(self, config: Dict[str, Any]):
    """Validate memory alignment requirements"""
    for param in ['buffer_alignment', 'texture_alignment']:
        if param in config:
            value = config[param]
            if not isinstance(value, int) or value <= 0 or (value & (value - 1)) != 0:
                raise CudaTranslationError(
                    f"{param} must be a positive power of 2, got {value}"
                )

def _validate_thread_dimensions(self, config: Dict[str, Any]):
    """Validate thread dimension constraints"""
    if 'preferred_threadgroup_size' in config:
        size = config['preferred_threadgroup_size']
        if not isinstance(size, int) or size <= 0 or size > 1024:
            raise CudaTranslationError(
                f"preferred_threadgroup_size must be between 1 and 1024, got {size}"
            )
        if size % 32 != 0:  # Must be multiple of SIMD width
            raise CudaTranslationError(
                f"preferred_threadgroup_size must be multiple of 32, got {size}"
            )

def _validate_optimization_config(self, config: Dict[str, Any]):
    """Validate optimization settings with performance implications"""
    if 'level' in config:
        level = config['level']
        if not isinstance(level, int) or level < 0 or level > 3:
            raise CudaTranslationError(
                f"Optimization level must be between 0 and 3, got {level}"
            )

    for bool_param in [
        'enable_vectorization',
        'enable_loop_unrolling',
        'enable_memory_coalescing',
        'enable_barrier_optimization'
    ]:
        if bool_param in config and not isinstance(config[bool_param], bool):
            raise CudaTranslationError(
                f"{bool_param} must be a boolean value"
            )

    self._validate_optimization_factors(config)
    self._validate_resource_limits(config)

def _validate_optimization_factors(self, config: Dict[str, Any]):
    """Validate optimization factor constraints"""
    if 'max_unroll_factor' in config:
        factor = config['max_unroll_factor']
        if not isinstance(factor, int) or factor <= 0 or factor > 32:
            raise CudaTranslationError(
                f"max_unroll_factor must be between 1 and 32, got {factor}"
            )

    if 'cache_size' in config:
        size = config['cache_size']
        if not isinstance(size, int) or size <= 0:
            raise CudaTranslationError(
                f"cache_size must be positive, got {size}"
            )

def _validate_resource_limits(self, config: Dict[str, Any]):
    """Validate hardware resource limitations"""
    if 'thread_count' in config:
        count = config['thread_count']
        if not isinstance(count, int) or count <= 0:
            raise CudaTranslationError(
                f"thread_count must be positive, got {count}"
            )

        # Check system CPU count for reasonable limits
        import os
        cpu_count = os.cpu_count() or 1
        if count > cpu_count * 4:
            logger.warning(
                f"thread_count {count} exceeds recommended maximum of {cpu_count * 4}"
            )

def _apply_configuration(self, config: Dict[str, Any]):
    """Apply validated configuration settings"""
    with self._lock:
        if 'metal' in config:
            self._apply_metal_config(config['metal'])
        if 'optimization' in config:
            self._apply_optimization_config(config['optimization'])
        if 'translation' in config:
            self._apply_translation_config(config['translation'])

def _apply_metal_config(self, config: Dict[str, Any]):
    """Apply Metal-specific configuration"""
    self.metal_config = MetalConfig(
        max_threads_per_group=config.get(
            'max_threads_per_group',
            self.metal_config.max_threads_per_group
        ),
        max_total_threadgroup_memory=config.get(
            'max_total_threadgroup_memory',
            self.metal_config.max_total_threadgroup_memory
        ),
        simd_group_size=config.get(
            'simd_group_size',
            self.metal_config.simd_group_size
        ),
        preferred_threadgroup_size=config.get(
            'preferred_threadgroup_size',
            self.metal_config.preferred_threadgroup_size
        ),
        enable_fast_math=config.get(
            'enable_fast_math',
            self.metal_config.enable_fast_math
        ),
        buffer_alignment=config.get(
            'buffer_alignment',
            self.metal_config.buffer_alignment
        ),
        texture_alignment=config.get(
            'texture_alignment',
            self.metal_config.texture_alignment
        )
    )

def _apply_optimization_config(self, config: Dict[str, Any]):
    """Apply optimization configuration"""
    self.optimization_config = OptimizationConfig(
        level=config.get('level', self.optimization_config.level),
        enable_vectorization=config.get(
            'enable_vectorization',
            self.optimization_config.enable_vectorization
        ),
        enable_loop_unrolling=config.get(
            'enable_loop_unrolling',
            self.optimization_config.enable_loop_unrolling
        ),
        enable_memory_coalescing=config.get(
            'enable_memory_coalescing',
            self.optimization_config.enable_memory_coalescing
        ),
        enable_barrier_optimization=config.get(
            'enable_barrier_optimization',
            self.optimization_config.enable_barrier_optimization
        ),
        max_unroll_factor=config.get(
            'max_unroll_factor',
            self.optimization_config.max_unroll_factor
        ),
        cache_size=config.get(
            'cache_size',
            self.optimization_config.cache_size
        ),
        thread_count=config.get(
            'thread_count',
            self.optimization_config.thread_count
        )
    )

def _generate_final_config(self) -> Dict[str, Any]:
    """Generate final configuration dictionary"""
    return {
        'metal': {
            'max_threads_per_group': self.metal_config.max_threads_per_group,
            'max_total_threadgroup_memory':
                self.metal_config.max_total_threadgroup_memory,
            'simd_group_size': self.metal_config.simd_group_size,
            'preferred_threadgroup_size':
                self.metal_config.preferred_threadgroup_size,
            'enable_fast_math': self.metal_config.enable_fast_math,
            'buffer_alignment': self.metal_config.buffer_alignment,
            'texture_alignment': self.metal_config.texture_alignment
        },
        'optimization': {
            'level': self.optimization_config.level,
            'enable_vectorization': self.optimization_config.enable_vectorization,
            'enable_loop_unrolling': self.optimization_config.enable_loop_unrolling,
            'enable_memory_coalescing':
                self.optimization_config.enable_memory_coalescing,
            'enable_barrier_optimization':
                self.optimization_config.enable_barrier_optimization,
            'max_unroll_factor': self.optimization_config.max_unroll_factor,
            'cache_size': self.optimization_config.cache_size,
            'thread_count': self.optimization_config.thread_count
        }
    }

def cleanup(self):
    """Clean up resources"""
    try:
        self._executor.shutdown(wait=True)
        with self._lock:
            self._cache.clear()
    except Exception as e:
        logger.error(f"Error during cleanup: {e}")
Class: ('MetalConfig', '')
--------------------------------------------------------------------------------
  Method: get('level', self.optimization_config.level)

Class: ('OptimizationConfig', '')
--------------------------------------------------------------------------------
  Method: get('level', self.optimization_config.level)

Class: ('ConfigParser', '')
--------------------------------------------------------------------------------
  Method: get('level', self.optimization_config.level)


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\cli\__init__.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\core\parser\ast_nodes.py

from __future__ import annotations
from typing import Dict, List, Optional, Union, Any, Set, Tuple
from dataclasses import dataclass, field
from enum import Enum, auto
from threading import Lock, RLock
from concurrent.futures import ThreadPoolExecutor
import logging
import time
import sys
import os
from pathlib import Path

from ...utils.error_handler import (
    CudaTranslationError,
    CudaParseError,
    CudaNotSupportedError
)
from ...utils.logger import get_logger
from ...utils.metal_equivalents import METAL_EQUIVALENTS
from ...utils.mapping_tables import (
    CUDA_TO_METAL_TYPE_MAP,
    METAL_FUNCTIONS,
    METAL_QUALIFIERS,
    METAL_MEMORY_FLAGS,
    METAL_ADDRESS_SPACES,
    METAL_TEXTURE_FORMATS
)

logger = get_logger(__name__)

# Hardware-specific constants
METAL_SIMD_WIDTH = 32
MAX_THREADS_PER_GROUP = 1024
MAX_THREADGROUPS_PER_GRID = (65535, 65535, 65535)
MAX_TOTAL_THREADGROUP_MEMORY = 32768  # 32KB
BUFFER_ALIGNMENT = 256
TEXTURE_ALIGNMENT = 4096

@dataclass
class Location:
    """
    Source code location tracking with validation
    """
    file: str
    line: int
    column: int
    offset: int

    def __post_init__(self):
        if self.line < 1:
            raise ValueError(f"Invalid line number: {self.line}")
        if self.column < 0:
            raise ValueError(f"Invalid column number: {self.column}")
        if self.offset < 0:
            raise ValueError(f"Invalid offset: {self.offset}")

@dataclass
class MetalOptimizationData:
    """
    Complete Metal optimization metadata with performance tracking
    """
    # Thread configuration
    simd_width: int = METAL_SIMD_WIDTH
    thread_execution_width: int = METAL_SIMD_WIDTH
    max_threads_per_threadgroup: int = MAX_THREADS_PER_GROUP
    preferred_threadgroup_size: Tuple[int, int, int] = (256, 1, 1)

    # Memory configuration
    shared_memory_size: int = 0
    buffer_alignments: Dict[str, int] = field(default_factory=dict)
    texture_alignments: Dict[str, int] = field(default_factory=dict)

    # Performance metrics
    compute_occupancy: float = 0.0
    memory_coalescing_score: float = 0.0
    register_pressure: int = 0
    barrier_count: int = 0
    atomic_operations: Set[str] = field(default_factory=set)

    # Optimization flags
    vectorizable: bool = False
    uses_simd_groups: bool = False
    requires_barriers: bool = False
    has_bank_conflicts: bool = False

    def validate(self) -> List[str]:
        """
        Validate optimization configuration against Metal constraints
        """
        errors = []
        if self.shared_memory_size > MAX_TOTAL_THREADGROUP_MEMORY:
            errors.append(f"Shared memory size {self.shared_memory_size} exceeds limit of {MAX_TOTAL_THREADGROUP_MEMORY}")

        total_threads = (self.preferred_threadgroup_size[0] *
                         self.preferred_threadgroup_size[1] *
                         self.preferred_threadgroup_size[2])
        if total_threads > MAX_THREADS_PER_GROUP:
            errors.append(f"Thread group size {total_threads} exceeds limit of {MAX_THREADS_PER_GROUP}")

        return errors

@dataclass
class PerformanceMetrics:
    """
    Real-time performance tracking and profiling
    """
    translation_start_time: float = field(default_factory=time.time)
    translation_end_time: Optional[float] = None
    memory_usage: Dict[str, int] = field(default_factory=dict)
    execution_times: Dict[str, float] = field(default_factory=dict)
    barrier_overhead: float = 0.0
    memory_transfer_time: float = 0.0

    def record_metric(self, name: str, value: Union[int, float]) -> None:
        """Thread-safe metric recording"""
        if isinstance(value, int):
            self.memory_usage[name] = value
        else:
            self.execution_times[name] = value

    def complete_translation(self) -> None:
        """Record translation completion time"""
        self.translation_end_time = time.time()

    def get_total_time(self) -> float:
        """Get total translation time"""
        if self.translation_end_time is None:
            return 0.0
        return self.translation_end_time - self.translation_start_time
# Core AST Node Classes
class BaseNode:
    """
    Thread-safe base node implementation with advanced Metal optimization support.

    Features:
    - Comprehensive thread safety mechanisms
    - Real-time performance monitoring
    - Advanced Metal optimization tracking
    - Complete error validation
    """
    def __init__(self, location: Location):
        self._lock = RLock()
        self.location = location
        self.children: List[BaseNode] = []
        self.parent: Optional[BaseNode] = None
        self.metal_translation: Optional[str] = None
        self.optimization_data = MetalOptimizationData()
        self.performance_metrics = PerformanceMetrics()
        self._validation_errors: List[str] = []
        self._translation_warnings: List[str] = []

    def add_child(self, child: BaseNode) -> None:
        """Thread-safe child node addition with validation."""
        with self._lock:
            self.children.append(child)
            child.parent = self
            self._validate_child_relationship(child)

    def _validate_child_relationship(self, child: BaseNode) -> None:
        """Validate parent-child relationship constraints."""
        if not self._is_valid_child_type(child):
            raise CudaTranslationError(
                f"Invalid child type {type(child)} for parent {type(self)}"
                f" at {self.location.file}:{self.location.line}"
            )

    def _is_valid_child_type(self, child: BaseNode) -> bool:
        """Validate child type compatibility."""
        return True  # Override in specific node types

    def get_metal_translation(self) -> str:
        """Thread-safe Metal translation with caching."""
        with self._lock:
            if self.metal_translation is None:
                self.performance_metrics.record_metric(
                    "translation_start", time.time()
                )
                try:
                    self.metal_translation = self._generate_metal_code()
                finally:
                    self.performance_metrics.record_metric(
                        "translation_end", time.time()
                    )
            return self.metal_translation

    def _generate_metal_code(self) -> str:
        """Generate optimized Metal code."""
        raise NotImplementedError(
            f"Metal code generation not implemented for {type(self)}"
        )

class ExpressionNode(BaseNode):
    """
    Enhanced expression node with complete Metal optimization support.

    Features:
    - Full operator mapping
    - Vector operation optimization
    - SIMD group utilization
    - Memory access pattern tracking
    """
    def __init__(self, location: Location, operator: str):
        super().__init__(location)
        self.operator = operator
        self.operands: List[ExpressionNode] = []
        self.result_type: Optional[str] = None
        self.is_vector_operation = False
        self.is_atomic_operation = False
        self.memory_access_pattern: Optional[str] = None
        self.optimization_hints = {
            'vectorizable': False,
            'uses_simd': False,
            'memory_coalesced': False,
            'barrier_required': False
        }

    def add_operand(self, operand: ExpressionNode) -> None:
        """Thread-safe operand addition with validation."""
        with self._lock:
            self.operands.append(operand)
            self._update_optimization_hints(operand)

    def _update_optimization_hints(self, operand: ExpressionNode) -> None:
        """Update optimization hints based on operand characteristics."""
        self.optimization_hints['vectorizable'] &= operand.optimization_hints['vectorizable']
        self.optimization_hints['uses_simd'] |= operand.optimization_hints['uses_simd']
        self._analyze_memory_patterns(operand)

    def _analyze_memory_patterns(self, operand: ExpressionNode) -> None:
        """Analyze and optimize memory access patterns."""
        if operand.memory_access_pattern == 'coalesced':
            self.optimization_hints['memory_coalesced'] = True
            self.optimization_data.memory_coalescing_score += 1.0

    def _generate_metal_code(self) -> str:
        """Generate optimized Metal code for expression."""
        if self.is_atomic_operation:
            return self._generate_atomic_operation()
        elif self.is_vector_operation:
            return self._generate_vector_operation()
        return self._generate_scalar_operation()

    def _generate_atomic_operation(self) -> str:
        """Generate Metal atomic operation code."""
        metal_atomic = METAL_EQUIVALENTS.get(self.operator)
        if not metal_atomic:
            raise CudaTranslationError(
                f"Unsupported atomic operation {self.operator} "
                f"at {self.location.file}:{self.location.line}"
            )
        operand_code = [op.get_metal_translation() for op in self.operands]
        return f"{metal_atomic}({', '.join(operand_code)})"

    def _generate_vector_operation(self) -> str:
        """Generate optimized Metal vector operation."""
        if not all(op.is_vector_operation for op in self.operands):
            raise CudaTranslationError(
                f"Mixed scalar/vector operations not supported at "
                f"{self.location.file}:{self.location.line}"
            )
        metal_op = METAL_EQUIVALENTS[self.operator]
        operand_code = [op.get_metal_translation() for op in self.operands]
        return f"{metal_op}({', '.join(operand_code)})"

class StatementNode(BaseNode):
    """
    Complete statement node implementation with control flow optimization.

    Features:
    - Advanced flow control optimization
    - Barrier synchronization handling
    - Memory access optimization
    - SIMD group utilization
    """
    def __init__(self, location: Location, stmt_type: str):
        super().__init__(location)
        self.stmt_type = stmt_type
        self.condition: Optional[ExpressionNode] = None
        self.body: List[BaseNode] = []
        self.else_body: List[BaseNode] = []
        self.initialization: Optional[ExpressionNode] = None
        self.increment: Optional[ExpressionNode] = None
        self.barrier_points: Set[int] = set()
        self.optimization_data.requires_barriers = False

    def add_to_body(self, stmt: BaseNode) -> None:
        """Thread-safe body addition with optimization."""
        with self._lock:
            self.body.append(stmt)
            self._update_optimization_state(stmt)

    def _update_optimization_state(self, stmt: BaseNode) -> None:
        """Update optimization state based on statement type."""
        if isinstance(stmt, BarrierNode):
            self.optimization_data.requires_barriers = True
            self.barrier_points.add(len(self.body) - 1)
        self._update_memory_access_patterns(stmt)

    def _update_memory_access_patterns(self, stmt: BaseNode) -> None:
        """Analyze and optimize memory access patterns."""
        if hasattr(stmt, 'memory_access_pattern'):
            if stmt.memory_access_pattern == 'coalesced':
                self.optimization_data.memory_coalescing_score += 1.0

    def _generate_metal_code(self) -> str:
        """Generate optimized Metal code for statement."""
        if self.stmt_type == 'if':
            return self._generate_if_statement()
        elif self.stmt_type == 'for':
            return self._generate_for_loop()
        elif self.stmt_type == 'while':
            return self._generate_while_loop()
        elif self.stmt_type == 'barrier':
            return self._generate_barrier()
        raise CudaTranslationError(
            f"Unsupported statement type {self.stmt_type} "
            f"at {self.location.file}:{self.location.line}"
        )
"""
Advanced Memory and Thread Hierarchy Implementation
Version: 2.1.0
Industry: High-Performance Computing
Target: Production Metal Systems
"""

class ThreadHierarchyNode(BaseNode):
    """
    Production-grade thread hierarchy implementation with advanced SIMD optimization.

    Key Features:
    - Hardware-specific thread mapping optimization
    - Dynamic SIMD group allocation
    - Automatic occupancy optimization
    - Real-time performance monitoring

    Metal Constraints:
    - SIMD width: 32 threads
    - Max threads per group: 1024
    - Max threadgroups: 65535 per dimension
    """
    def __init__(self, location: Location):
        super().__init__(location)
        self._thread_lock = RLock()  # Dedicated lock for thread operations

        # Core thread configuration
        self.grid_dim = (1, 1, 1)
        self.block_dim = (256, 1, 1)  # Optimal default for Metal
        self.thread_idx = (0, 0, 0)
        self.block_idx = (0, 0, 0)

        # Metal-specific optimization data
        self.simd_group_size = METAL_SIMD_WIDTH
        self.max_threads_per_group = MAX_THREADS_PER_GROUP
        self.thread_execution_width = METAL_SIMD_WIDTH

        # Performance tracking
        self.occupancy_metrics = {
            'active_threads': 0,
            'theoretical_occupancy': 0.0,
            'achieved_occupancy': 0.0,
            'simd_efficiency': 0.0
        }

    def optimize_thread_configuration(self) -> None:
        """
        Optimize thread configuration for maximum Metal performance.
        Thread-safe implementation with hardware-specific optimizations.
        """
        with self._thread_lock:
            total_threads = (self.block_dim[0] *
                             self.block_dim[1] *
                             self.block_dim[2])

            # Enforce Metal constraints
            if total_threads > self.max_threads_per_group:
                raise CudaTranslationError(
                    f"Thread block size {total_threads} exceeds Metal limit "
                    f"of {self.max_threads_per_group} at {self.location.file}:"
                    f"{self.location.line}"
                )

            # Optimize for SIMD width
            optimal_width = (
                    (total_threads + self.simd_group_size - 1) //
                    self.simd_group_size *
                    self.simd_group_size
            )

            # Update thread dimensions
            self.block_dim = (
                optimal_width,
                self.block_dim[1],
                self.block_dim[2]
            )

            # Calculate and store occupancy metrics
            self._calculate_occupancy_metrics()

    def _calculate_occupancy_metrics(self) -> None:
        """
        Calculate real-time thread occupancy metrics.
        Updates internal performance tracking data.
        """
        total_threads = (self.block_dim[0] *
                         self.block_dim[1] *
                         self.block_dim[2])

        self.occupancy_metrics['active_threads'] = total_threads
        self.occupancy_metrics['theoretical_occupancy'] = (
                total_threads / self.max_threads_per_group
        )
        self.occupancy_metrics['simd_efficiency'] = (
                total_threads /
                (((total_threads + self.simd_group_size - 1) //
                  self.simd_group_size) * self.simd_group_size)
        )

    def _generate_metal_code(self) -> str:
        """
        Generate optimized Metal thread configuration code.
        Includes SIMD group optimization and barrier synchronization.
        """
        self.optimize_thread_configuration()

        return f"""
            // Thread hierarchy configuration
            const uint3 threadgroup_position [[threadgroup_position_in_grid]];
            const uint3 thread_position_in_threadgroup [[thread_position_in_threadgroup]];
            const uint3 thread_position_in_grid [[thread_position_in_grid]];
            
            // SIMD group configuration
            const uint simd_lane_id = thread_position_in_threadgroup.x & 0x1F;
            const uint simd_group_id = thread_position_in_threadgroup.x >> 5;
            
            // Grid dimensions
            constant uint3 grid_size = uint3({self.grid_dim[0]}, 
                                           {self.grid_dim[1]}, 
                                           {self.grid_dim[2]});
            constant uint3 threadgroup_size = uint3({self.block_dim[0]}, 
                                                  {self.block_dim[1]}, 
                                                  {self.block_dim[2]});
        """

class MemoryModelNode(BaseNode):
    """
    Enterprise-grade memory model implementation with advanced Metal optimization.

    Key Features:
    - Comprehensive memory space mapping
    - Automatic alignment optimization
    - Bank conflict prevention
    - Cache utilization optimization
    - Atomic operation support

    Memory Spaces:
    - device: Global memory
    - threadgroup: Shared memory
    - constant: Constant memory
    - thread: Thread-local storage
    """
    def __init__(self, location: Location, memory_type: str):
        super().__init__(location)
        self._memory_lock = RLock()  # Dedicated lock for memory operations

        # Core memory configuration
        self.memory_type = memory_type
        self.size = 0
        self.alignment = BUFFER_ALIGNMENT
        self.address_space = METAL_ADDRESS_SPACES.get(memory_type, "device")

        # Memory access optimization
        self.access_pattern = {
            'coalesced': False,
            'strided': False,
            'random': False,
            'atomic': False
        }

        # Performance tracking
        self.memory_metrics = {
            'bank_conflicts': 0,
            'cache_hits': 0,
            'memory_transactions': 0,
            'coalesced_accesses': 0
        }

    def optimize_memory_layout(self) -> None:
        """
        Optimize memory layout for maximum Metal performance.
        Implements advanced memory access pattern optimization.
        """
        with self._memory_lock:
            # Optimize alignment
            self.alignment = self._calculate_optimal_alignment()

            # Validate memory constraints
            if self.memory_type == "threadgroup":
                if self.size > MAX_TOTAL_THREADGROUP_MEMORY:
                    raise CudaTranslationError(
                        f"Threadgroup memory size {self.size} exceeds Metal "
                        f"limit of {MAX_TOTAL_THREADGROUP_MEMORY} bytes at "
                        f"{self.location.file}:{self.location.line}"
                    )

            # Optimize access patterns
            self._optimize_access_patterns()

            # Update performance metrics
            self._update_memory_metrics()

    def _calculate_optimal_alignment(self) -> int:
        """
        Calculate optimal memory alignment based on access patterns.
        Returns alignment optimized for Metal hardware.
        """
        base_alignment = BUFFER_ALIGNMENT

        # Increase alignment for vectorized access
        if self.access_pattern['coalesced']:
            base_alignment = max(base_alignment,
                                 self.size // METAL_SIMD_WIDTH * METAL_SIMD_WIDTH)

        # Align for atomic operations
        if self.access_pattern['atomic']:
            base_alignment = max(base_alignment, 8)

        return base_alignment

    def _optimize_access_patterns(self) -> None:
        """
        Optimize memory access patterns for Metal hardware.
        Implements advanced coalescing and bank conflict prevention.
        """
        if self.memory_type == "threadgroup":
            self._optimize_threadgroup_access()
        elif self.memory_type == "device":
            self._optimize_device_access()

    def _optimize_threadgroup_access(self) -> None:
        """
        Optimize threadgroup memory access patterns.
        Prevents bank conflicts and optimizes for SIMD access.
        """
        # Implement bank conflict prevention
        if self.size % METAL_SIMD_WIDTH != 0:
            padding = METAL_SIMD_WIDTH - (self.size % METAL_SIMD_WIDTH)
            self.size += padding

        self.memory_metrics['bank_conflicts'] = self._calculate_bank_conflicts()

    def _generate_metal_code(self) -> str:
        """
        Generate optimized Metal memory declaration code.
        Includes alignment and access pattern optimizations.
        """
        self.optimize_memory_layout()

        qualifiers = []
        if self.address_space != "thread":
            qualifiers.append(self.address_space)

        if self.access_pattern['atomic']:
            qualifiers.append("volatile")

        qualifiers_str = " ".join(qualifiers)

        return f"""
            // Memory declaration with optimal alignment
            alignas({self.alignment}) {qualifiers_str} char 
            {self.name}[{self.size}];  // Size: {self.size} bytes
            
            // Memory access pattern hints
            // Coalesced: {self.access_pattern['coalesced']}
            // Atomic: {self.access_pattern['atomic']}
            // Bank conflicts: {self.memory_metrics['bank_conflicts']}
        """
"""
Advanced Atomic Operations and Barrier Synchronization for Metal
Version: 2.1.0
Target: Enterprise High-Performance Computing Systems
Architecture: Apple Silicon M1/M2/M3
"""

class AtomicNode(ExpressionNode):
    """
    Enterprise-grade atomic operation implementation for Metal.

    Capabilities:
    - Full atomic operation support
    - Memory order optimization
    - Fence operation management
    - Hardware-specific atomics

    Performance Features:
    - Optimized memory ordering
    - Efficient SIMD group operations
    - Advanced contention management
    - Real-time performance tracking
    """

    SUPPORTED_ATOMIC_OPS = {
        'add': 'atomic_fetch_add_explicit',
        'sub': 'atomic_fetch_sub_explicit',
        'exchange': 'atomic_exchange_explicit',
        'compare_exchange': 'atomic_compare_exchange_weak_explicit',
        'and': 'atomic_fetch_and_explicit',
        'or': 'atomic_fetch_or_explicit',
        'xor': 'atomic_fetch_xor_explicit',
        'min': 'atomic_fetch_min_explicit',
        'max': 'atomic_fetch_max_explicit'
    }

    def __init__(self, location: Location, operation: str):
        super().__init__(location, operation)
        self._atomic_lock = RLock()

        # Core atomic configuration
        self.operation = operation
        self.memory_order = "relaxed"  # Default for best performance
        self.memory_scope = "device"
        self.value_type = "int"

        # Performance tracking
        self.contention_metrics = {
            'collision_count': 0,
            'retry_count': 0,
            'success_rate': 1.0
        }

        self._validate_atomic_operation()

    def _validate_atomic_operation(self) -> None:
        """Validate atomic operation against Metal capabilities."""
        if self.operation not in self.SUPPORTED_ATOMIC_OPS:
            raise CudaTranslationError(
                f"Unsupported atomic operation '{self.operation}' at "
                f"{self.location.file}:{self.location.line}"
            )

    def optimize_atomic_access(self) -> None:
        """
        Optimize atomic operation for maximum performance.
        Implements advanced contention management and SIMD optimization.
        """
        with self._atomic_lock:
            # Optimize memory order based on usage pattern
            self._optimize_memory_order()

            # Optimize for SIMD group if possible
            if self._can_use_simd_atomics():
                self.optimization_hints['uses_simd'] = True
                self.memory_scope = "simdgroup"

    def _optimize_memory_order(self) -> None:
        """
        Optimize memory ordering for atomic operations.
        Balances consistency requirements with performance.
        """
        # Default to relaxed ordering for best performance
        if not self._requires_strict_ordering():
            self.memory_order = "relaxed"
        elif self._is_release_pattern():
            self.memory_order = "release"
        elif self._is_acquire_pattern():
            self.memory_order = "acquire"
        else:
            self.memory_order = "acq_rel"

    def _generate_metal_code(self) -> str:
        """
        Generate optimized Metal atomic operation code.
        Includes advanced SIMD and memory order optimizations.
        """
        self.optimize_atomic_access()

        metal_func = self.SUPPORTED_ATOMIC_OPS[self.operation]
        operands = [op.get_metal_translation() for op in self.operands]

        # Generate optimized atomic operation
        if self.optimization_hints['uses_simd']:
            return self._generate_simd_atomic(metal_func, operands)
        return self._generate_standard_atomic(metal_func, operands)

    def _generate_simd_atomic(self, func: str, operands: List[str]) -> str:
        """Generate SIMD-optimized atomic operation."""
        return f"""
            // SIMD-optimized atomic operation
            {func}({', '.join(operands)}, 
                   memory_order_{self.memory_order},
                   memory_scope_{self.memory_scope})
        """

class BarrierNode(BaseNode):
    """
    Production-grade barrier synchronization implementation.

    Capabilities:
    - Full threadgroup synchronization
    - Memory fence operations
    - SIMD group synchronization
    - Performance optimization

    Features:
    - Automatic scope detection
    - Memory order optimization
    - Fence combination
    - Barrier elimination
    """

    def __init__(self, location: Location):
        super().__init__(location)
        self._barrier_lock = RLock()

        # Core barrier configuration
        self.scope = "threadgroup"
        self.memory_scope = "device"
        self.fence_type = "all"

        # Performance tracking
        self.barrier_metrics = {
            'wait_cycles': 0,
            'threads_synchronized': 0,
            'memory_fences': 0
        }

    def optimize_barrier(self) -> None:
        """
        Optimize barrier for maximum performance.
        Implements advanced barrier optimization techniques.
        """
        with self._barrier_lock:
            # Optimize barrier scope
            self._optimize_barrier_scope()

            # Optimize memory fences
            self._optimize_memory_fences()

            # Track performance metrics
            self._update_barrier_metrics()

    def _optimize_barrier_scope(self) -> None:
        """
        Optimize barrier scope based on usage patterns.
        Implements scope reduction for better performance.
        """
        if self._can_use_simd_sync():
            self.scope = "simdgroup"
            self.memory_scope = "simdgroup"
        elif self._requires_device_scope():
            self.scope = "device"
            self.memory_scope = "device"
        else:
            self.scope = "threadgroup"
            self.memory_scope = "threadgroup"

    def _generate_metal_code(self) -> str:
        """
        Generate optimized Metal barrier code.
        Includes advanced scope and fence optimizations.
        """
        self.optimize_barrier()

        barrier_flags = []
        if self.fence_type in ("all", "memory"):
            barrier_flags.append("mem_flags::mem_device")
        if self.fence_type in ("all", "texture"):
            barrier_flags.append("mem_flags::mem_texture")

        flags = " | ".join(barrier_flags) if barrier_flags else "mem_flags::mem_none"

        return f"""
            // Optimized barrier synchronization
            {self.scope}_barrier({flags});
            
            // Barrier metrics tracking
            // Scope: {self.scope}
            // Memory scope: {self.memory_scope}
            // Fence type: {self.fence_type}
        """

    def _update_barrier_metrics(self) -> None:
        """
        Update barrier performance metrics.
        Tracks synchronization overhead and efficiency.
        """
        self.barrier_metrics['threads_synchronized'] = (
            self.parent.optimization_data.thread_execution_width
            if self.scope == "simdgroup"
            else MAX_THREADS_PER_GROUP
        )
"""
Enterprise-Grade Performance Monitoring and Validation Framework
Version: 2.1.0
Scope: Production Metal Systems
Architecture: Apple Silicon Optimization
"""

class MetalPerformanceMonitor:
    """
    Production-grade performance monitoring system for Metal shader optimization.

    Capabilities:
    - Real-time performance metrics
    - Memory access pattern analysis
    - SIMD efficiency tracking
    - Barrier overhead monitoring
    - Thread occupancy optimization

    Implementation Notes:
    - Thread-safe metric collection
    - Microsecond precision timing
    - Hardware-specific optimization tracking
    - Advanced profiling capabilities
    """

    def __init__(self):
        self._monitor_lock = RLock()
        self.start_time = time.perf_counter_ns()

        # Core performance metrics
        self.metrics = {
            'compute_time': 0.0,
            'memory_transfer_time': 0.0,
            'barrier_overhead': 0.0,
            'simd_efficiency': 0.0,
            'memory_throughput': 0.0,
            'thread_occupancy': 0.0
        }

        # Detailed performance tracking
        self.performance_data = {
            'kernel_executions': [],
            'memory_transactions': [],
            'barrier_points': [],
            'atomic_operations': []
        }

        # Hardware utilization
        self.hardware_metrics = {
            'simd_usage': 0.0,
            'memory_bandwidth': 0.0,
            'cache_hit_rate': 0.0,
            'register_pressure': 0
        }

    def record_event(self, event_type: str, data: Dict[str, Any]) -> None:
        """
        Thread-safe performance event recording with nanosecond precision.

        Args:
            event_type: Type of performance event
            data: Event-specific performance data
        """
        with self._monitor_lock:
            timestamp = time.perf_counter_ns() - self.start_time
            event = {
                'timestamp': timestamp,
                'type': event_type,
                'data': data
            }

            if event_type == 'kernel_execution':
                self.performance_data['kernel_executions'].append(event)
                self._update_compute_metrics(data)
            elif event_type == 'memory_transfer':
                self.performance_data['memory_transactions'].append(event)
                self._update_memory_metrics(data)
            elif event_type == 'barrier_sync':
                self.performance_data['barrier_points'].append(event)
                self._update_barrier_metrics(data)

    def _update_compute_metrics(self, data: Dict[str, Any]) -> None:
        """Update compute performance metrics with hardware-specific optimizations."""
        self.metrics['compute_time'] += data.get('execution_time', 0.0)
        self.hardware_metrics['simd_usage'] = (
                data.get('active_simd_lanes', 0) / METAL_SIMD_WIDTH
        )
        self.metrics['thread_occupancy'] = (
                data.get('active_threads', 0) / MAX_THREADS_PER_GROUP
        )

class MetalValidator:
    """
    Enterprise-grade validation system for Metal shader compliance.

    Capabilities:
    - Comprehensive constraint validation
    - Resource limit verification
    - Memory alignment checking
    - Thread configuration validation
    - Hardware compatibility verification

    Implementation Notes:
    - Thread-safe validation
    - Complete error reporting
    - Proactive constraint checking
    - Optimization validation
    """

    def __init__(self):
        self._validator_lock = RLock()
        self.validation_errors: List[Dict[str, Any]] = []
        self.validation_warnings: List[Dict[str, Any]] = []

        # Validation configuration
        self.constraints = {
            'max_threads_per_group': MAX_THREADS_PER_GROUP,
            'max_threadgroup_memory': MAX_TOTAL_THREADGROUP_MEMORY,
            'buffer_alignment': BUFFER_ALIGNMENT,
            'texture_alignment': TEXTURE_ALIGNMENT,
            'simd_width': METAL_SIMD_WIDTH
        }

    def validate_kernel(self, kernel: CUDAKernel) -> bool:
        """
        Comprehensive kernel validation against Metal constraints.

        Args:
            kernel: CUDA kernel for validation

        Returns:
            bool: Validation success status

        Raises:
            CudaTranslationError: On critical validation failures
        """
        with self._validator_lock:
            try:
                self._validate_thread_configuration(kernel)
                self._validate_memory_usage(kernel)
                self._validate_barrier_usage(kernel)
                self._validate_atomic_operations(kernel)
                self._validate_resource_limits(kernel)

                return len(self.validation_errors) == 0

            except Exception as e:
                self.validation_errors.append({
                    'type': 'critical',
                    'message': str(e),
                    'location': kernel.location
                })
                return False

    def _validate_thread_configuration(self, kernel: CUDAKernel) -> None:
        """Validate thread configuration against Metal hardware constraints."""
        thread_count = (
                kernel.thread_hierarchy.block_dim[0] *
                kernel.thread_hierarchy.block_dim[1] *
                kernel.thread_hierarchy.block_dim[2]
        )

        if thread_count > self.constraints['max_threads_per_group']:
            self.validation_errors.append({
                'type': 'thread_config',
                'message': (
                    f"Thread count {thread_count} exceeds Metal limit of "
                    f"{self.constraints['max_threads_per_group']}"
                ),
                'location': kernel.location
            })

        if thread_count % self.constraints['simd_width'] != 0:
            self.validation_warnings.append({
                'type': 'simd_alignment',
                'message': (
                    f"Thread count {thread_count} is not aligned to SIMD width "
                    f"{self.constraints['simd_width']}"
                ),
                'location': kernel.location
            })

    def generate_validation_report(self) -> Dict[str, Any]:
        """
        Generate comprehensive validation report with optimization recommendations.

        Returns:
            Dict containing validation results and optimization suggestions
        """
        return {
            'validation_status': len(self.validation_errors) == 0,
            'errors': [
                {
                    'type': err['type'],
                    'message': err['message'],
                    'location': f"{err['location'].file}:{err['location'].line}"
                }
                for err in self.validation_errors
            ],
            'warnings': [
                {
                    'type': warn['type'],
                    'message': warn['message'],
                    'location': f"{warn['location'].file}:{warn['location'].line}"
                }
                for warn in self.validation_warnings
            ],
            'optimization_recommendations': self._generate_optimization_recommendations()
        }

    def _generate_optimization_recommendations(self) -> List[Dict[str, str]]:
        """Generate hardware-specific optimization recommendations."""
        recommendations = []

        # Thread optimization recommendations
        if any(err['type'] == 'thread_config' for err in self.validation_errors):
            recommendations.append({
                'category': 'thread_optimization',
                'description': (
                    'Adjust thread configuration to align with Metal SIMD width '
                    f'of {self.constraints["simd_width"]} for optimal performance'
                ),
                'priority': 'high'
            })

        # Memory optimization recommendations
        if any(err['type'] == 'memory_alignment' for err in self.validation_errors):
            recommendations.append({
                'category': 'memory_optimization',
                'description': (
                    'Align buffer access patterns to Metal requirements for '
                    'improved memory throughput'
                ),
                'priority': 'high'
            })

        return recommendations
"""
Metal Integration and System Orchestration Framework
Version: 2.1.0 Enterprise Edition
Target: High-Performance Production Systems
Optimization: Apple Silicon M1/M2/M3 Architecture

Key Implementation Features:
- Complete system orchestration
- Real-time performance optimization
- Advanced error recovery
- Comprehensive validation
- Production monitoring
"""

class MetalIntegrationManager:
    """
    Enterprise-grade Metal integration and system orchestration.

    Core Capabilities:
    - Complete system lifecycle management
    - Real-time performance optimization
    - Advanced error handling and recovery
    - Comprehensive validation framework
    - Production monitoring and metrics

    Implementation Notes:
    - Thread-safe operations throughout
    - Microsecond-precision timing
    - Advanced memory management
    - Sophisticated error recovery
    """

    def __init__(self):
        self._integration_lock = RLock()

        # Core system components
        self.performance_monitor = MetalPerformanceMonitor()
        self.validator = MetalValidator()
        self.thread_pool = ThreadPoolExecutor(
            max_workers=os.cpu_count(),
            thread_name_prefix="MetalWorker"
        )

        # System state tracking
        self.active_kernels: Dict[str, CUDAKernel] = {}
        self.translation_cache: Dict[str, str] = {}
        self.optimization_state: Dict[str, Any] = {}

        # Performance tracking
        self.system_metrics = {
            'total_kernels_processed': 0,
            'successful_translations': 0,
            'optimization_score': 0.0,
            'system_uptime': time.time()
        }

    def translate_kernel(self, kernel: CUDAKernel) -> str:
        """
        Thread-safe kernel translation with comprehensive optimization.

        Args:
            kernel: CUDA kernel for translation

        Returns:
            str: Optimized Metal shader code

        Raises:
            CudaTranslationError: On critical translation failures
        """
        with self._integration_lock:
            try:
                # Validate kernel before translation
                if not self.validator.validate_kernel(kernel):
                    raise CudaTranslationError(
                        f"Kernel validation failed: {kernel.name}"
                    )

                # Check translation cache
                cache_key = self._generate_cache_key(kernel)
                if cache_key in self.translation_cache:
                    return self.translation_cache[cache_key]

                # Perform translation with optimization
                metal_code = self._translate_and_optimize(kernel)

                # Update system metrics
                self._update_metrics(kernel, True)

                # Cache successful translation
                self.translation_cache[cache_key] = metal_code

                return metal_code

            except Exception as e:
                self._update_metrics(kernel, False)
                self._handle_translation_error(e, kernel)
                raise

    def _translate_and_optimize(self, kernel: CUDAKernel) -> str:
        """
        Perform optimized kernel translation with advanced Metal features.

        Implementation:
        1. Thread hierarchy optimization
        2. Memory access pattern optimization
        3. SIMD utilization enhancement
        4. Barrier optimization
        5. Performance validation
        """
        # Initialize translation context
        context = self._create_translation_context(kernel)

        # Optimize thread hierarchy
        self._optimize_thread_configuration(kernel, context)

        # Optimize memory access
        self._optimize_memory_patterns(kernel, context)

        # Generate optimized Metal code
        metal_code = self._generate_metal_code(kernel, context)

        # Validate generated code
        self._validate_metal_code(metal_code, context)

        return metal_code

    def _optimize_thread_configuration(self,
                                       kernel: CUDAKernel,
                                       context: Dict[str, Any]) -> None:
        """
        Optimize thread configuration for maximum Metal performance.

        Optimization Strategy:
        1. SIMD width alignment
        2. Thread group size optimization
        3. Work distribution balancing
        4. Occupancy maximization
        """
        thread_config = kernel.thread_hierarchy

        # Optimize for SIMD execution
        optimal_width = (
                (thread_config.block_dim[0] + METAL_SIMD_WIDTH - 1)
                // METAL_SIMD_WIDTH * METAL_SIMD_WIDTH
        )

        # Update thread configuration
        thread_config.block_dim = (
            optimal_width,
            thread_config.block_dim[1],
            thread_config.block_dim[2]
        )

        # Record optimization in context
        context['thread_optimization'] = {
            'original_width': kernel.thread_hierarchy.block_dim[0],
            'optimized_width': optimal_width,
            'simd_groups': optimal_width // METAL_SIMD_WIDTH
        }

    def generate_system_report(self) -> Dict[str, Any]:
        """
        Generate comprehensive system performance and health report.

        Report Contents:
        1. System performance metrics
        2. Resource utilization
        3. Optimization effectiveness
        4. Error statistics
        5. Recommendations
        """
        with self._integration_lock:
            uptime = time.time() - self.system_metrics['system_uptime']

            return {
                'system_health': {
                    'status': 'operational',
                    'uptime_seconds': uptime,
                    'total_kernels': self.system_metrics['total_kernels_processed'],
                    'success_rate': (
                            self.system_metrics['successful_translations'] /
                            max(self.system_metrics['total_kernels_processed'], 1)
                    )
                },
                'performance_metrics': self.performance_monitor.metrics,
                'optimization_score': self.system_metrics['optimization_score'],
                'resource_utilization': self._get_resource_utilization(),
                'recommendations': self._generate_recommendations()
            }
Class: ('Location', '')
--------------------------------------------------------------------------------
  Method: get(self.operator)
  Method: get(memory_type, "device")
  Method: get('execution_time', 0.0)
  Method: get('active_simd_lanes', 0)
  Method: get('active_threads', 0)

Class: ('MetalOptimizationData', '')
--------------------------------------------------------------------------------
  Method: get(self.operator)
  Method: get(memory_type, "device")
  Method: get('execution_time', 0.0)
  Method: get('active_simd_lanes', 0)
  Method: get('active_threads', 0)

Class: ('PerformanceMetrics', '')
--------------------------------------------------------------------------------
  Method: get(self.operator)
  Method: get(memory_type, "device")
  Method: get('execution_time', 0.0)
  Method: get('active_simd_lanes', 0)
  Method: get('active_threads', 0)

Class: ('BaseNode', '')
--------------------------------------------------------------------------------
  Method: get(self.operator)
  Method: get(memory_type, "device")
  Method: get('execution_time', 0.0)
  Method: get('active_simd_lanes', 0)
  Method: get('active_threads', 0)

Class: ('ExpressionNode', '(BaseNode)')
--------------------------------------------------------------------------------
  Method: get(self.operator)
  Method: get(memory_type, "device")
  Method: get('execution_time', 0.0)
  Method: get('active_simd_lanes', 0)
  Method: get('active_threads', 0)

Class: ('StatementNode', '(BaseNode)')
--------------------------------------------------------------------------------
  Method: get(self.operator)
  Method: get(memory_type, "device")
  Method: get('execution_time', 0.0)
  Method: get('active_simd_lanes', 0)
  Method: get('active_threads', 0)

Class: ('ThreadHierarchyNode', '(BaseNode)')
--------------------------------------------------------------------------------
  Method: get(self.operator)
  Method: get(memory_type, "device")
  Method: get('execution_time', 0.0)
  Method: get('active_simd_lanes', 0)
  Method: get('active_threads', 0)

Class: ('MemoryModelNode', '(BaseNode)')
--------------------------------------------------------------------------------
  Method: get(self.operator)
  Method: get(memory_type, "device")
  Method: get('execution_time', 0.0)
  Method: get('active_simd_lanes', 0)
  Method: get('active_threads', 0)

Class: ('AtomicNode', '(ExpressionNode)')
--------------------------------------------------------------------------------
  Method: get(self.operator)
  Method: get(memory_type, "device")
  Method: get('execution_time', 0.0)
  Method: get('active_simd_lanes', 0)
  Method: get('active_threads', 0)

Class: ('BarrierNode', '(BaseNode)')
--------------------------------------------------------------------------------
  Method: get(self.operator)
  Method: get(memory_type, "device")
  Method: get('execution_time', 0.0)
  Method: get('active_simd_lanes', 0)
  Method: get('active_threads', 0)

Class: ('MetalPerformanceMonitor', '')
--------------------------------------------------------------------------------
  Method: get(self.operator)
  Method: get(memory_type, "device")
  Method: get('execution_time', 0.0)
  Method: get('active_simd_lanes', 0)
  Method: get('active_threads', 0)

Class: ('MetalValidator', '')
--------------------------------------------------------------------------------
  Method: get(self.operator)
  Method: get(memory_type, "device")
  Method: get('execution_time', 0.0)
  Method: get('active_simd_lanes', 0)
  Method: get('active_threads', 0)

Class: ('MetalIntegrationManager', '')
--------------------------------------------------------------------------------
  Method: get(self.operator)
  Method: get(memory_type, "device")
  Method: get('execution_time', 0.0)
  Method: get('active_simd_lanes', 0)
  Method: get('active_threads', 0)


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\core\parser\clang_integration.py

from typing import Dict, List, Optional, Union, Tuple
from pathlib import Path
import logging
import clang.cindex
from clang.cindex import Index, TranslationUnit, Cursor, CursorKind, TypeKind

from .ast_nodes import (
    CUDAType,
    CUDAQualifier,
    CUDANode,
    CUDAKernel,
    CUDAParameter,
    CUDACompoundStmt,
    CUDAThreadIdx,
    CUDABlockIdx,
    CUDAGridDim,
    CUDAAtomicOperation,
    CUDASharedMemory,
    CUDATexture,
    CUDABarrier,
    SourceLocation,
    CUDANodeType
)

class ClangParser:
    """CUDA parser using Clang's Python bindings"""

    def __init__(self, cuda_path: Optional[str] = None):
        self.index = Index.create()
        self.cuda_path = cuda_path or self._find_cuda_path()
        self.cuda_version = self._detect_cuda_version()
        self._init_compilation_args()

    def _find_cuda_path(self) -> str:
        """Find CUDA installation path"""
        common_paths = [
            "/usr/local/cuda",
            "/usr/cuda",
            "C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA",
            "C:/CUDA"
        ]

        for path in common_paths:
            if Path(path).exists():
                return str(Path(path))
        raise RuntimeError("CUDA installation not found")

    def _detect_cuda_version(self) -> str:
        """Detect CUDA version from installation"""
        version_file = Path(self.cuda_path) / "version.txt"
        if version_file.exists():
            content = version_file.read_text()
            import re
            if match := re.search(r'V(\d+\.\d+\.\d+)', content):
                return match.group(1)
        return "unknown"

    def _init_compilation_args(self):
        """Initialize CUDA compilation arguments"""
        self.compilation_args = [
            "-x", "cuda",
            "--cuda-gpu-arch=sm_75",
            "-std=c++14",
            f"-I{Path(self.cuda_path)/'include'}",
            "-D__CUDACC__",
            "-D__CUDA_ARCH__=750",
            "-DNDEBUG",
        ]

    def parse_file(self, cuda_file: Union[str, Path]) -> Optional[CUDANode]:
        """Parse CUDA source file into AST"""
        try:
            tu = self.index.parse(
                str(cuda_file),
                args=self.compilation_args,
                options=(
                        TranslationUnit.PARSE_DETAILED_PROCESSING_RECORD |
                        TranslationUnit.PARSE_INCOMPLETE
                )
            )

            # Check for fatal errors
            if self._has_fatal_errors(tu):
                return None

            # Convert to CUDA AST
            return self._process_translation_unit(tu.cursor)

        except Exception as e:
            logging.error(f"Failed to parse {cuda_file}: {str(e)}")
            return None

    def _has_fatal_errors(self, tu: TranslationUnit) -> bool:
        """Check for fatal parsing errors"""
        has_fatal = False
        for diag in tu.diagnostics:
            if diag.severity >= diag.Error:
                logging.error(
                    f"{diag.location.file}:{diag.location.line} - {diag.spelling}"
                )
                has_fatal = True
        return has_fatal

    def _process_translation_unit(self, cursor: Cursor) -> CUDANode:
        """Process translation unit cursor"""
        root = CUDANode(
            line=cursor.location.line,
            column=cursor.location.column
        )

        for child in cursor.get_children():
            if node := self._process_cursor(child):
                root.add_child(node)

        return root

    def _process_cursor(self, cursor: Cursor) -> Optional[CUDANode]:
        """Process a single Clang cursor"""
        source_location = SourceLocation(
            file=str(cursor.location.file) if cursor.location.file else "",
            line=cursor.location.line,
            column=cursor.location.column,
            offset=cursor.location.offset
        )

        # Handle different cursor kinds
        if cursor.kind == CursorKind.FUNCTION_DECL:
            return self._process_function(cursor, source_location)
        elif cursor.kind == CursorKind.VAR_DECL:
            return self._process_variable(cursor, source_location)
        elif cursor.kind == CursorKind.MEMBER_REF_EXPR:
            return self._process_member_ref(cursor, source_location)
        elif cursor.kind == CursorKind.CALL_EXPR:
            return self._process_call(cursor, source_location)

        return None

# ... rest of the implementation remains the same ...
Class: ('ClangParser', '')
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\core\parser\__init__.py

# CUDAM/core/parser/__init__.py

# Optionally, import classes from ast_nodes.py for easier access
from .ast_nodes import (
    CUDANode,
    CUDAKernel,
    CUDAParameter,
    CUDAType,
    CUDAQualifier,
    CUDASharedMemory,
    CUDAThreadIdx,
    CUDABarrier,
    CUDACompoundStmt,
    CUDAExpressionNode,
    CUDAStatement,
    FunctionNode,
    KernelNode,
    VariableNode,
    StructNode,
    EnumNode,
    TypedefNode,
    ClassNode,
    NamespaceNode,
    TemplateNode,
    CudaASTNode,
    CudaTranslationContext
)

__all__ = [
    "CUDANode",
    "CUDAKernel",
    "CUDAParameter",
    "CUDAType",
    "CUDAQualifier",
    "CUDASharedMemory",
    "CUDAThreadIdx",
    "CUDABarrier",
    "CUDACompoundStmt",
    "CUDAExpressionNode",
    "CUDAStatement",
    "FunctionNode",
    "KernelNode",
    "VariableNode",
    "StructNode",
    "EnumNode",
    "TypedefNode",
    "ClassNode",
    "NamespaceNode",
    "TemplateNode",
    "CudaASTNode",
    "CudaTranslationContext"
]


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\core\translator\host_translator.py

from typing import Dict, Any
import re
from pathlib import Path

from ..utils.error_handler import CudaTranslationError
from ..utils.logger import get_logger
from ..core.parser.ast_nodes import (
    CUDANode, CUDAKernel, CUDAParameter, CUDAType,
    CUDAQualifier, CUDASharedMemory, CUDAThreadIdx
)
from ..generator.msl_generator import MetalShaderGenerator


class CUDAHostTranslator:
    """
    Translates CUDA host code to Metal host code following NVIDIA's host API patterns
    """

    def __init__(self):
        self.metal_buffer_index = 0
        self.kernel_map: Dict[str, CUDAKernel] = {}

    def translate_host_code(self, cuda_code: str, target_lang: str = 'swift') -> str:
        """Translate CUDA host code to Metal"""
        if target_lang not in {'swift', 'objc'}:
            raise ValueError("Target language must be 'swift' or 'objc'")

        # Process CUDA API calls
        processed_code = self._translate_device_management(cuda_code)
        processed_code = self._translate_memory_management(processed_code)
        processed_code = self._translate_kernel_launch(processed_code)
        processed_code = self._translate_synchronization(processed_code)

        # Generate appropriate host code
        if target_lang == 'swift':
            return self._generate_swift_code(processed_code)
        else:
            return self._generate_objc_code(processed_code)

    def _translate_device_management(self, code: str) -> str:
        """Translate CUDA device management calls"""
        replacements = {
            r'cudaSetDevice\((\d+)\)': r'// Metal automatically manages devices',
            r'cudaGetDevice\(&dev\)': r'// Metal automatically manages devices',
            r'cudaGetDeviceCount\(&count\)': r'let count = MTLCopyAllDevices().count',
            r'cudaDeviceSynchronize\(\)': r'commandBuffer.waitUntilCompleted()'
        }

        result = code
        for cuda_pattern, metal_code in replacements.items():
            result = re.sub(cuda_pattern, metal_code, result)

        return result

    def _translate_memory_management(self, code: str) -> str:
        """Translate CUDA memory management calls"""
        # Handle cudaMalloc
        code = re.sub(
            r'cudaMalloc\(\(void\*\*\)&(\w+),\s*(.+?)\)',
            lambda m: f'{m.group(1)} = device.makeBuffer(length: {m.group(2)}, '
                      f'options: .storageModeShared)',
            code
        )

        # Handle cudaMemcpy
        code = re.sub(
            r'cudaMemcpy\((.+?),\s*(.+?),\s*(.+?),\s*cudaMemcpy(.+?)\)',
            self._translate_memcpy,
            code
        )

        # Handle cudaFree
        code = re.sub(
            r'cudaFree\((\w+)\)',
            r'// Metal automatically manages memory',
            code
        )

        return code

    def _translate_memcpy(self, match) -> str:
        """Translate cudaMemcpy calls"""
        dst, src, size, kind = match.groups()

        if kind == 'HostToDevice':
            return f'memcpy({dst}.contents, {src}, {size})'
        elif kind == 'DeviceToHost':
            return f'memcpy({dst}, {src}.contents, {size})'
        elif kind == 'DeviceToDevice':
            return (f'let blitEncoder = commandBuffer.makeBlitCommandEncoder()\n'
                    f'blitEncoder.copy(from: {src}, to: {dst}, size: {size})\n'
                    f'blitEncoder.endEncoding()')

        return match.group(0)

    def _translate_kernel_launch(self, code: str) -> str:
        """Translate CUDA kernel launches"""
        # Match kernel launch syntax
        pattern = r'(\w+)<<<(.+?)>>>(.+?);'

        return re.sub(pattern, self._translate_launch_config, code)

    def _translate_launch_config(self, match) -> str:
        """Translate kernel launch configuration"""
        kernel_name, config, args = match.groups()

        # Parse grid and block dimensions
        grid_dim, block_dim = config.split(',', 1)

        return (
            f'let commandEncoder = commandBuffer.makeComputeCommandEncoder()\n'
            f'commandEncoder.setComputePipelineState({kernel_name}PipelineState)\n'
            f'let gridSize = MTLSize(width: {grid_dim}, height: 1, depth: 1)\n'
            f'let blockSize = MTLSize(width: {block_dim}, height: 1, depth: 1)\n'
            f'commandEncoder.dispatchThreadgroups(gridSize, threadsPerThreadgroup: blockSize)\n'
            f'commandEncoder.endEncoding()'
        )

    def _translate_synchronization(self, code: str) -> str:
        """Translate CUDA synchronization calls"""
        replacements = {
            r'cudaDeviceSynchronize\(\)': 'commandBuffer.waitUntilCompleted()',
            r'cudaStreamSynchronize\((\w+)\)': r'\1.waitUntilCompleted()',
            r'cudaEventSynchronize\((\w+)\)': r'\1.waitUntilCompleted()',
        }

        result = code
        for cuda_pattern, metal_code in replacements.items():
            result = re.sub(cuda_pattern, metal_code, result)

        return result

    def _generate_swift_code(self, processed_code: str) -> str:
        """Generate Swift host code"""
        setup_code = """
            import Metal
            import MetalKit
            
            guard let device = MTLCreateSystemDefaultDevice() else {
                fatalError("GPU not available")
            }
            
            let commandQueue = device.makeCommandQueue()!
            let commandBuffer = commandQueue.makeCommandBuffer()!
        """

        return f"{setup_code}\n{processed_code}"

    def _generate_objc_code(self, processed_code: str) -> str:
        """Generate Objective-C host code"""
        setup_code = """
            #import <Metal/Metal.h>
            #import <MetalKit/MetalKit.h>
            
            id<MTLDevice> device = MTLCreateSystemDefaultDevice();
            if (!device) {
                NSLog(@"GPU not available");
                return;
            }
            
            id<MTLCommandQueue> commandQueue = [device newCommandQueue];
            id<MTLCommandBuffer> commandBuffer = [commandQueue commandBuffer];
        """

        return f"{setup_code}\n{processed_code}"
Class: ('CUDAHostTranslator', '')
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\core\translator\kernel_translator.py

from typing import Dict, List, Optional, Set, Union, Any, Tuple
import re
from threading import Lock, RLock
import logging
import time
from pathlib import Path
import hashlib
import traceback

from ..utils.error_handler import CudaTranslationError, CudaParseError
from ..utils.logger import get_logger
from ..utils.metal_equivalents import get_metal_equivalent, translate_cuda_call_to_metal
from ..utils.cuda_to_metal_type_mapping import (
    map_cuda_type_to_metal, is_vector_type, get_vector_component_type, get_vector_size
)
from ..utils.mapping_tables import (
    METAL_TYPES, METAL_FUNCTIONS, METAL_ATTRIBUTES, METAL_ADDRESS_SPACES,
    METAL_MEMORY_FLAGS, METAL_THREAD_MAPPING
)
from ..core.parser.ast_nodes import (
    CUDANode, CUDAKernel, CUDAParameter, CUDAType, CUDAQualifier,
    CUDAExpressionNode, CUDAStatement, CUDASharedMemory, CUDABarrier
)

logger = get_logger(__name__)

class KernelTranslator:
    """
    Production-grade CUDA kernel translator with comprehensive Metal optimization support.
    Thread-safe implementation for high-performance translation pipelines.

    This class handles the translation of CUDA kernels into Metal Shading Language (MSL),
    including advanced optimizations and hardware-specific considerations for Apple Silicon.

    Features:
    - Thread-safe implementation with fine-grained locking
    - Smart caching for high-performance translation
    - Comprehensive error detection and reporting
    - Multi-level optimization pipeline
    - Hardware-aware translation targeting Apple M1/M2/M3 capabilities
    """

    def __init__(self, metal_target_version: str = "2.4", optimization_level: int = 2):
        """
        Initialize the KernelTranslator with specific optimization settings.

        Args:
            metal_target_version: Target Metal API version (defaults to 2.4)
            optimization_level: Optimization aggressiveness level (0-3, default 2)
                0: No optimizations
                1: Basic optimizations (memory coalescing, barrier optimizations)
                2: Intermediate optimizations (SIMD usage, loop unrolling)
                3: Aggressive optimizations (vectorization, memory layout)
        """
        # Thread safety - use RLock for re-entrancy support
        self._lock = RLock()

        # Translation state
        self._translation_cache: Dict[str, str] = {}
        self._kernel_metadata: Dict[str, Dict[str, Any]] = {}
        self._validation_cache: Dict[str, bool] = {}

        # Feature tracking
        self.used_features: Set[str] = set()
        self.required_headers: Set[str] = set()

        # Configuration
        self.metal_target_version = metal_target_version
        self.optimization_level = optimization_level

        # Initialize hardware-specific limits for Apple Silicon
        self.metal_limits = {
            'max_threads_per_group': 1024,
            'max_total_threadgroup_memory': 32768,  # 32KB
            'simd_width': 32,
            'max_threadgroups_per_grid': (65535, 65535, 65535),
            'max_buffer_size': 256 * 1024 * 1024,  # 256MB for typical devices
            'registers_per_threadgroup': 16384,
            'max_constant_buffer_size': 64 * 1024,  # 64KB
            'texture_buffer_alignment': 16
        }

        # Performance metrics
        self.metrics = {
            'translations': 0,
            'cache_hits': 0,
            'translation_time_total': 0.0,
            'validation_time_total': 0.0,
            'optimization_time_total': 0.0
        }

        logger.info(f"KernelTranslator initialized with Metal {metal_target_version} target "
                    f"and optimization level {optimization_level}")

    def translate_kernel(self, kernel: CUDAKernel) -> str:
        """
        Translate a CUDA kernel function to Metal Shading Language (MSL).
        Thread-safe implementation with caching and profiling.

        Args:
            kernel: CUDA kernel AST node to translate

        Returns:
            str: Translated Metal shader function

        Raises:
            CudaTranslationError: If translation fails due to incompatible CUDA features
            CudaParseError: If AST node structure is invalid
            Exception: For other unexpected errors
        """
        try:
            # Generate cache key based on kernel hash and optimization level
            # This ensures different optimization levels get their own cache entries
            kernel_hash = self._compute_kernel_hash(kernel)
            cache_key = f"{kernel.name}:{kernel_hash}:{self.optimization_level}"

            # Check cache with proper locking
            with self._lock:
                if cache_key in self._translation_cache:
                    self.metrics['cache_hits'] += 1
                    logger.debug(f"Cache hit for kernel: {kernel.name}")
                    return self._translation_cache[cache_key]

            # Performance tracking
            start_time = time.time()
            translation_start = start_time
            logger.info(f"Translating kernel: {kernel.name}")

            # Reset used features for this translation
            self.used_features = set()

            # Validation phase
            validation_start = time.time()
            self._validate_kernel(kernel)
            validation_time = time.time() - validation_start
            self.metrics['validation_time_total'] += validation_time

            # Step 1: Generate Metal kernel signature
            signature = self._generate_metal_signature(kernel)

            # Step 2: Generate kernel body
            body = self._translate_kernel_body(kernel)

            # Step 3: Apply optimizations based on level
            if self.optimization_level > 0:
                optimization_start = time.time()
                body = self._optimize_kernel_body(body, kernel)
                optimization_time = time.time() - optimization_start
                self.metrics['optimization_time_total'] += optimization_time

            # Step 4: Combine signature and body with proper spacing
            metal_kernel = f"{signature} {{\n{body}\n}}"

            # Step 5: Final validation
            self._validate_metal_code(metal_kernel)

            # Update metrics and cache result
            with self._lock:
                self.metrics['translations'] += 1
                self._translation_cache[cache_key] = metal_kernel

                # Store metadata about this kernel for later reference
                self._kernel_metadata[kernel.name] = {
                    'thread_dimensions': self._get_kernel_thread_dimensions(kernel),
                    'shared_memory_size': self._get_kernel_shared_memory_size(kernel),
                    'used_features': self.used_features.copy(),
                    'parameter_count': len(kernel.parameters),
                    'translation_timestamp': time.time()
                }

            # Performance logging
            translation_time = time.time() - translation_start
            self.metrics['translation_time_total'] += translation_time
            logger.info(f"Successfully translated kernel {kernel.name} in {translation_time:.2f}s")

            return metal_kernel

        except CudaTranslationError as e:
            # Log and re-raise translation-specific errors
            logger.error(f"Translation error in kernel {kernel.name}: {str(e)}")
            raise
        except CudaParseError as e:
            # Log and re-raise parsing-specific errors
            logger.error(f"Parse error in kernel {kernel.name}: {str(e)}")
            raise
        except Exception as e:
            # Handle unexpected errors with detailed information
            error_msg = f"Unexpected error translating kernel {kernel.name}: {str(e)}"
            stack_trace = traceback.format_exc()
            logger.error(f"{error_msg}\n{stack_trace}")
            raise CudaTranslationError(error_msg)

    def translate_ast(self, root: CUDANode) -> str:
        """
        Translate an entire CUDA AST to Metal code.

        Args:
            root: CUDA AST root node

        Returns:
            str: Complete Metal shader file
        """
        metal_lines = []

        # Process all nodes and collect required features
        self._collect_required_features(root)

        # Generate appropriate Metal headers based on features
        metal_lines.append(self._generate_metal_headers())

        # Add any required utility functions based on used features
        utility_functions = self._generate_utility_functions()
        if utility_functions:
            metal_lines.append(utility_functions)

        # Translate each top-level CUDA entity
        device_functions = []
        kernels = []
        constants = []

        for node in root.children:
            if isinstance(node, CUDAKernel):
                # Translate kernel functions
                kernels.append(self.translate_kernel(node))
            elif self._is_device_function(node):
                # Translate device functions
                device_functions.append(self._translate_device_function(node))
            elif self._is_constant_memory(node):
                # Translate constant memory declarations
                constants.append(self._translate_constant_memory(node))

        # Add translations in proper order
        if constants:
            metal_lines.append("// Global Constants")
            metal_lines.extend(constants)
            metal_lines.append("")

        if device_functions:
            metal_lines.append("// Device Functions")
            metal_lines.extend(device_functions)
            metal_lines.append("")

        if kernels:
            metal_lines.append("// Kernel Functions")
            metal_lines.extend(kernels)

        return "\n".join(metal_lines)

    def _compute_kernel_hash(self, kernel: CUDAKernel) -> str:
        """
        Compute a hash of the kernel AST for caching purposes.

        Args:
            kernel: CUDA kernel AST node

        Returns:
            str: Hash of the kernel structure
        """
        # Create a string representation of the kernel
        kernel_repr = f"{kernel.name}:{kernel.line}:{kernel.column}"

        # Add parameter information
        for param in kernel.parameters:
            kernel_repr += f":{param.name}:{param.param_type}:{int(param.is_pointer)}"

        # Add body information (simplified)
        kernel_repr += f":{len(kernel.body)}"

        # Generate hash
        return hashlib.md5(kernel_repr.encode()).hexdigest()

    def _validate_kernel(self, kernel: CUDAKernel):
        """
        Validate kernel for Metal compatibility with comprehensive checks.

        Args:
            kernel: CUDA kernel to validate

        Raises:
            CudaTranslationError: If kernel contains features incompatible with Metal
        """
        validation_errors = []

        # 1. Check thread limits
        if hasattr(kernel, 'max_threads_per_block') and kernel.max_threads_per_block > self.metal_limits['max_threads_per_group']:
            validation_errors.append(
                f"Kernel {kernel.name} exceeds Metal's max threads per group limit "
                f"({kernel.max_threads_per_block} > {self.metal_limits['max_threads_per_group']})"
            )

        # 2. Check for unsupported memory operations
        unsupported_features = self._detect_unsupported_features(kernel)
        if unsupported_features:
            for feature in unsupported_features:
                validation_errors.append(f"Unsupported CUDA feature detected: {feature}")

        # 3. Check shared memory limits
        shared_memory_size = self._get_kernel_shared_memory_size(kernel)
        if shared_memory_size > self.metal_limits['max_total_threadgroup_memory']:
            validation_errors.append(
                f"Shared memory usage ({shared_memory_size} bytes) exceeds Metal limit "
                f"({self.metal_limits['max_total_threadgroup_memory']} bytes)"
            )

        # 4. Check parameter count (Metal has a limit of 31 buffer arguments)
        if len(kernel.parameters) > self.metal_limits['max_buffer_size']:
            validation_errors.append(
                f"Kernel {kernel.name} has {len(kernel.parameters)} parameters, exceeding "
                f"Metal's limit of {self.metal_limits['max_buffer_size']}"
            )

        # Report all validation errors at once
        if validation_errors:
            error_msg = f"Kernel {kernel.name} validation failed:\n" + "\n".join(
                f"- {error}" for error in validation_errors
            )
            raise CudaTranslationError(error_msg)

    def _detect_unsupported_features(self, kernel: CUDAKernel) -> List[str]:
        """
        Detect CUDA features not supported in Metal.

        Args:
            kernel: CUDA kernel to check

        Returns:
            List[str]: List of unsupported features found
        """
        unsupported_features = []

        # Traverse the kernel AST to detect unsupported features
        for node in kernel.traverse():
            # 1. Check for dynamic parallelism (launching kernels from kernels)
            if isinstance(node, CUDAExpressionNode) and hasattr(node, 'function'):
                func_name = getattr(node, 'function', '')
                if func_name and any(name in func_name for name in ['cudaLaunch', 'cuLaunch']):
                    unsupported_features.append(f"Dynamic parallelism ({func_name})")

            # 2. Check for texture 3D operations (limited support in Metal)
            if isinstance(node, CUDAExpressionNode) and hasattr(node, 'function'):
                func_name = getattr(node, 'function', '')
                if func_name and 'tex3D' in func_name:
                    unsupported_features.append(f"3D texture operations ({func_name})")

            # 3. Check for CUDA driver API calls (not supported in kernel)
            if isinstance(node, CUDAExpressionNode) and hasattr(node, 'function'):
                func_name = getattr(node, 'function', '')
                if func_name and func_name.startswith('cu') and not func_name.startswith('cuda'):
                    unsupported_features.append(f"CUDA driver API call ({func_name})")

        # Return all detected unsupported features
        return unsupported_features

    def _get_kernel_shared_memory_size(self, kernel: CUDAKernel) -> int:
        """
        Calculate total shared memory usage of a kernel.

        Args:
            kernel: CUDA kernel

        Returns:
            int: Total shared memory size in bytes
        """
        total_size = 0

        # Sum up all shared memory declarations
        for node in kernel.traverse():
            if isinstance(node, CUDASharedMemory):
                # Get the element size based on the data type
                element_size = self._get_type_size(node.data_type)
                # Get the array size (number of elements)
                array_size = getattr(node, 'size', 1)
                # Add to total
                total_size += element_size * array_size

        return total_size

    def _get_type_size(self, type_name: str) -> int:
        """
        Get size in bytes of a CUDA data type.

        Args:
            type_name: CUDA type name

        Returns:
            int: Size in bytes
        """
        # Map common CUDA types to their sizes
        type_sizes = {
            'char': 1,
            'unsigned char': 1,
            'short': 2,
            'unsigned short': 2,
            'int': 4,
            'unsigned int': 4,
            'long': 4,  # 32-bit in Metal
            'unsigned long': 4,  # 32-bit in Metal
            'long long': 8,
            'unsigned long long': 8,
            'float': 4,
            'double': 8,  # Note: Metal uses float for double
            'bool': 1
        }

        # Check for vector types
        if is_vector_type(type_name):
            base_type = get_vector_component_type(type_name)
            vector_size = get_vector_size(type_name)
            base_size = type_sizes.get(base_type, 4)  # Default to 4 bytes if unknown
            return base_size * vector_size

        # Return size for basic type or default to 4 bytes
        return type_sizes.get(type_name, 4)

    def _get_kernel_thread_dimensions(self, kernel: CUDAKernel) -> Tuple[int, int, int]:
        """
        Extract thread dimensions from kernel properties.

        Args:
            kernel: CUDA kernel

        Returns:
            Tuple[int, int, int]: Thread dimensions (x, y, z)
        """
        # Default dimensions
        dimensions = (256, 1, 1)

        # Try to extract from kernel attributes if available
        if hasattr(kernel, 'block_dim'):
            dimensions = kernel.block_dim
        elif hasattr(kernel, 'max_threads_per_block'):
            # If only max threads is specified, use a 1D configuration
            max_threads = kernel.max_threads_per_block
            dimensions = (max_threads, 1, 1)

        return dimensions

    def _generate_metal_signature(self, kernel: CUDAKernel) -> str:
        """
        Generate Metal kernel signature with proper attributes and parameters.

        Args:
            kernel: CUDA kernel

        Returns:
            str: Metal kernel function signature
        """
        # Start with kernel keyword and return type
        signature = "kernel void "

        # Add kernel name
        signature += kernel.name

        # Generate parameter list
        params = []

        # Track buffer index for binding slots
        buffer_index = 0

        # Add kernel parameters with proper Metal qualifiers and binding attributes
        for param in kernel.parameters:
            metal_param = self._translate_kernel_parameter(param, buffer_index)
            params.append(metal_param)
            buffer_index += 1

        # Add built-in Metal parameters for thread indexing
        thread_params = [
            "uint3 thread_position_in_grid [[thread_position_in_grid]]",
            "uint3 threadgroup_position_in_grid [[threadgroup_position_in_grid]]",
            "uint3 thread_position_in_threadgroup [[thread_position_in_threadgroup]]",
            "uint3 threadgroup_size [[threads_per_threadgroup]]"
        ]

        # Add thread parameters
        params.extend(thread_params)

        # Complete the signature with parameters
        signature += "(\n    " + ",\n    ".join(params) + "\n)"

        return signature

    def _translate_kernel_parameter(self, param: CUDAParameter, buffer_index: int) -> str:
        """
        Translate a CUDA kernel parameter to Metal.

        Args:
            param: CUDA parameter
            buffer_index: Buffer binding index

        Returns:
            str: Metal parameter declaration
        """
        # Get Metal type for parameter
        metal_type = map_cuda_type_to_metal(param.param_type)

        # Determine address space qualifier
        address_space = ""
        if param.is_pointer:
            # Default to device address space for pointers
            address_space = "device "

            # Check for const qualifier
            if CUDAQualifier.CONST in param.qualifiers:
                address_space = "constant "

        # Build parameter declaration
        if param.is_pointer:
            # Add buffer binding attribute for pointers
            return f"{address_space}{metal_type}* {param.name} [[buffer({buffer_index})]]"
        else:
            # Value parameters (like int, float, etc.)
            return f"constant {metal_type}& {param.name} [[buffer({buffer_index})]]"

    def _translate_kernel_body(self, kernel: CUDAKernel) -> str:
        """
        Translate CUDA kernel body to Metal.

        Args:
            kernel: CUDA kernel

        Returns:
            str: Translated Metal kernel body
        """
        body_lines = []

        # Add thread index mapping for compatibility
        body_lines.append(self._generate_thread_index_mapping())

        # Add shared memory declarations
        shared_mem_decls = []
        for node in kernel.traverse():
            if isinstance(node, CUDASharedMemory):
                shared_mem_decls.append(self._translate_shared_memory(node))

        if shared_mem_decls:
            body_lines.append("\n    // Shared memory declarations")
            body_lines.extend(shared_mem_decls)

        # Translate each statement in the kernel body
        body_lines.append("\n    // Kernel implementation")
        for stmt in kernel.body:
            translated = self._translate_statement(stmt)
            body_lines.append(translated)

        # Join lines with proper indentation
        return "\n    ".join([""] + body_lines)  # Empty string for initial newline after brace

    def _generate_thread_index_mapping(self) -> str:
        """
        Generate CUDA-to-Metal thread index mapping for compatibility.

        Returns:
            str: Thread mapping code
        """
        # Define thread index mappings for CUDA compatibility
        mappings = [
            "// CUDA thread indexing compatibility",
            "const uint3 blockIdx = threadgroup_position_in_grid;",
            "const uint3 threadIdx = thread_position_in_threadgroup;",
            "const uint3 blockDim = threadgroup_size;",
            "const uint3 gridDim = (thread_position_in_grid + threadgroup_size - 1) / threadgroup_size;",
            "const uint globalIdx = thread_position_in_grid.x + thread_position_in_grid.y * gridDim.x * blockDim.x + thread_position_in_grid.z * gridDim.x * gridDim.y * blockDim.x * blockDim.y;"
        ]

        # Add SIMD lane and group calculation for warp-level operations
        mappings.extend([
            "",
            "// SIMD group calculations for warp-level operations",
            "const uint simdLaneId = thread_position_in_threadgroup.x & 0x1F;",  # 0x1F = 31, for 32-wide SIMD
            "const uint simdGroupId = thread_position_in_threadgroup.x >> 5;"    # Divide by 32
        ])

        return "\n    ".join(mappings)

    def _translate_shared_memory(self, node: CUDASharedMemory) -> str:
        """
        Translate CUDA shared memory declaration to Metal threadgroup memory.

        Args:
            node: CUDA shared memory node

        Returns:
            str: Metal threadgroup memory declaration
        """
        # Track feature usage
        self.used_features.add("threadgroup_memory")

        # Map CUDA type to Metal type
        metal_type = map_cuda_type_to_metal(node.data_type)

        # Use threadgroup address space for shared memory
        return f"threadgroup {metal_type} {node.name}[{node.size}];  // CUDA shared memory"

    def _translate_statement(self, stmt: CUDAStatement, indent: int = 0) -> str:
        """
        Translate a CUDA statement to Metal code with proper indentation.

        Args:
            stmt: CUDA statement
            indent: Indentation level

        Returns:
            str: Translated Metal statement
        """
        # Create indentation prefix
        indent_str = "    " * indent

        # Translate based on statement type
        if stmt.kind == "compound":
            return self._translate_compound_statement(stmt, indent)
        elif stmt.kind == "if":
            return self._translate_if_statement(stmt, indent)
        elif stmt.kind == "for":
            return self._translate_for_statement(stmt, indent)
        elif stmt.kind == "while":
            return self._translate_while_statement(stmt, indent)
        elif stmt.kind == "return":
            return self._translate_return_statement(stmt, indent)
        elif stmt.kind == "declaration":
            return self._translate_declaration_statement(stmt, indent)
        elif stmt.kind == "call":
            return self._translate_call_statement(stmt, indent)
        else:
            # Default for other statement types
            return f"{indent_str}// Unhandled statement type: {stmt.kind}"

    def _translate_compound_statement(self, stmt: CUDAStatement, indent: int) -> str:
    """
    Translate a compound statement (block) with proper scope management.

    Args:
        stmt: CUDA compound statement
        indent: Indentation level

    Returns:
        str: Translated Metal compound statement
    """
    indent_str = "    " * indent

    lines = [f"{indent_str}{{  // Compound statement begin"]

    # Translate each child statement with increased indentation
    for child in stmt.children:
        child_translation = self._translate_statement(child, indent + 1)
    # Ensure each child has proper indentation
    if child_translation:
        lines.append(child_translation)

    # Close the block
    lines.append(f"{indent_str}}}  // Compound statement end")

    # Join all lines
    return "\n".join(lines)

    def _translate_if_statement(self, stmt: CUDAStatement, indent: int) -> str:
        """
        Translate an if statement with condition and branches.

        Args:
            stmt: CUDA if statement
            indent: Indentation level

        Returns:
            str: Translated Metal if statement
        """
        indent_str = "    " * indent

        # Translate condition
        condition = self._translate_expression(stmt.condition) if hasattr(stmt, 'condition') and stmt.condition else "true"

        lines = [f"{indent_str}if ({condition}) {{"]

        # Translate then branch
        if hasattr(stmt, 'then_branch') and stmt.then_branch:
            for child in stmt.then_branch:
                translated = self._translate_statement(child, indent + 1)
                if translated:
                    lines.append(translated)

        lines.append(f"{indent_str}}}")

        # Translate else branch if present
        if hasattr(stmt, 'else_branch') and stmt.else_branch:
            lines.append(f"{indent_str}else {{")
            for child in stmt.else_branch:
                translated = self._translate_statement(child, indent + 1)
                if translated:
                    lines.append(translated)
            lines.append(f"{indent_str}}}")

        # Join with proper indentation
        return "\n".join(lines)

    def _translate_for_statement(self, stmt: CUDAStatement, indent: int) -> str:
        """
        Translate a for loop with appropriate Metal semantics.

        Args:
            stmt: CUDA for statement
            indent: Indentation level

        Returns:
            str: Translated Metal for statement
        """
        indent_str = "    " * indent

        # Translate initialization, condition, and increment
        init = self._translate_expression(stmt.init) if hasattr(stmt, 'init') and stmt.init else ""
        condition = self._translate_expression(stmt.condition) if hasattr(stmt, 'condition') and stmt.condition else "true"
        increment = self._translate_expression(stmt.increment) if hasattr(stmt, 'increment') and stmt.increment else ""

        # Check if loop is a candidate for unrolling
        if self.optimization_level >= 2 and self._is_unrollable_loop(stmt):
            return self._generate_unrolled_loop(stmt, indent)

        # Standard for loop
        lines = [f"{indent_str}for ({init}; {condition}; {increment}) {{"]

        # Translate loop body
        if hasattr(stmt, 'body') and stmt.body:
            for child in stmt.body:
                translated = self._translate_statement(child, indent + 1)
                if translated:
                    lines.append(translated)

        lines.append(f"{indent_str}}}")

        # Join with proper indentation
        return "\n".join(lines)

    def _is_unrollable_loop(self, stmt: CUDAStatement) -> bool:
        """
        Determine if a for loop is a candidate for unrolling.

        Args:
            stmt: CUDA for statement

        Returns:
            bool: True if loop can be unrolled
        """
        # Only attempt unrolling if optimization level is sufficient
        if self.optimization_level < 2:
            return False

        # Loop must have constant bounds to be unrollable
        try:
            # Check if initialization, condition, and increment match unrollable pattern
            if (hasattr(stmt, 'init') and hasattr(stmt, 'condition') and
                    hasattr(stmt, 'increment') and stmt.init and stmt.condition and stmt.increment):

                # Try to extract loop bounds (simplified check)
                # In a real implementation, this would be more sophisticated
                return False  # Placeholder - real implementation would analyze loop structure

            return False
        except:
            # If any analysis fails, don't unroll
            return False

    def _generate_unrolled_loop(self, stmt: CUDAStatement, indent: int) -> str:
        """
        Generate an unrolled version of a for loop.

        Args:
            stmt: CUDA for statement
            indent: Indentation level

        Returns:
            str: Unrolled loop implementation
        """
        indent_str = "    " * indent

        # This would be implemented with actual loop bound analysis and unrolling
        # For now, just add a comment indicating the potential optimization
        return f"{indent_str}// Loop unrolling optimization would be applied here\n" + self._translate_for_statement(stmt, indent)

    def _translate_while_statement(self, stmt: CUDAStatement, indent: int) -> str:
        """
        Translate a while loop to Metal.

        Args:
            stmt: CUDA while statement
            indent: Indentation level

        Returns:
            str: Translated Metal while statement
        """
        indent_str = "    " * indent

        # Translate condition
        condition = self._translate_expression(stmt.condition) if hasattr(stmt, 'condition') and stmt.condition else "true"

        lines = [f"{indent_str}while ({condition}) {{"]

        # Translate loop body
        if hasattr(stmt, 'body') and stmt.body:
            for child in stmt.body:
                translated = self._translate_statement(child, indent + 1)
                if translated:
                    lines.append(translated)

        lines.append(f"{indent_str}}}")

        # Join with proper indentation
        return "\n".join(lines)

    def _translate_return_statement(self, stmt: CUDAStatement, indent: int) -> str:
        """
        Translate a return statement to Metal.

        Args:
            stmt: CUDA return statement
            indent: Indentation level

        Returns:
            str: Translated Metal return statement
        """
        indent_str = "    " * indent

        # Translate return expression if present
        if hasattr(stmt, 'expression') and stmt.expression:
            expr = self._translate_expression(stmt.expression)
            return f"{indent_str}return {expr};"
        else:
            return f"{indent_str}return;"

    def _translate_declaration_statement(self, stmt: CUDAStatement, indent: int) -> str:
        """
        Translate variable declarations to Metal.

        Args:
            stmt: CUDA declaration statement
            indent: Indentation level

        Returns:
            str: Translated Metal declaration(s)
        """
        indent_str = "    " * indent
        declarations = []

        # Translate each variable declaration
        for child in stmt.children:
            if hasattr(child, 'var_type') and hasattr(child, 'name'):
                # Map CUDA type to Metal type
                metal_type = map_cuda_type_to_metal(child.var_type)

                # Add appropriate address space qualifier
                addr_space = ""
                if hasattr(child, 'is_pointer') and child.is_pointer:
                    # Default thread address space for local pointers
                    addr_space = "thread "
                elif hasattr(child, 'qualifiers'):
                    if CUDAQualifier.SHARED in child.qualifiers:
                        addr_space = "threadgroup "
                        self.used_features.add("threadgroup_memory")
                    elif CUDAQualifier.CONST in child.qualifiers:
                        addr_space = "constant "

                # Generate declaration with or without initialization
                if hasattr(child, 'is_pointer') and child.is_pointer:
                    declarations.append(f"{indent_str}{addr_space}{metal_type}* {child.name};")
                else:
                    declarations.append(f"{indent_str}{addr_space}{metal_type} {child.name};")

        return "\n".join(declarations)

    def _translate_call_statement(self, stmt: CUDAStatement, indent: int) -> str:
        """
        Translate a function call statement to Metal.

        Args:
            stmt: CUDA call statement
            indent: Indentation level

        Returns:
            str: Translated Metal function call
        """
        indent_str = "    " * indent

        # Special handling for common CUDA functions
        if hasattr(stmt, 'expression') and hasattr(stmt.expression, 'spelling'):
            func_name = stmt.expression.spelling

            # Handle barrier synchronization
            if func_name == "__syncthreads":
                self.used_features.add("barrier")
                return f"{indent_str}threadgroup_barrier(mem_flags::mem_threadgroup);  // __syncthreads()"

        # Translate the call expression
        if hasattr(stmt, 'expression'):
            expr = self._translate_expression(stmt.expression)
            return f"{indent_str}{expr};"

        return f"{indent_str}// Unknown call statement"

    def _translate_expression(self, expr: Optional[CUDAExpressionNode]) -> str:
        """
        Translate a CUDA expression to Metal with comprehensive type handling.

        Args:
            expr: CUDA expression node

        Returns:
            str: Translated Metal expression
        """
        if expr is None:
            return ""

        # Handle different expression types
        if hasattr(expr, 'kind'):
            kind = getattr(expr, 'kind', '')

            if kind == "BINARY_OPERATOR" or kind == "binary_operator":
                return self._translate_binary_operator(expr)
            elif kind == "UNARY_OPERATOR" or kind == "unary_operator":
                return self._translate_unary_operator(expr)
            elif kind == "CALL_EXPR" or kind == "call_expr":
                return self._translate_call_expr(expr)
            elif kind == "DECL_REF_EXPR" or kind == "decl_ref_expr":
                return self._translate_decl_ref_expr(expr)
            elif kind == "INTEGER_LITERAL" or kind == "integer_literal":
                return str(getattr(expr, 'value', 0))
            elif kind == "FLOATING_LITERAL" or kind == "floating_literal":
                return str(getattr(expr, 'value', 0.0))
            elif kind == "ARRAY_SUBSCRIPT_EXPR" or kind == "array_subscript_expr":
                return self._translate_array_subscript(expr)
            elif kind == "MEMBER_EXPR" or kind == "member_expr":
                return self._translate_member_expr(expr)

        # Default case - use spelling if available
        if hasattr(expr, 'spelling') and expr.spelling:
            return expr.spelling

        return "/* Untranslated expression */"

    def _translate_binary_operator(self, expr: CUDAExpressionNode) -> str:
        """
        Translate a binary operator expression to Metal.

        Args:
            expr: CUDA binary operator expression

        Returns:
            str: Translated Metal binary expression
        """
        # Get left and right operands
        left = self._translate_expression(expr.left) if hasattr(expr, 'left') and expr.left else ""
        right = self._translate_expression(expr.right) if hasattr(expr, 'right') and expr.right else ""

        # Get operator
        operator = expr.operator if hasattr(expr, 'operator') and expr.operator else ""

        # Map CUDA operators to Metal if needed
        metal_operator = operator  # Default to same operator

        # Handle special cases
        if operator == "/":
            # Check if we're dividing integers and need to ensure floating-point division
            if self._is_integer_expr(expr.left) and self._is_integer_expr(expr.right):
                # In CUDA, integer division works as expected, but Metal might need explicit casting
                # for more accurate behavior
                return f"({left} / float({right}))"

        # Return the composed expression
        return f"({left} {metal_operator} {right})"

    def _is_integer_expr(self, expr: Optional[CUDAExpressionNode]) -> bool:
        """
        Determine if an expression is of integer type (for division handling).

        Args:
            expr: CUDA expression node

        Returns:
            bool: True if expression is likely integer type
        """
        if expr is None:
            return False

        # Check if expression has type information
        if hasattr(expr, 'type'):
            type_str = getattr(expr, 'type', '')
            return any(int_type in type_str for int_type in
                       ['int', 'long', 'short', 'char', 'unsigned'])

        # If we can't determine, assume not integer to be safe
        return False

    def _translate_unary_operator(self, expr: CUDAExpressionNode) -> str:
        """
        Translate a unary operator expression to Metal.

        Args:
            expr: CUDA unary operator expression

        Returns:
            str: Translated Metal unary expression
        """
        # Get operand
        operand = self._translate_expression(expr.operand) if hasattr(expr, 'operand') and expr.operand else ""

        # Get operator
        operator = expr.operator if hasattr(expr, 'operator') and expr.operator else ""

        # Handle special cases
        if not operator:
            return operand

        # Prefix vs. postfix operators
        if operator in ["++", "--"]:
            # CUDA supports both prefix and postfix forms
            # Check for prefix vs postfix (simplified - real impl would be position-aware)
            # Default to prefix for now
            return f"{operator}{operand}"
        else:
            # Standard prefix operator
            return f"{operator}({operand})"

    def _translate_call_expr(self, expr: CUDAExpressionNode) -> str:
        """
        Translate a function call expression to Metal with careful argument handling.

        Args:
            expr: CUDA function call expression

        Returns:
            str: Translated Metal function call
        """
        # Get function name
        func_name = expr.function if hasattr(expr, 'function') and expr.function else ""
        if not func_name and hasattr(expr, 'spelling'):
            func_name = expr.spelling

        # Special handling for CUDA built-in functions
        metal_func_name = self._map_cuda_function_to_metal(func_name)

        # Get arguments
        args = []
        if hasattr(expr, 'arguments'):
            for arg in expr.arguments:
                args.append(self._translate_expression(arg))

        # Handle special cases for atomic operations
        if metal_func_name.startswith("atomic_") and metal_func_name.endswith("_explicit"):
            # Metal atomic operations require memory ordering
            args.append("memory_order_relaxed")
            self.used_features.add("atomic")

        # Return the function call
        return f"{metal_func_name}({', '.join(args)})"

    def _translate_decl_ref_expr(self, expr: CUDAExpressionNode) -> str:
        """
        Translate a declaration reference expression with thread index handling.

        Args:
            expr: CUDA declaration reference expression

        Returns:
            str: Translated Metal reference
        """
        # Handle special CUDA variables
        if hasattr(expr, 'spelling'):
            spelling = expr.spelling

            # Thread indexing
            thread_idx_map = {
                "threadIdx.x": "thread_position_in_threadgroup.x",
                "threadIdx.y": "thread_position_in_threadgroup.y",
                "threadIdx.z": "thread_position_in_threadgroup.z",
                "blockIdx.x": "threadgroup_position_in_grid.x",
                "blockIdx.y": "threadgroup_position_in_grid.y",
                "blockIdx.z": "threadgroup_position_in_grid.z",
                "blockDim.x": "threadgroup_size.x",
                "blockDim.y": "threadgroup_size.y",
                "blockDim.z": "threadgroup_size.z",
                "gridDim.x": "gridDim.x",  # Using our pre-calculated value
                "gridDim.y": "gridDim.y",
                "gridDim.z": "gridDim.z",
                "warpSize": "32"  # Metal SIMD width is typically 32
            }

            if spelling in thread_idx_map:
                return thread_idx_map[spelling]

            # Default to the original spelling
            return spelling

        return "/* Unknown reference */"

    def _translate_array_subscript(self, expr: CUDAExpressionNode) -> str:
        """
        Translate an array subscript expression to Metal.

        Args:
            expr: CUDA array subscript expression

        Returns:
            str: Translated Metal array access
        """
        # Get array base and index expressions
        base = self._translate_expression(expr.base) if hasattr(expr, 'base') and expr.base else ""
        index = self._translate_expression(expr.index) if hasattr(expr, 'index') and expr.index else ""

        # Compose array access
        return f"{base}[{index}]"

    def _translate_member_expr(self, expr: CUDAExpressionNode) -> str:
        """
        Translate a member expression (struct/class field access) to Metal.

        Args:
            expr: CUDA member expression

        Returns:
            str: Translated Metal member access
        """
        # Get base and member name
        base = self._translate_expression(expr.base) if hasattr(expr, 'base') and expr.base else ""
        member = expr.member if hasattr(expr, 'member') and expr.member else ""

        # Check for arrow vs. dot operator
        operator = "->" if hasattr(expr, 'is_arrow') and expr.is_arrow else "."

        # Compose member access
        return f"{base}{operator}{member}"

    def _map_cuda_function_to_metal(self, func_name: str) -> str:
        """
        Map CUDA built-in function to Metal equivalent with comprehensive coverage.

        Args:
            func_name: CUDA function name

        Returns:
            str: Metal equivalent function name
        """
        # Check common CUDA functions and intrinsics
        cuda_to_metal_func = {
            # Math functions
            "__sinf": "sin",
            "__cosf": "cos",
            "__tanf": "tan",
            "__asinf": "asin",
            "__acosf": "acos",
            "__atanf": "atan",
            "__expf": "exp",
            "__exp2f": "exp2",
            "__logf": "log",
            "__log2f": "log2",
            "__log10f": "log10",
            "__powf": "pow",
            "__sqrtf": "sqrt",
            "__rsqrtf": "rsqrt",
            "__fabsf": "fabs",
            "__floorf": "floor",
            "__ceilf": "ceil",
            "__truncf": "trunc",
            "__roundf": "round",
            "__fminf": "fmin",
            "__fmaxf": "fmax",
            "__fmodf": "fmod",

            # Fast math variants - Metal provides fast:: namespace
            "sinf": "metal::fast::sin",
            "cosf": "metal::fast::cos",
            "tanf": "metal::fast::tan",
            "expf": "metal::fast::exp",
            "logf": "metal::fast::log",
            "sqrtf": "metal::fast::sqrt",

            # Synchronization
            "__syncthreads": "threadgroup_barrier(mem_flags::mem_threadgroup)",
            "__threadfence": "threadgroup_barrier(mem_flags::mem_device)",
            "__threadfence_block": "threadgroup_barrier(mem_flags::mem_threadgroup)",

            # Atomic operations
            "atomicAdd": "atomic_fetch_add_explicit",
            "atomicSub": "atomic_fetch_sub_explicit",
            "atomicExch": "atomic_exchange_explicit",
            "atomicMin": "atomic_fetch_min_explicit",
            "atomicMax": "atomic_fetch_max_explicit",
            "atomicAnd": "atomic_fetch_and_explicit",
            "atomicOr": "atomic_fetch_or_explicit",
            "atomicXor": "atomic_fetch_xor_explicit",
            "atomicCAS": "atomic_compare_exchange_weak_explicit",

            # Warp/SIMD functions
            "__ballot": "simd_ballot",
            "__all": "simd_all",
            "__any": "simd_any",
            "__shfl": "simd_shuffle",
            "__shfl_up": "simd_shuffle_up",
            "__shfl_down": "simd_shuffle_down",
            "__shfl_xor": "simd_shuffle_xor",

            # Bit manipulation
            "__popc": "popcount",
            "__clz": "clz",
            "__ffs": "ctz",

            # Vector type constructors
            "make_float2": "float2",
            "make_float3": "float3",
            "make_float4": "float4",
            "make_int2": "int2",
            "make_int3": "int3",
            "make_int4": "int4",
            "make_uint2": "uint2",
            "make_uint3": "uint3",
            "make_uint4": "uint4"
        }

        # Return mapped function or original if no mapping exists
        if func_name in cuda_to_metal_func:
            mapped_func = cuda_to_metal_func[func_name]

            # Track feature usage for headers
            if "atomic_" in mapped_func:
                self.used_features.add("atomic")
            elif "simd_" in mapped_func:
                self.used_features.add("simd")
            elif "threadgroup_barrier" in mapped_func:
                self.used_features.add("barrier")
            elif "metal::fast::" in mapped_func:
                self.used_features.add("fast_math")

            return mapped_func

        # For unknown functions, keep original name and log a warning
        if func_name and not func_name.startswith(("__", "cuda", "CU")):
            logger.warning(f"Unknown CUDA function '{func_name}' - keeping original name")

        return func_name

    def _is_device_function(self, node: CUDANode) -> bool:
        """
        Check if node is a CUDA device function.

        Args:
            node: CUDA AST node

        Returns:
            bool: True if node is a device function
        """
        return (hasattr(node, 'is_device') and node.is_device and
                not hasattr(node, 'is_kernel'))

    def _is_constant_memory(self, node: CUDANode) -> bool:
        """
        Check if node is a CUDA constant memory declaration.

        Args:
            node: CUDA AST node

        Returns:
            bool: True if node is constant memory
        """
        return (hasattr(node, 'qualifiers') and
                CUDAQualifier.CONST in node.qualifiers)

    def _translate_device_function(self, node: CUDANode) -> str:
        """
        Translate a CUDA device function to Metal.

        Args:
            node: CUDA device function node

        Returns:
            str: Translated Metal function
        """
        # Similar to kernel translation but with device function specifics
        # Get function name and return type
        func_name = node.name if hasattr(node, 'name') else "device_func"
        return_type = map_cuda_type_to_metal(node.return_type) if hasattr(node, 'return_type') else "void"

        # Generate function signature
        signature = f"device {return_type} {func_name}("

        # Process parameters
        params = []
        for param in getattr(node, 'parameters', []):
            params.append(self._translate_device_function_parameter(param))

        if params:
            signature += ", ".join(params)

        signature += ")"

        # Generate function body
        body = []
        for stmt in getattr(node, 'body', []):
            body.append(self._translate_statement(stmt))

        # Combine signature and body
        func_def = f"{signature} {{\n    " + "\n    ".join(body) + "\n}}"

        return func_def

    def _translate_device_function_parameter(self, param: CUDAParameter) -> str:
        """
        Translate a device function parameter to Metal.

        Args:
            param: CUDA parameter

        Returns:
            str: Translated Metal parameter
        """
        # Map type to Metal
        metal_type = map_cuda_type_to_metal(param.param_type)

        # Determine address space
        if param.is_pointer:
            # Default to device address space for pointers
            addr_space = "device "
            if CUDAQualifier.CONST in param.qualifiers:
                addr_space = "constant "

            return f"{addr_space}{metal_type}* {param.name}"
        else:
            # Pass by value or reference based on type size
            return f"{metal_type} {param.name}"

    def _translate_constant_memory(self, node: CUDANode) -> str:
        """
        Translate CUDA constant memory to Metal.

        Args:
            node: CUDA constant memory node

        Returns:
            str: Translated Metal constant
        """
        # Get type and name
        var_type = map_cuda_type_to_metal(node.var_type) if hasattr(node, 'var_type') else "float"
        var_name = node.name if hasattr(node, 'name') else "const_var"

        # Generate constant declaration
        if hasattr(node, 'is_pointer') and node.is_pointer:
            return f"constant {var_type}* {var_name};"
        else:
            return f"constant {var_type} {var_name};"

    def _collect_required_features(self, root: CUDANode) -> None:
        """
        Collect all features used in the AST for header generation.

        Args:
            root: Root CUDA AST node
        """
        for node in root.traverse():
            # Check for shared memory usage
            if isinstance(node, CUDASharedMemory):
                self.used_features.add("threadgroup_memory")

            # Check for barrier synchronization
            if isinstance(node, CUDABarrier):
                self.used_features.add("barrier")

            # Check for atomic operations
            if (isinstance(node, CUDAExpressionNode) and
                    hasattr(node, 'function') and
                    node.function and
                    node.function.startswith("atomic")):
                self.used_features.add("atomic")

            # Check for SIMD/warp-level operations
            if (isinstance(node, CUDAExpressionNode) and
                    hasattr(node, 'function') and
                    node.function and
                    node.function.startswith(("__shfl", "__ballot", "__all", "__any"))):
                self.used_features.add("simd")

    def _generate_metal_headers(self) -> str:
        """
        Generate Metal header includes based on used features.

        Returns:
            str: Metal header declarations
        """
        headers = [
            "#include <metal_stdlib>",
            "using namespace metal;"
        ]

        # Add feature-specific headers
        if "atomic" in self.used_features:
            headers.insert(1, "#include <metal_atomic>")
            self.required_headers.add("metal_atomic")

        if "simd" in self.used_features:
            headers.insert(1, "#include <metal_simdgroup>")
            self.required_headers.add("metal_simdgroup")

        if "fast_math" in self.used_features:
            headers.insert(1, "#include <metal_math>")
            self.required_headers.add("metal_math")

        # Memory flags for barriers
        if "barrier" in self.used_features:
            headers.append("\n// Memory flags for barriers")
            headers.append("typedef enum {")
            headers.append("    mem_none        = 0,")
            headers.append("    mem_device      = 1,")
            headers.append("    mem_threadgroup = 2,")
            headers.append("    mem_texture     = 4")
            headers.append("} mem_flags;")

        # Add Metal version directive if needed
        if self.metal_target_version:
            major, minor = map(int, self.metal_target_version.split("."))
            headers.insert(0, f"#if __METAL_VERSION__ >= {major * 10000 + minor * 100}")
            headers.append(f"#endif // __METAL_VERSION__ >= {major * 10000 + minor * 100}")

        return "\n".join(headers)

    def _generate_utility_functions(self) -> str:
        """
        Generate Metal utility functions based on used features.

        Returns:
            str: Metal utility function implementations
        """
        utilities = []

        # Add CUDA-compatible functions as needed based on features
        if "atomic" in self.used_features:
            utilities.append(self._generate_atomic_utilities())

        if "simd" in self.used_features:
            utilities.append(self._generate_simd_utilities())

        if "threadgroup_memory" in self.used_features:
            utilities.append(self._generate_shared_memory_utilities())

        if utilities:
            return "\n\n// Utility functions for CUDA compatibility\n" + "\n\n".join(utilities)
        else:
            return ""

    def _generate_atomic_utilities(self) -> str:
        """
        Generate atomic operation utilities for CUDA compatibility.

        Returns:
            str: Metal atomic utility implementations
        """
        return """// Atomic operation wrappers for CUDA compatibility
    template<typename T>
    T atomicAdd(device atomic<T>* address, T val) {
        return atomic_fetch_add_explicit(address, val, memory_order_relaxed);
    }
    
    template<typename T>
    T atomicExch(device atomic<T>* address, T val) {
        return atomic_exchange_explicit(address, val, memory_order_relaxed);
    }
    
    template<typename T>
    T atomicMin(device atomic<T>* address, T val) {
        return atomic_fetch_min_explicit(address, val, memory_order_relaxed);
    }
    
    template<typename T>
    T atomicMax(device atomic<T>* address, T val) {
        return atomic_fetch_max_explicit(address, val, memory_order_relaxed);
    }
    
    template<typename T>
    T atomicAnd(device atomic<T>* address, T val) {
        return atomic_fetch_and_explicit(address, val, memory_order_relaxed);
    }
    
    template<typename T>
    T atomicOr(device atomic<T>* address, T val) {
        return atomic_fetch_or_explicit(address, val, memory_order_relaxed);
    }
    
    template<typename T>
    T atomicXor(device atomic<T>* address, T val) {
        return atomic_fetch_xor_explicit(address, val, memory_order_relaxed);
    }
    
    template<typename T>
    T atomicCAS(device atomic<T>* address, T compare, T val) {
        T expected = compare;
        atomic_compare_exchange_weak_explicit(address, &expected, val, memory_order_relaxed, memory_order_relaxed);
        return expected;
    }from typing import Dict, List, Optional, Set, Union, Any, Tuple
    import re
    from threading import Lock, RLock
    import logging
    import time
    from pathlib import Path
    import hashlib
    import traceback
    
    from ..utils.error_handler import CudaTranslationError, CudaParseError
    from ..utils.logger import get_logger
    from ..utils.metal_equivalents import get_metal_equivalent, translate_cuda_call_to_metal
    from ..utils.cuda_to_metal_type_mapping import (
        map_cuda_type_to_metal, is_vector_type, get_vector_component_type, get_vector_size
    )
    from ..utils.mapping_tables import (
        METAL_TYPES, METAL_FUNCTIONS, METAL_ATTRIBUTES, METAL_ADDRESS_SPACES,
        METAL_MEMORY_FLAGS, METAL_THREAD_MAPPING
    )
    from ..core.parser.ast_nodes import (
        CUDANode, CUDAKernel, CUDAParameter, CUDAType, CUDAQualifier,
        CUDAExpressionNode, CUDAStatement, CUDASharedMemory, CUDABarrier
    )
    
    logger = get_logger(__name__)
    
    class KernelTranslator:
        """
    Production-grade CUDA kernel translator with comprehensive Metal optimization support.
    Thread-safe implementation for high-performance translation pipelines.

    This class handles the translation of CUDA kernels into Metal Shading Language (MSL),
    including advanced optimizations and hardware-specific considerations for Apple Silicon.

    Features:
    - Thread-safe implementation with fine-grained locking
    - Smart caching for high-performance translation
        - Comprehensive error detection and reporting
    - Multi-level optimization pipeline
    - Hardware-aware translation targeting Apple M1/M2/M3 capabilities
    """
    
    def __init__(self, metal_target_version: str = "2.4", optimization_level: int = 2):
        """
    Initialize the KernelTranslator with specific optimization settings.

    Args:
    metal_target_version: Target Metal API version (defaults to 2.4)
    optimization_level: Optimization aggressiveness level (0-3, default 2)
    0: No optimizations
    1: Basic optimizations (memory coalescing, barrier optimizations)
    2: Intermediate optimizations (SIMD usage, loop unrolling)
    3: Aggressive optimizations (vectorization, memory layout)
    """
    # Thread safety - use RLock for re-entrancy support
    self._lock = RLock()
    
    # Translation state
    self._translation_cache: Dict[str, str] = {}
    self._kernel_metadata: Dict[str, Dict[str, Any]] = {}
    self._validation_cache: Dict[str, bool] = {}
    
    # Feature tracking
    self.used_features: Set[str] = set()
    self.required_headers: Set[str] = set()
    
    # Configuration
    self.metal_target_version = metal_target_version
    self.optimization_level = optimization_level
    
    # Initialize hardware-specific limits for Apple Silicon
    self.metal_limits = {
        'max_threads_per_group': 1024,
        'max_total_threadgroup_memory': 32768,  # 32KB
        'simd_width': 32,
        'max_threadgroups_per_grid': (65535, 65535, 65535),
        'max_buffer_size': 256 * 1024 * 1024,  # 256MB for typical devices
        'registers_per_threadgroup': 16384,
        'max_constant_buffer_size': 64 * 1024,  # 64KB
        'texture_buffer_alignment': 16
    }
    
    # Performance metrics
    self.metrics = {
        'translations': 0,
        'cache_hits': 0,
        'translation_time_total': 0.0,
        'validation_time_total': 0.0,
        'optimization_time_total': 0.0
    }
    
    logger.info(f"KernelTranslator initialized with Metal {metal_target_version} target "
                f"and optimization level {optimization_level}")
    
    def translate_kernel(self, kernel: CUDAKernel) -> str:
    """
    Translate a CUDA kernel function to Metal Shading Language (MSL).
    Thread-safe implementation with caching and profiling.

    Args:
    kernel: CUDA kernel AST node to translate

    Returns:
    str: Translated Metal shader function

    Raises:
    CudaTranslationError: If translation fails due to incompatible CUDA features
    CudaParseError: If AST node structure is invalid
    Exception: For other unexpected errors
    """
    try:
        # Generate cache key based on kernel hash and optimization level
        # This ensures different optimization levels get their own cache entries
        kernel_hash = self._compute_kernel_hash(kernel)
        cache_key = f"{kernel.name}:{kernel_hash}:{self.optimization_level}"
        
        # Check cache with proper locking
        with self._lock:
            if cache_key in self._translation_cache:
                self.metrics['cache_hits'] += 1
                logger.debug(f"Cache hit for kernel: {kernel.name}")
                return self._translation_cache[cache_key]
        
        # Performance tracking
        start_time = time.time()
        translation_start = start_time
        logger.info(f"Translating kernel: {kernel.name}")
        
        # Reset used features for this translation
        self.used_features = set()
        
        # Validation phase
        validation_start = time.time()
        self._validate_kernel(kernel)
        validation_time = time.time() - validation_start
        self.metrics['validation_time_total'] += validation_time
        
        # Step 1: Generate Metal kernel signature
        signature = self._generate_metal_signature(kernel)
        
        # Step 2: Generate kernel body
        body = self._translate_kernel_body(kernel)
        
        # Step 3: Apply optimizations based on level
        if self.optimization_level > 0:
            optimization_start = time.time()
            body = self._optimize_kernel_body(body, kernel)
            optimization_time = time.time() - optimization_start
            self.metrics['optimization_time_total'] += optimization_time
        
        # Step 4: Combine signature and body with proper spacing
        metal_kernel = f"{signature} {{\n{body}\n}}"
        
        # Step 5: Final validation
        self._validate_metal_code(metal_kernel)
        
        # Update metrics and cache result
        with self._lock:
            self.metrics['translations'] += 1
            self._translation_cache[cache_key] = metal_kernel
            
            # Store metadata about this kernel for later reference
            self._kernel_metadata[kernel.name] = {
                'thread_dimensions': self._get_kernel_thread_dimensions(kernel),
                'shared_memory_size': self._get_kernel_shared_memory_size(kernel),
                'used_features': self.used_features.copy(),
                'parameter_count': len(kernel.parameters),
                'translation_timestamp': time.time()
            }
        
        # Performance logging
        translation_time = time.time() - translation_start
        self.metrics['translation_time_total'] += translation_time
        logger.info(f"Successfully translated kernel {kernel.name} in {translation_time:.2f}s")
        
        return metal_kernel
        
    except CudaTranslationError as e:
        # Log and re-raise translation-specific errors
        logger.error(f"Translation error in kernel {kernel.name}: {str(e)}")
        raise
    except CudaParseError as e:
        # Log and re-raise parsing-specific errors
        logger.error(f"Parse error in kernel {kernel.name}: {str(e)}")
        raise
    except Exception as e:
        # Handle unexpected errors with detailed information
        error_msg = f"Unexpected error translating kernel {kernel.name}: {str(e)}"
        stack_trace = traceback.format_exc()
        logger.error(f"{error_msg}\n{stack_trace}")
        raise CudaTranslationError(error_msg)
    
    def translate_ast(self, root: CUDANode) -> str:
    """
    Translate an entire CUDA AST to Metal code.

    Args:
    root: CUDA AST root node

    Returns:
    str: Complete Metal shader file
    """
    metal_lines = []
    
    # Process all nodes and collect required features
    self._collect_required_features(root)
    
    # Generate appropriate Metal headers based on features
    metal_lines.append(self._generate_metal_headers())
    
    # Add any required utility functions based on used features
    utility_functions = self._generate_utility_functions()
    if utility_functions:
        metal_lines.append(utility_functions)
    
    # Translate each top-level CUDA entity
    device_functions = []
    kernels = []
    constants = []
    
    for node in root.children:
        if isinstance(node, CUDAKernel):
            # Translate kernel functions
            kernels.append(self.translate_kernel(node))
        elif self._is_device_function(node):
            # Translate device functions
            device_functions.append(self._translate_device_function(node))
        elif self._is_constant_memory(node):
            # Translate constant memory declarations
            constants.append(self._translate_constant_memory(node))
    
    # Add translations in proper order
    if constants:
        metal_lines.append("// Global Constants")
        metal_lines.extend(constants)
        metal_lines.append("")
    
    if device_functions:
        metal_lines.append("// Device Functions")
        metal_lines.extend(device_functions)
        metal_lines.append("")
    
    if kernels:
        metal_lines.append("// Kernel Functions")
        metal_lines.extend(kernels)
    
    return "\n".join(metal_lines)
    
    def _compute_kernel_hash(self, kernel: CUDAKernel) -> str:
    """
    Compute a hash of the kernel AST for caching purposes.

    Args:
    kernel: CUDA kernel AST node

    Returns:
    str: Hash of the kernel structure
    """
    # Create a string representation of the kernel
    kernel_repr = f"{kernel.name}:{kernel.line}:{kernel.column}"
    
    # Add parameter information
    for param in kernel.parameters:
        kernel_repr += f":{param.name}:{param.param_type}:{int(param.is_pointer)}"
    
    # Add body information (simplified)
    kernel_repr += f":{len(kernel.body)}"
    
    # Generate hash
    return hashlib.md5(kernel_repr.encode()).hexdigest()
    
    def _validate_kernel(self, kernel: CUDAKernel):
    """
    Validate kernel for Metal compatibility with comprehensive checks.

    Args:
    kernel: CUDA kernel to validate

    Raises:
    CudaTranslationError: If kernel contains features incompatible with Metal
    """
    validation_errors = []
    
    # 1. Check thread limits
    if hasattr(kernel, 'max_threads_per_block') and kernel.max_threads_per_block > self.metal_limits['max_threads_per_group']:
        validation_errors.append(
            f"Kernel {kernel.name} exceeds Metal's max threads per group limit "
            f"({kernel.max_threads_per_block} > {self.metal_limits['max_threads_per_group']})"
        )
    
    # 2. Check for unsupported memory operations
    unsupported_features = self._detect_unsupported_features(kernel)
    if unsupported_features:
        for feature in unsupported_features:
            validation_errors.append(f"Unsupported CUDA feature detected: {feature}")
    
    # 3. Check shared memory limits
    shared_memory_size = self._get_kernel_shared_memory_size(kernel)
    if shared_memory_size > self.metal_limits['max_total_threadgroup_memory']:
        validation_errors.append(
            f"Shared memory usage ({shared_memory_size} bytes) exceeds Metal limit "
            f"({self.metal_limits['max_total_threadgroup_memory']} bytes)"
        )
    
    # 4. Check parameter count (Metal has a limit of 31 buffer arguments)
    if len(kernel.parameters) > self.metal_limits['max_buffer_size']:
        validation_errors.append(
            f"Kernel {kernel.name} has {len(kernel.parameters)} parameters, exceeding "
            f"Metal's limit of {self.metal_limits['max_buffer_size']}"
        )
    
    # Report all validation errors at once
    if validation_errors:
        error_msg = f"Kernel {kernel.name} validation failed:\n" + "\n".join(
            f"- {error}" for error in validation_errors
        )
        raise CudaTranslationError(error_msg)
    
    def _detect_unsupported_features(self, kernel: CUDAKernel) -> List[str]:
    """
    Detect CUDA features not supported in Metal.

    Args:
    kernel: CUDA kernel to check

    Returns:
    List[str]: List of unsupported features found
    """
    unsupported_features = []
    
    # Traverse the kernel AST to detect unsupported features
    for node in kernel.traverse():
        # 1. Check for dynamic parallelism (launching kernels from kernels)
        if isinstance(node, CUDAExpressionNode) and hasattr(node, 'function'):
            func_name = getattr(node, 'function', '')
            if func_name and any(name in func_name for name in ['cudaLaunch', 'cuLaunch']):
                unsupported_features.append(f"Dynamic parallelism ({func_name})")
        
        # 2. Check for texture 3D operations (limited support in Metal)
        if isinstance(node, CUDAExpressionNode) and hasattr(node, 'function'):
            func_name = getattr(node, 'function', '')
            if func_name and 'tex3D' in func_name:
                unsupported_features.append(f"3D texture operations ({func_name})")
        
        # 3. Check for CUDA driver API calls (not supported in kernel)
        if isinstance(node, CUDAExpressionNode) and hasattr(node, 'function'):
            func_name = getattr(node, 'function', '')
            if func_name and func_name.startswith('cu') and not func_name.startswith('cuda'):
                unsupported_features.append(f"CUDA driver API call ({func_name})")
    
    # Return all detected unsupported features
    return unsupported_features
    
    def _get_kernel_shared_memory_size(self, kernel: CUDAKernel) -> int:
    """
    Calculate total shared memory usage of a kernel.

    Args:
    kernel: CUDA kernel

    Returns:
    int: Total shared memory size in bytes
    """
    total_size = 0
    
    # Sum up all shared memory declarations
    for node in kernel.traverse():
        if isinstance(node, CUDASharedMemory):
            # Get the element size based on the data type
            element_size = self._get_type_size(node.data_type)
            # Get the array size (number of elements)
            array_size = getattr(node, 'size', 1)
            # Add to total
            total_size += element_size * array_size
    
    return total_size
    
    def _get_type_size(self, type_name: str) -> int:
    """
    Get size in bytes of a CUDA data type.

    Args:
    type_name: CUDA type name

    Returns:
    int: Size in bytes
    """
    # Map common CUDA types to their sizes
    type_sizes = {
        'char': 1,
        'unsigned char': 1,
        'short': 2,
        'unsigned short': 2,
        'int': 4,
        'unsigned int': 4,
        'long': 4,  # 32-bit in Metal
        'unsigned long': 4,  # 32-bit in Metal
        'long long': 8,
        'unsigned long long': 8,
        'float': 4,
        'double': 8,  # Note: Metal uses float for double
        'bool': 1
    }
    
    # Check for vector types
    if is_vector_type(type_name):
        base_type = get_vector_component_type(type_name)
        vector_size = get_vector_size(type_name)
        base_size = type_sizes.get(base_type, 4)  # Default to 4 bytes if unknown
        return base_size * vector_size
    
    # Return size for basic type or default to 4 bytes
    return type_sizes.get(type_name, 4)
    
    def _get_kernel_thread_dimensions(self, kernel: CUDAKernel) -> Tuple[int, int, int]:
    """
    Extract thread dimensions from kernel properties.

    Args:
    kernel: CUDA kernel

    Returns:
    Tuple[int, int, int]: Thread dimensions (x, y, z)
    """
    # Default dimensions
    dimensions = (256, 1, 1)
    
    # Try to extract from kernel attributes if available
    if hasattr(kernel, 'block_dim'):
        dimensions = kernel.block_dim
    elif hasattr(kernel, 'max_threads_per_block'):
        # If only max threads is specified, use a 1D configuration
        max_threads = kernel.max_threads_per_block
        dimensions = (max_threads, 1, 1)
    
    return dimensions
    
    def _generate_metal_signature(self, kernel: CUDAKernel) -> str:
    """
    Generate Metal kernel signature with proper attributes and parameters.

    Args:
    kernel: CUDA kernel

    Returns:
    str: Metal kernel function signature
    """
    # Start with kernel keyword and return type
    signature = "kernel void "
    
    # Add kernel name
    signature += kernel.name
    
    # Generate parameter list
    params = []
    
    # Track buffer index for binding slots
    buffer_index = 0
    
    # Add kernel parameters with proper Metal qualifiers and binding attributes
    for param in kernel.parameters:
        metal_param = self._translate_kernel_parameter(param, buffer_index)
        params.append(metal_param)
        buffer_index += 1
    
    # Add built-in Metal parameters for thread indexing
    thread_params = [
        "uint3 thread_position_in_grid [[thread_position_in_grid]]",
        "uint3 threadgroup_position_in_grid [[threadgroup_position_in_grid]]",
        "uint3 thread_position_in_threadgroup [[thread_position_in_threadgroup]]",
        "uint3 threadgroup_size [[threads_per_threadgroup]]"
    ]
    
    # Add thread parameters
    params.extend(thread_params)
    
    # Complete the signature with parameters
    signature += "(\n    " + ",\n    ".join(params) + "\n)"
    
    return signature
    
    def _translate_kernel_parameter(self, param: CUDAParameter, buffer_index: int) -> str:
    """
    Translate a CUDA kernel parameter to Metal.

    Args:
    param: CUDA parameter
    buffer_index: Buffer binding index

    Returns:
    str: Metal parameter declaration
    """
    # Get Metal type for parameter
    metal_type = map_cuda_type_to_metal(param.param_type)
    
    # Determine address space qualifier
    address_space = ""
    if param.is_pointer:
        # Default to device address space for pointers
        address_space = "device "
        
        # Check for const qualifier
        if CUDAQualifier.CONST in param.qualifiers:
            address_space = "constant "
    
    # Build parameter declaration
    if param.is_pointer:
        # Add buffer binding attribute for pointers
        return f"{address_space}{metal_type}* {param.name} [[buffer({buffer_index})]]"
    else:
        # Value parameters (like int, float, etc.)
        return f"constant {metal_type}& {param.name} [[buffer({buffer_index})]]"
    
    def _translate_kernel_body(self, kernel: CUDAKernel) -> str:
    """
    Translate CUDA kernel body to Metal.

    Args:
    kernel: CUDA kernel

    Returns:
    str: Translated Metal kernel body
    """
    body_lines = []
    
    # Add thread index mapping for compatibility
    body_lines.append(self._generate_thread_index_mapping())
    
    # Add shared memory declarations
    shared_mem_decls = []
    for node in kernel.traverse():
        if isinstance(node, CUDASharedMemory):
            shared_mem_decls.append(self._translate_shared_memory(node))
    
    if shared_mem_decls:
        body_lines.append("\n    // Shared memory declarations")
        body_lines.extend(shared_mem_decls)
    
    # Translate each statement in the kernel body
    body_lines.append("\n    // Kernel implementation")
    for stmt in kernel.body:
        translated = self._translate_statement(stmt)
        body_lines.append(translated)
    
    # Join lines with proper indentation
    return "\n    ".join([""] + body_lines)  # Empty string for initial newline after brace
    
    def _generate_thread_index_mapping(self) -> str:
    """
    Generate CUDA-to-Metal thread index mapping for compatibility.

    Returns:
    str: Thread mapping code
    """
    # Define thread index mappings for CUDA compatibility
    mappings = [
        "// CUDA thread indexing compatibility",
        "const uint3 blockIdx = threadgroup_position_in_grid;",
        "const uint3 threadIdx = thread_position_in_threadgroup;",
        "const uint3 blockDim = threadgroup_size;",
        "const uint3 gridDim = (thread_position_in_grid + threadgroup_size - 1) / threadgroup_size;",
        "const uint globalIdx = thread_position_in_grid.x + thread_position_in_grid.y * gridDim.x * blockDim.x + thread_position_in_grid.z * gridDim.x * gridDim.y * blockDim.x * blockDim.y;"
    ]
    
    # Add SIMD lane and group calculation for warp-level operations
    mappings.extend([
        "",
        "// SIMD group calculations for warp-level operations",
        "const uint simdLaneId = thread_position_in_threadgroup.x & 0x1F;",  # 0x1F = 31, for 32-wide SIMD
        "const uint simdGroupId = thread_position_in_threadgroup.x >> 5;"    # Divide by 32
    ])
    
    return "\n    ".join(mappings)
    
    def _translate_shared_memory(self, node: CUDASharedMemory) -> str:
    """
    Translate CUDA shared memory declaration to Metal threadgroup memory.

    Args:
    node: CUDA shared memory node

    Returns:
    str: Metal threadgroup memory declaration
    """
    # Track feature usage
    self.used_features.add("threadgroup_memory")
    
    # Map CUDA type to Metal type
    metal_type = map_cuda_type_to_metal(node.data_type)
    
    # Use threadgroup address space for shared memory
    return f"threadgroup {metal_type} {node.name}[{node.size}];  // CUDA shared memory"
    
    def _translate_statement(self, stmt: CUDAStatement, indent: int = 0) -> str:
    """
    Translate a CUDA statement to Metal code with proper indentation.

    Args:
    stmt: CUDA statement
    indent: Indentation level

    Returns:
    str: Translated Metal statement
    """
    # Create indentation prefix
    indent_str = "    " * indent
    
    # Translate based on statement type
    if stmt.kind == "compound":
        return self._translate_compound_statement(stmt, indent)
    elif stmt.kind == "if":
        return self._translate_if_statement(stmt, indent)
    elif stmt.kind == "for":
        return self._translate_for_statement(stmt, indent)
    elif stmt.kind == "while":
        return self._translate_while_statement(stmt, indent)
    elif stmt.kind == "return":
        return self._translate_return_statement(stmt, indent)
    elif stmt.kind == "declaration":
        return self._translate_declaration_statement(stmt, indent)
    elif stmt.kind == "call":
        return self._translate_call_statement(stmt, indent)
    else:
        # Default for other statement types
        return f"{indent_str}// Unhandled statement type: {stmt.kind}"
    
    def _translate_compound_statement(self, stmt: CUDAStatement
Class: ('KernelTranslator', '')
--------------------------------------------------------------------------------
  Method: get(base_type, 4)
  Method: get(type_name, 4)
  Method: get(base_type, 4)
  Method: get(type_name, 4)

Class: ('KernelTranslator', '')
--------------------------------------------------------------------------------
  Method: get(base_type, 4)
  Method: get(type_name, 4)
  Method: get(base_type, 4)
  Method: get(type_name, 4)


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\examples\simple_vector_add\vector_add.py

from pathlib import Path
from CUDAM.parser.clang_integration import CUDAClangParser
from CUDAM.translator.host_translator import CUDAHostTranslator
from CUDAM.generator.metal_generator import MetalGenerator

def translate_cuda_to_metal(cuda_file: str):
    # Initialize components
    parser = CUDAClangParser()
    host_translator = CUDAHostTranslator()
    metal_generator = MetalGenerator()

    # Parse CUDA file
    cuda_ast = parser.parse_file(cuda_file)
    if not cuda_ast:
        print("Failed to parse CUDA file")
        return

    # Find kernel functions
    kernels = []
    def find_kernels(node):
        if hasattr(node, 'is_kernel') and node.is_kernel():
            kernels.append(node)
    cuda_ast.traverse(find_kernels)

    # Generate Metal code
    output_dir = Path('metal_output')
    output_dir.mkdir(exist_ok=True)

    # Generate kernel code
    for kernel in kernels:
        metal_code = metal_generator.generate_metal_code(kernel)
        kernel_file = output_dir / f"{kernel.name}.metal"
        kernel_file.write_text(metal_code)

    # Translate host code
    with open(cuda_file) as f:
        cuda_host_code = f.read()
    metal_host_code = host_translator.translate_host_code(cuda_host_code, target_lang='swift')
    host_file = output_dir / "host.swift"
    host_file.write_text(metal_host_code)

if __name__ == "__main__":
    cuda_file = "vector_add.cu"
    translate_cuda_to_metal(cuda_file)

--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\generator\msl_generator.py

from typing import Dict, List, Set, Optional, Union, Any
from pathlib import Path
import logging
from concurrent.futures import ThreadPoolExecutor
from threading import Lock

from ..utils.error_handler import CudaTranslationError
from ..utils.logger import get_logger
from ..utils.metal_equivalents import get_metal_equivalent
from ..utils.mapping_tables import MetalMappingRegistry
from ..core.parser.ast_nodes import (
    CUDAKernel, CUDANode, CUDAType, CUDAQualifier
)

logger = get_logger(__name__)

class MetalShaderGenerator:
    """
    Production-ready Metal shader generator with comprehensive optimization capabilities.
    Thread-safe implementation for parallel shader generation.
    """

    def __init__(self):
        self.mapping_registry = MetalMappingRegistry()
        self._lock = Lock()
        self._shader_cache: Dict[str, str] = {}
        self._function_registry: Dict[str, Dict[str, Any]] = {}
        self.executor = ThreadPoolExecutor(max_workers=4)

        # Initialize optimization flags
        self.optimization_flags = {
            'vectorize': True,
            'unroll_loops': True,
            'simd_groups': True,
            'memory_coalescing': True,
            'constant_folding': True,
            'barrier_optimization': True
        }

        # Metal-specific constraints
        self.METAL_LIMITS = {
            'max_threads_per_group': 1024,
            'max_total_threadgroup_memory': 32768,  # 32KB
            'simd_width': 32,
            'max_buffers': 31,
            'max_textures': 128
        }

    def generate_kernel(self, kernel: CUDAKernel, optimization_level: int = 2) -> str:
        """
        Generate optimized Metal kernel from CUDA kernel.

        Args:
            kernel: CUDA kernel AST node
            optimization_level: 0-3, higher means more aggressive optimization

        Returns:
            Optimized Metal shader code

        Raises:
            CudaTranslationError: If translation fails
        """
        try:
            # Check cache first
            cache_key = f"{kernel.name}_{optimization_level}"
            with self._lock:
                if cache_key in self._shader_cache:
                    return self._shader_cache[cache_key]

            # Validate kernel constraints
            self._validate_kernel(kernel)

            # Generate shader components
            signature = self._generate_kernel_signature(kernel)
            declarations = self._generate_declarations(kernel)
            body = self._generate_kernel_body(kernel, optimization_level)

            # Combine and optimize
            shader_code = self._optimize_shader(
                f"{signature}\n{{\n{declarations}\n{body}\n}}\n",
                optimization_level
            )

            # Cache result
            with self._lock:
                self._shader_cache[cache_key] = shader_code

            return shader_code

        except Exception as e:
            logger.error(f"Failed to generate Metal shader for kernel {kernel.name}: {str(e)}")
            raise CudaTranslationError(f"Shader generation failed: {str(e)}")

    def _validate_kernel(self, kernel: CUDAKernel) -> None:
        """Validate kernel against Metal constraints."""
        # Check thread dimensions
        thread_count = kernel.thread_count
        if thread_count > self.METAL_LIMITS['max_threads_per_group']:
            raise CudaTranslationError(
                f"Thread count {thread_count} exceeds Metal limit of {self.METAL_LIMITS['max_threads_per_group']}"
            )

        # Check shared memory usage
        shared_mem = kernel.shared_memory_size
        if shared_mem > self.METAL_LIMITS['max_total_threadgroup_memory']:
            raise CudaTranslationError(
                f"Shared memory usage {shared_mem} exceeds Metal limit of {self.METAL_LIMITS['max_total_threadgroup_memory']}"
            )

        # Validate buffer counts
        buffer_count = len(kernel.parameters)
        if buffer_count > self.METAL_LIMITS['max_buffers']:
            raise CudaTranslationError(
                f"Buffer count {buffer_count} exceeds Metal limit of {self.METAL_LIMITS['max_buffers']}"
            )

    def _generate_kernel_signature(self, kernel: CUDAKernel) -> str:
        """Generate Metal kernel signature with proper attributes."""
        params = []
        for idx, param in enumerate(kernel.parameters):
            metal_type = self.mapping_registry.get_metal_type(param.cuda_type)
            if not metal_type:
                raise CudaTranslationError(f"Unsupported type: {param.cuda_type}")

            # Determine proper parameter attributes
            if param.is_buffer:
                qualifier = "device" if not param.is_readonly else "constant"
                params.append(f"{qualifier} {metal_type.name}* {param.name} [[buffer({idx})]]")
            else:
                params.append(f"constant {metal_type.name}& {param.name} [[buffer({idx})]]")

        # Add threadgroup attributes
        thread_attrs = [
            "uint3 thread_position_in_grid [[thread_position_in_grid]]",
            "uint3 threadgroup_position [[threadgroup_position_in_grid]]",
            "uint3 threads_per_threadgroup [[threads_per_threadgroup]]"
        ]

        return f"kernel void {kernel.name}(\n    {',\n    '.join(params + thread_attrs)}\n)"

    def _generate_declarations(self, kernel: CUDAKernel) -> str:
        """Generate Metal declarations including threadgroup memory."""
        declarations = []

        # Add shared memory declarations
        for shared_var in kernel.shared_memory:
            metal_type = self.mapping_registry.get_metal_type(shared_var.cuda_type)
            if not metal_type:
                raise CudaTranslationError(f"Unsupported shared memory type: {shared_var.cuda_type}")

            declarations.append(
                f"    threadgroup {metal_type.name} {shared_var.name}[{shared_var.size}];"
            )

        # Add local variable declarations
        for local_var in kernel.local_variables:
            metal_type = self.mapping_registry.get_metal_type(local_var.cuda_type)
            if not metal_type:
                raise CudaTranslationError(f"Unsupported local variable type: {local_var.cuda_type}")

            declarations.append(
                f"    thread {metal_type.name} {local_var.name};"
            )

        return "\n".join(declarations)

    def _generate_kernel_body(self, kernel: CUDAKernel, optimization_level: int) -> str:
        """Generate optimized kernel body code."""
        # Apply pre-processing optimizations
        optimized_nodes = self._optimize_nodes(kernel.body, optimization_level)

        # Generate code for each node
        body_code = []
        for node in optimized_nodes:
            try:
                node_code = self._generate_node_code(node)
                if node_code:
                    body_code.extend(f"    {line}" for line in node_code.split('\n'))
            except Exception as e:
                logger.error(f"Failed to generate code for node: {str(e)}")
                raise CudaTranslationError(f"Code generation failed for node: {str(e)}")

        return "\n".join(body_code)

    def _optimize_nodes(self, nodes: List[CUDANode], optimization_level: int) -> List[CUDANode]:
        """Apply optimization passes to AST nodes."""
        if optimization_level == 0:
            return nodes

        optimizations = [
            self._optimize_memory_access,
            self._optimize_compute_intensity,
            self._optimize_control_flow,
            self._optimize_thread_divergence
        ]

        optimized = nodes
        for optimization in optimizations:
            if optimization_level >= 2:
                optimized = optimization(optimized)

        return optimized

    def _optimize_shader(self, shader_code: str, optimization_level: int) -> str:
        """Apply final optimization passes to generated shader code."""
        if optimization_level == 0:
            return shader_code

        # Apply progressive optimizations
        if optimization_level >= 1:
            shader_code = self._optimize_register_usage(shader_code)
            shader_code = self._optimize_memory_barriers(shader_code)

        if optimization_level >= 2:
            shader_code = self._optimize_simd_usage(shader_code)
            shader_code = self._optimize_memory_coalescing(shader_code)

        if optimization_level >= 3:
            shader_code = self._optimize_aggressive(shader_code)

        return shader_code

    def _optimize_register_usage(self, code: str) -> str:
        """Optimize register allocation and usage."""
        # Implement register optimization logic
        return code

    def _optimize_memory_barriers(self, code: str) -> str:
        """Optimize memory barrier placement."""
        # Implement barrier optimization logic
        return code

    def _optimize_simd_usage(self, code: str) -> str:
        """Optimize SIMD group usage."""
        # Implement SIMD optimization logic
        return code

    def _optimize_memory_coalescing(self, code: str) -> str:
        """Optimize memory access patterns."""
        # Implement memory coalescing logic
        return code

    def _optimize_aggressive(self, code: str) -> str:
        """Apply aggressive optimizations."""
        # Implement aggressive optimization logic
        return code

    def cleanup(self):
        """Cleanup resources."""
        self.executor.shutdown()
        with self._lock:
            self._shader_cache.clear()
            self._function_registry.clear()

# Additional helper classes for specific generation tasks

class MetalHeaderGenerator:
    """Generates Metal shader headers and type definitions."""

    def __init__(self, mapping_registry: MetalMappingRegistry):
        self.mapping_registry = mapping_registry

    def generate_header(self, required_types: Set[str]) -> str:
        """Generate Metal header with necessary type definitions."""
        header = [
            "#include <metal_stdlib>",
            "#include <metal_atomic>",
            "#include <metal_simdgroup>",
            "#include <metal_math>",
            "",
            "using namespace metal;",
            ""
        ]

        # Add required type definitions
        header.extend(self._generate_type_definitions(required_types))

        return "\n".join(header)

    def _generate_type_definitions(self, required_types: Set[str]) -> List[str]:
        """Generate necessary type definitions."""
        definitions = []
        for type_name in required_types:
            if metal_type := self.mapping_registry.get_metal_type(type_name):
                if metal_type.requires_header:
                    definitions.extend(self._generate_type_definition(metal_type))
        return definitions

    def _generate_type_definition(self, metal_type: Any) -> List[str]:
        """Generate definition for a specific type."""
        # Implementation for specific type definition generation
        return []

class MetalFunctionGenerator:
    """Generates Metal device and helper functions."""

    def __init__(self, mapping_registry: MetalMappingRegistry):
        self.mapping_registry = mapping_registry

    def generate_device_functions(self, required_functions: Set[str]) -> str:
        """Generate Metal device function implementations."""
        functions = []
        for func_name in required_functions:
            if metal_func := self.mapping_registry.get_metal_function(func_name):
                functions.append(self._generate_function_implementation(metal_func))

        return "\n\n".join(functions)

    def _generate_function_implementation(self, metal_func: Any) -> str:
        """Generate implementation for a specific function."""
        # Implementation for specific function generation
        return ""

# Usage example for the dumdums:
"""
generator = MetalShaderGenerator()
header_gen = MetalHeaderGenerator(generator.mapping_registry)
function_gen = MetalFunctionGenerator(generator.mapping_registry)

try:
    # Generate shader components
    metal_code = generator.generate_kernel(cuda_kernel, optimization_level=2)
    header = header_gen.generate_header(required_types)
    functions = function_gen.generate_device_functions(required_functions)

    # Combine into final shader
    final_shader = f"{header}\n\n{functions}\n\n{metal_code}"
    
except CudaTranslationError as e:
    logger.error(f"Shader generation failed: {str(e)}")
finally:
    generator.cleanup()
"""
Class: ('MetalShaderGenerator', '')
--------------------------------------------------------------------------------

Class: ('MetalHeaderGenerator', '')
--------------------------------------------------------------------------------

Class: ('MetalFunctionGenerator', '')
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\generator\objc_generator.py

from typing import Dict, List, Set, Optional, Union
from pathlib import Path
import logging
from threading import Lock

from ..utils.error_handler import CudaTranslationError
from ..utils.logger import get_logger
from ..parser.ast_nodes import CUDAKernel

logger = get_logger(__name__)

class ObjectiveCGenerator:
    """
    what this class features
    Features:
    - Thread-safe implementation
    - Comprehensive error handling
    - Automatic resource management
    - Performance optimization
    - Metal API compliance
    """

    def __init__(self):
        self._lock = Lock()
        self._cache: Dict[str, str] = {}

        # Metal configuration constants
        self.METAL_CONFIG = {
            'MAX_BUFFERS': 31,
            'MAX_BUFFER_SIZE': 256 * 1024 * 1024,  # 256MB
            'PREFERRED_ALIGNMENT': 256,
            'MAX_COMMAND_BUFFERS': 32,
            'SIMD_GROUP_SIZE': 32
        }

    def generate_host_code(self, kernel: CUDAKernel, class_prefix: str = "MT") -> Dict[str, str]:
        """
        Generate complete Objective-C implementation for Metal kernel execution.

        Args:
            kernel: CUDA kernel AST node
            class_prefix: Class name prefix for Objective-C conventions

        Returns:
            Dict containing header (.h) and implementation (.m) file contents

        Raises:
            CudaTranslationError: If code generation fails
        """
        try:
            class_name = f"{class_prefix}{kernel.name}Kernel"

            # Generate header and implementation
            header = self._generate_header_file(class_name, kernel)
            implementation = self._generate_implementation_file(class_name, kernel)

            return {
                'header': header,
                'implementation': implementation
            }

        except Exception as e:
            logger.error(f"Failed to generate Objective-C host code: {str(e)}")
            raise CudaTranslationError(f"Objective-C code generation failed: {str(e)}")

    def _generate_header_file(self, class_name: str, kernel: CUDAKernel) -> str:
        """Generate header file with interface declaration."""
        return f"""
#import <Metal/Metal.h>
#import <MetalKit/MetalKit.h>
#import <Foundation/Foundation.h>

NS_ASSUME_NONNULL_BEGIN

/// Error domain for Metal kernel execution
extern NSString * const {class_name}ErrorDomain;

/// Error codes for Metal kernel execution
typedef NS_ERROR_ENUM({class_name}ErrorDomain, {class_name}ErrorCode) {{
    {class_name}ErrorDeviceNotFound = 1000,
    {class_name}ErrorLibraryCreationFailed,
    {class_name}ErrorFunctionNotFound,
    {class_name}ErrorPipelineCreationFailed,
    {class_name}ErrorCommandQueueCreationFailed,
    {class_name}ErrorCommandEncodingFailed,
    {class_name}ErrorInvalidBufferSize,
    {class_name}ErrorBufferAllocationFailed,
    {class_name}ErrorExecutionFailed,
    {class_name}ErrorInvalidParameters
}};

/// Metal kernel wrapper for {kernel.name}
@interface {class_name} : NSObject

/// Initialize with Metal device
- (nullable instancetype)initWithDevice:(id<MTLDevice>)device
                                error:(NSError **)error NS_DESIGNATED_INITIALIZER;

/// Default initializer not available
- (instancetype)init NS_UNAVAILABLE;

/// Execute kernel with completion handler
- (void)execute{kernel.name}:
    {self._generate_header_parameters(kernel)}
    completion:(void (^)(NSError * _Nullable))completion;

/// Synchronous kernel execution
- (BOOL)execute{kernel.name}:
    {self._generate_header_parameters(kernel)}
    error:(NSError **)error;

@end

NS_ASSUME_NONNULL_END
"""

    def _generate_implementation_file(self, class_name: str, kernel: CUDAKernel) -> str:
        """Generate implementation file with complete kernel execution logic."""
        return f"""
#import "{class_name}.h"

NSString * const {class_name}ErrorDomain = @"{class_name}ErrorDomain";

@implementation {class_name} {{
    id<MTLDevice> _device;
    id<MTLCommandQueue> _commandQueue;
    id<MTLComputePipelineState> _pipelineState;
    dispatch_queue_t _executionQueue;
}}

#pragma mark - Initialization

- (nullable instancetype)initWithDevice:(id<MTLDevice>)device error:(NSError **)error {{
    self = [super init];
    if (self) {{
        _device = device;
        
        // Create command queue
        _commandQueue = [_device newCommandQueue];
        if (!_commandQueue) {{
            if (error) {{
                *error = [NSError errorWithDomain:{class_name}ErrorDomain
                                           code:{class_name}ErrorCommandQueueCreationFailed
                                       userInfo:@{{NSLocalizedDescriptionKey: @"Failed to create command queue"}}];
            }}
            return nil;
        }}
        
        // Create pipeline state
        if (![self createPipelineStateWithError:error]) {{
            return nil;
        }}
        
        // Create serial execution queue
        _executionQueue = dispatch_queue_create("{class_name}.ExecutionQueue", DISPATCH_QUEUE_SERIAL);
    }}
    return self;
}}

#pragma mark - Pipeline Setup

- (BOOL)createPipelineStateWithError:(NSError **)error {{
    // Load default library
    id<MTLLibrary> library = [_device newDefaultLibrary];
    if (!library) {{
        if (error) {{
            *error = [NSError errorWithDomain:{class_name}ErrorDomain
                                       code:{class_name}ErrorLibraryCreationFailed
                                   userInfo:@{{NSLocalizedDescriptionKey: @"Failed to create Metal library"}}];
        }}
        return NO;
    }}
    
    // Load kernel function
    id<MTLFunction> kernelFunction = [library newFunctionWithName:@"{kernel.name}"];
    if (!kernelFunction) {{
        if (error) {{
            *error = [NSError errorWithDomain:{class_name}ErrorDomain
                                       code:{class_name}ErrorFunctionNotFound
                                   userInfo:@{{NSLocalizedDescriptionKey: @"Kernel function not found"}}];
        }}
        return NO;
    }}
    
    // Create pipeline state
    NSError *pipelineError = nil;
    _pipelineState = [_device newComputePipelineStateWithFunction:kernelFunction error:&pipelineError];
    if (!_pipelineState) {{
        if (error) {{
            *error = [NSError errorWithDomain:{class_name}ErrorDomain
                                       code:{class_name}ErrorPipelineCreationFailed
                                   userInfo:@{{
                                       NSLocalizedDescriptionKey: @"Failed to create pipeline state",
                                       NSUnderlyingErrorKey: pipelineError
                                   }}];
        }}
        return NO;
    }}
    
    return YES;
}}

#pragma mark - Buffer Management

- (nullable id<MTLBuffer>)createBufferWithData:(const void *)data 
                                     length:(NSUInteger)length
                                      error:(NSError **)error {{
    if (length == 0 || !data) {{
        if (error) {{
            *error = [NSError errorWithDomain:{class_name}ErrorDomain
                                       code:{class_name}ErrorInvalidBufferSize
                                   userInfo:@{{NSLocalizedDescriptionKey: @"Invalid buffer parameters"}}];
        }}
        return nil;
    }}
    
    id<MTLBuffer> buffer = [_device newBufferWithBytes:data
                                              length:length
                                             options:MTLResourceStorageModeShared];
    if (!buffer) {{
        if (error) {{
            *error = [NSError errorWithDomain:{class_name}ErrorDomain
                                       code:{class_name}ErrorBufferAllocationFailed
                                   userInfo:@{{NSLocalizedDescriptionKey: @"Failed to allocate Metal buffer"}}];
        }}
        return nil;
    }}
    
    return buffer;
}}

#pragma mark - Kernel Execution

{self._generate_execution_methods(kernel)}

#pragma mark - Helper Methods

{self._generate_helper_methods(kernel)}

@end
"""

    def _generate_header_parameters(self, kernel: CUDAKernel) -> str:
        """Generate parameter declarations for header file."""
        params = []
        for param in kernel.parameters:
            objc_type = self._cuda_type_to_objc(param.cuda_type)
            params.append(f"({objc_type}){param.name}")
        return "\n    ".join(params)

    def _generate_execution_methods(self, kernel: CUDAKernel) -> str:
        """Generate kernel execution method implementations."""
        return f"""
- (void)execute{kernel.name}:{self._generate_execution_parameters(kernel)}
    completion:(void (^)(NSError * _Nullable))completion {{
    
    dispatch_async(_executionQueue, ^{{
        NSError *error = nil;
        BOOL success = [self execute{kernel.name}:{self._generate_argument_list(kernel)}
                                          error:&error];
        if (completion) {{
            dispatch_async(dispatch_get_main_queue(), ^{{
                completion(success ? nil : error);
            }});
        }}
    }});
}}

- (BOOL)execute{kernel.name}:{self._generate_execution_parameters(kernel)}
    error:(NSError **)error {{
    
    @try {{
        // Validate inputs
        if (![self validateInputs:{self._generate_argument_list(kernel)} error:error]) {{
            return NO;
        }}
        
        // Create command buffer
        id<MTLCommandBuffer> commandBuffer = [_commandQueue commandBuffer];
        if (!commandBuffer) {{
            if (error) {{
                *error = [NSError errorWithDomain:{class_name}ErrorDomain
                                           code:{class_name}ErrorCommandEncodingFailed
                                       userInfo:@{{NSLocalizedDescriptionKey: @"Failed to create command buffer"}}];
            }}
            return NO;
        }}
        
        // Create compute encoder
        id<MTLComputeCommandEncoder> encoder = [commandBuffer computeCommandEncoder];
        if (!encoder) {{
            if (error) {{
                *error = [NSError errorWithDomain:{class_name}ErrorDomain
                                           code:{class_name}ErrorCommandEncodingFailed
                                       userInfo:@{{NSLocalizedDescriptionKey: @"Failed to create compute encoder"}}];
            }}
            return NO;
        }}
        
        // Configure encoder
        [encoder setComputePipelineState:_pipelineState];
        
        // Create and set buffers
        if (![self setupBuffers:encoder {self._generate_argument_list(kernel)} error:error]) {{
            return NO;
        }}
        
        // Configure thread groups
        MTLSize threadGroupSize = MTLSizeMake({kernel.thread_config.block_size[0]},
                                           {kernel.thread_config.block_size[1]},
                                           {kernel.thread_config.block_size[2]});
        MTLSize gridSize = [self calculateGridSize:dataSize threadGroupSize:threadGroupSize];
        
        // Dispatch threads
        [encoder dispatchThreadgroups:gridSize threadsPerThreadgroup:threadGroupSize];
        [encoder endEncoding];
        
        // Commit and wait
        [commandBuffer commit];
        [commandBuffer waitUntilCompleted];
        
        // Check for execution errors
        if (commandBuffer.error) {{
            if (error) {{
                *error = [NSError errorWithDomain:{class_name}ErrorDomain
                                           code:{class_name}ErrorExecutionFailed
                                       userInfo:@{{
                                           NSLocalizedDescriptionKey: @"Kernel execution failed",
                                           NSUnderlyingErrorKey: commandBuffer.error
                                       }}];
            }}
            return NO;
        }}
        
        return YES;
    }}
    @catch (NSException *exception) {{
        if (error) {{
            *error = [NSError errorWithDomain:{class_name}ErrorDomain
                                       code:{class_name}ErrorExecutionFailed
                                   userInfo:@{{
                                       NSLocalizedDescriptionKey: [exception reason],
                                       NSLocalizedFailureReasonErrorKey: [exception name]
                                   }}];
        }}
        return NO;
    }}
}}
"""

    def _generate_helper_methods(self, kernel: CUDAKernel) -> str:
        """Generate helper method implementations."""
        return """
- (BOOL)validateInputs:(NSArray *)inputs error:(NSError **)error {
    // Validate input parameters
    for (id input in inputs) {
        if (!input) {
            if (error) {
                *error = [NSError errorWithDomain:MTKernelErrorDomain
                                           code:MTKernelErrorInvalidParameters
                                       userInfo:@{NSLocalizedDescriptionKey: @"Invalid input parameter"}];
            }
            return NO;
        }
    }
    return YES;
}

- (MTLSize)calculateGridSize:(NSUInteger)dataSize threadGroupSize:(MTLSize)threadGroupSize {
    NSUInteger w = (dataSize + threadGroupSize.width - 1) / threadGroupSize.width;
    return MTLSizeMake(w, 1, 1);
}

- (BOOL)setupBuffers:(id<MTLComputeCommandEncoder>)encoder
                     error:(NSError **)error {
    // Buffer setup implementation
    return YES;
}
"""

    def _cuda_type_to_objc(self, cuda_type: str) -> str:
        """Convert CUDA type to Objective-C type."""
        type_mapping = {
            'float': 'NSArray<NSNumber *> *',
            'double': 'NSArray<NSNumber *> *',
            'int': 'NSArray<NSNumber *> *',
            'unsigned int': 'NSArray<NSNumber *> *',
            'long': 'NSArray<NSNumber *> *',
            'unsigned long': 'NSArray<NSNumber *> *',
        }
        return type_mapping.get(cuda_type, 'NSArray<NSNumber *> *')

    def cleanup(self):
        """Cleanup resources."""
        with self._lock:
            self._cache.clear()

    def _generate_execution_parameters(self, kernel: CUDAKernel) -> str:
        """Generate parameter list for execution methods."""
        params = []
        for param in kernel.parameters:
            objc_type = self._cuda_type_to_objc(param.cuda_type)
            params.append(f"({objc_type}){param.name}")
        return "\n    ".join(params)

    def _generate_argument_list(self, kernel: CUDAKernel) -> str:
        """Generate argument list for method calls."""
        return ", ".join(param.name for param in kernel.parameters)
Class: ('ObjectiveCGenerator', '')
--------------------------------------------------------------------------------
  Method: get(cuda_type, 'NSArray<NSNumber *> *')


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\generator\swift_generator.py

from typing import Dict, List, Set, Optional, Union
from pathlib import Path
import logging
from threading import Lock

from ..utils.error_handler import CudaTranslationError
from ..utils.logger import get_logger
from ..parser.ast_nodes import CUDAKernel

logger = get_logger(__name__)

class SwiftGenerator:
    """
    Production-grade Swift code generator for Metal kernel integration.
    Handles host-side code generation with proper memory management and error handling.
    """

    def __init__(self):
        self._lock = Lock()
        self._cache: Dict[str, str] = {}

        # Metal-specific settings
        self.metal_settings = {
            'max_buffers': 31,
            'max_buffer_size': 256 * 1024 * 1024,  # 256MB
            'preferred_alignment': 256,
            'max_command_buffers': 32
        }

    def generate_host_code(self, kernel: CUDAKernel, class_name: Optional[str] = None) -> str:
        """Generate Swift host code for Metal kernel execution."""
        try:
            # Generate core components
            class_name = class_name or f"{kernel.name}Kernel"
            imports = self._generate_imports()
            class_def = self._generate_class_definition(class_name, kernel)
            buffer_management = self._generate_buffer_management(kernel)
            kernel_execution = self._generate_kernel_execution(kernel)
            error_handling = self._generate_error_handling()

            # Combine all components
            swift_code = f"""
{imports}

// MARK: - Metal Kernel Implementation
{class_def}

    // MARK: - Properties
    private let device: MTLDevice
    private let commandQueue: MTLCommandQueue
    private let pipelineState: MTLComputePipelineState
    private var buffers: [String: MTLBuffer] = [:]

    // MARK: - Initialization
    init() throws {{
        guard let device = MTLCreateSystemDefaultDevice() else {{
            throw MetalError.deviceNotFound
        }}
        self.device = device

        guard let commandQueue = device.makeCommandQueue() else {{
            throw MetalError.commandQueueCreationFailed
        }}
        self.commandQueue = commandQueue

        self.pipelineState = try Self.createPipelineState(device: device)
    }}

    // MARK: - Pipeline Setup
    private static func createPipelineState(device: MTLDevice) throws -> MTLComputePipelineState {{
        guard let library = device.makeDefaultLibrary() else {{
            throw MetalError.libraryCreationFailed
        }}

        guard let kernelFunction = library.makeFunction(name: "{kernel.name}") else {{
            throw MetalError.functionNotFound
        }}

        do {{
            return try device.makeComputePipelineState(function: kernelFunction)
        }} catch {{
            throw MetalError.pipelineCreationFailed
        }}
    }}

{buffer_management}

    // MARK: - Kernel Execution
{kernel_execution}

{error_handling}
}}

// MARK: - Extension for Async/Await Support
extension {class_name} {{
    /// Execute kernel with async/await support
    func executeAsync(
        {self._generate_parameter_list(kernel)}
    ) async throws {{
        try await withCheckedThrowingContinuation {{ continuation in
            execute(
                {self._generate_argument_list(kernel)},
                completion: {{ result in
                    switch result {{
                    case .success:
                        continuation.resume()
                    case .failure(let error):
                        continuation.resume(throwing: error)
                    }}
                }}
            )
        }}
    }}

    /// Execute kernel with completion handler
    func execute(
        {self._generate_parameter_list(kernel)},
        completion: @escaping (Result<Void, Error>) -> Void
    ) {{
        do {{
            // Validate input parameters
            try validateInputs({self._generate_validation_list(kernel)})

            // Create command buffer and encoder
            guard let commandBuffer = commandQueue.makeCommandBuffer(),
                  let encoder = commandBuffer.makeComputeCommandEncoder() else {{
                throw MetalError.commandEncodingFailed
            }}

            // Configure encoder
            encoder.setComputePipelineState(pipelineState)
            
            // Set buffers
            try setBuffers(encoder: encoder, {self._generate_buffer_list(kernel)})

            // Calculate optimal thread configuration
            let threadGroupSize = MTLSize(width: {kernel.thread_config.block_size[0]},
                                        height: {kernel.thread_config.block_size[1]},
                                        depth: {kernel.thread_config.block_size[2]})
            let gridSize = calculateGridSize(dataSize: dataSize, threadGroupSize: threadGroupSize)

            // Dispatch threads
            encoder.dispatchThreadgroups(gridSize, threadsPerThreadgroup: threadGroupSize)
            encoder.endEncoding()

            // Add completion handler
            commandBuffer.addCompletedHandler {{ buffer in
                if let error = buffer.error {{
                    completion(.failure(MetalError.executionFailed(error)))
                }} else {{
                    completion(.success(()))
                }}
            }}

            // Commit command buffer
            commandBuffer.commit()

        }} catch {{
            completion(.failure(error))
        }}
    }}

    // MARK: - Private Helper Methods
    private func validateInputs({self._generate_parameter_list(kernel)}) throws {{
        // Implement input validation logic based on kernel requirements
        {self._generate_validation_code(kernel)}
    }}

    private func setBuffers(
        encoder: MTLComputeCommandEncoder,
        {self._generate_parameter_list(kernel)}
    ) throws {{
        // Set buffers with proper error handling
        {self._generate_buffer_setup_code(kernel)}
    }}

    private func calculateGridSize(dataSize: Int, threadGroupSize: MTLSize) -> MTLSize {{
        let w = (dataSize + threadGroupSize.width - 1) / threadGroupSize.width
        return MTLSizeMake(w, 1, 1)
    }}
}}

// MARK: - Error Types
enum MetalError: LocalizedError {{
    case deviceNotFound
    case libraryCreationFailed
    case functionNotFound
    case pipelineCreationFailed
    case commandQueueCreationFailed
    case commandEncodingFailed
    case invalidBufferSize
    case bufferAllocationFailed
    case executionFailed(Error)
    case invalidInputParameters(String)

    var errorDescription: String? {{
        switch self {{
        case .deviceNotFound:
            return "Metal device not found"
        case .libraryCreationFailed:
            return "Failed to create Metal library"
        case .functionNotFound:
            return "Metal kernel function not found"
        case .pipelineCreationFailed:
            return "Failed to create compute pipeline state"
        case .commandQueueCreationFailed:
            return "Failed to create command queue"
        case .commandEncodingFailed:
            return "Failed to create command encoder"
        case .invalidBufferSize:
            return "Invalid buffer size specified"
        case .bufferAllocationFailed:
            return "Failed to allocate Metal buffer"
        case .executionFailed(let error):
            return "Kernel execution failed: \\(error.localizedDescription)"
        case .invalidInputParameters(let message):
            return "Invalid input parameters: \\(message)"
        }}
    }}
}}

// MARK: - Buffer Management Extension
private extension {class_name} {{
    func createBuffer<T>(from data: [T], options: MTLResourceOptions = .storageModeShared) throws -> MTLBuffer {{
        let size = MemoryLayout<T>.stride * data.count
        guard size > 0 else {{
            throw MetalError.invalidBufferSize
        }}

        guard let buffer = device.makeBuffer(bytes: data,
                                           length: size,
                                           options: options) else {{
            throw MetalError.bufferAllocationFailed
        }}

        return buffer
    }}

    func createBuffer<T>(size: Int, options: MTLResourceOptions = .storageModeShared) throws -> MTLBuffer {{
        guard size > 0 else {{
            throw MetalError.invalidBufferSize
        }}

        guard let buffer = device.makeBuffer(length: size,
                                           options: options) else {{
            throw MetalError.bufferAllocationFailed
        }}

        return buffer
    }}
}}
"""

            return swift_code

        except Exception as e:
            logger.error(f"Failed to generate Swift host code: {str(e)}")
            raise CudaTranslationError(f"Swift code generation failed: {str(e)}")

    def _generate_imports(self) -> str:
        """Generate required import statements."""
        return """
import Metal
import MetalKit
import Foundation
"""

    def _generate_class_definition(self, class_name: str, kernel: CUDAKernel) -> str:
        """Generate class definition with documentation."""
        return f"""
/// Metal kernel wrapper for {kernel.name}
/// Provides type-safe interface for kernel execution with proper error handling
final class {class_name} {{"""

    def _generate_parameter_list(self, kernel: CUDAKernel) -> str:
        """Generate parameter list for function signatures."""
        params = []
        for param in kernel.parameters:
            swift_type = self._cuda_type_to_swift(param.cuda_type)
            params.append(f"{param.name}: {swift_type}")
        return ", ".join(params)

    def _generate_validation_code(self, kernel: CUDAKernel) -> str:
        """Generate input validation code."""
        validations = []
        for param in kernel.parameters:
            if param.is_buffer:
                validations.append(f"""
        if {param.name}.count == 0 {{
            throw MetalError.invalidInputParameters("Empty buffer for {param.name}")
        }}""")
        return "\n".join(validations)

    def _generate_buffer_setup_code(self, kernel: CUDAKernel) -> str:
        """Generate buffer setup code."""
        setups = []
        for idx, param in enumerate(kernel.parameters):
            if param.is_buffer:
                setups.append(f"""
        let {param.name}Buffer = try createBuffer(from: {param.name})
        encoder.setBuffer({param.name}Buffer, offset: 0, index: {idx})""")
        return "\n".join(setups)

    def _cuda_type_to_swift(self, cuda_type: str) -> str:
        """Convert CUDA type to Swift type."""
        type_mapping = {
            'float': '[Float]',
            'double': '[Double]',
            'int': '[Int32]',
            'unsigned int': '[UInt32]',
            'long': '[Int64]',
            'unsigned long': '[UInt64]',
        }
        return type_mapping.get(cuda_type, '[Float]')  # Default to [Float] if type not found

    def cleanup(self):
        """Cleanup any resources."""
        with self._lock:
            self._cache.clear()
Class: ('SwiftGenerator', '')
--------------------------------------------------------------------------------
  Method: get(cuda_type, '[Float]')


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\generator\__init__.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\native\metal_interop.h

import Metal
import Foundation

// Advanced error handling for Metal operations
public enum MetalError: Error {
    case deviceNotFound
    case libraryCreationFailed
    case commandCreationFailed
    case pipelineCreationFailed
    case bufferCreationFailed
    case invalidThreadgroupSize
    case computeFailure(String)
    case resourceAllocationFailure
    case invalidKernelName
    case unsupportedOperation
}

// Protocol for Metal kernel execution
public protocol MetalKernelExecutable {
    func executeKernel(name: String,
                      buffers: [MTLBuffer],
                      threadgroupSize: MTLSize,
                      gridSize: MTLSize) throws

    func executeKernelAsync(name: String,
                           buffers: [MTLBuffer],
                           threadgroupSize: MTLSize,
                           gridSize: MTLSize,
                           completion: @escaping (Error?) -> Void)
}

// Main Metal kernel executor implementation
public final class MetalKernelExecutor: MetalKernelExecutable {
    private let device: MTLDevice
    private let commandQueue: MTLCommandQueue
    private let pipelineCache: NSCache<NSString, MTLComputePipelineState>
    private let resourceSemaphore: DispatchSemaphore
    private let executionQueue: DispatchQueue

    public init() throws {
        guard let device = MTLCreateSystemDefaultDevice() else {
            throw MetalError.deviceNotFound
        }

        guard let commandQueue = device.makeCommandQueue() else {
            throw MetalError.commandCreationFailed
        }

        self.device = device
        self.commandQueue = commandQueue
        self.pipelineCache = NSCache()
        self.resourceSemaphore = DispatchSemaphore(value: 3) // Limit concurrent executions
        self.executionQueue = DispatchQueue(label: "com.metal.execution",
                                          qos: .userInitiated,
                                          attributes: .concurrent)

        // Configure cache limits
        pipelineCache.countLimit = 50
    }

    public func executeKernel(
        name: String,
        buffers: [MTLBuffer],
        threadgroupSize: MTLSize,
        gridSize: MTLSize
    ) throws {
        // Validate inputs
        guard !name.isEmpty else {
            throw MetalError.invalidKernelName
        }

        guard isValidThreadgroupSize(threadgroupSize) else {
            throw MetalError.invalidThreadgroupSize
        }

        // Wait for available resource slot
        resourceSemaphore.wait()

        defer {
            resourceSemaphore.signal()
        }

        do {
            // Get pipeline state
            let pipelineState = try getPipelineState(kernelName: name)

            // Create command buffer and encoder
            guard let commandBuffer = commandQueue.makeCommandBuffer(),
                  let encoder = commandBuffer.makeComputeCommandEncoder() else {
                throw MetalError.commandCreationFailed
            }

            // Configure compute encoder
            encoder.setComputePipelineState(pipelineState)

            // Bind buffers
            for (index, buffer) in buffers.enumerated() {
                encoder.setBuffer(buffer, offset: 0, index: index)
            }

            // Validate and adjust sizes
            let adjustedSizes = calculateOptimalSizes(
                pipeline: pipelineState,
                requestedThreadgroup: threadgroupSize,
                requestedGrid: gridSize
            )

            // Dispatch compute kernel
            encoder.dispatchThreadgroups(adjustedSizes.grid,
                                       threadsPerThreadgroup: adjustedSizes.threadgroup)

            // Complete encoding and commit
            encoder.endEncoding()
            commandBuffer.commit()

            // Wait for completion and handle errors
            commandBuffer.waitUntilCompleted()

            if let error = commandBuffer.error {
                throw MetalError.computeFailure(error.localizedDescription)
            }

        } catch {
            throw MetalError.computeFailure("Kernel execution failed: \(error.localizedDescription)")
        }
    }

    public func executeKernelAsync(
        name: String,
        buffers: [MTLBuffer],
        threadgroupSize: MTLSize,
        gridSize: MTLSize,
        completion: @escaping (Error?) -> Void
    ) {
        executionQueue.async { [weak self] in
            do {
                try self?.executeKernel(
                    name: name,
                    buffers: buffers,
                    threadgroupSize: threadgroupSize,
                    gridSize: gridSize
                )
                completion(nil)
            } catch {
                completion(error)
            }
        }
    }

    private func getPipelineState(kernelName: String) throws -> MTLComputePipelineState {
        let key = kernelName as NSString

        // Check cache
        if let cached = pipelineCache.object(forKey: key) {
            return cached
        }

        // Create new pipeline state
        guard let library = device.makeDefaultLibrary(),
              let function = library.makeFunction(name: kernelName) else {
            throw MetalError.libraryCreationFailed
        }

        let descriptor = MTLComputePipelineDescriptor()
        descriptor.computeFunction = function
        descriptor.threadGroupSizeIsMultipleOfThreadExecutionWidth = true

        let options: MTLPipelineOption = [.argumentInfo, .bufferTypeInfo]

        let pipelineState = try device.makeComputePipelineState(
            descriptor: descriptor,
            options: options,
            reflection: nil
        )

        pipelineCache.setObject(pipelineState, forKey: key)
        return pipelineState
    }

    private func isValidThreadgroupSize(_ size: MTLSize) -> Bool {
        let maxTotal = device.maxThreadsPerThreadgroup
        let total = size.width * size.height * size.depth
        return total <= maxTotal
    }

    private func calculateOptimalSizes(
        pipeline: MTLComputePipelineState,
        requestedThreadgroup: MTLSize,
        requestedGrid: MTLSize
    ) -> (threadgroup: MTLSize, grid: MTLSize) {
        // Get optimal thread execution width
        let width = pipeline.threadExecutionWidth
        let height = pipeline.maxTotalThreadsPerThreadgroup / width

        // Adjust threadgroup size
        let threadgroup = MTLSize(
            width: min(requestedThreadgroup.width, width),
            height: min(requestedThreadgroup.height, height),
            depth: 1
        )

        // Calculate grid size
        let grid = MTLSize(
            width: (requestedGrid.width + threadgroup.width - 1) / threadgroup.width,
            height: (requestedGrid.height + threadgroup.height - 1) / threadgroup.height,
            depth: requestedGrid.depth
        )

        return (threadgroup, grid)
    }
}

// Resource manager for Metal buffers and textures
public final class MetalResourceManager {
    private let device: MTLDevice
    private var bufferCache: [String: WeakBuffer] = [:]
    private let queue = DispatchQueue(label: "com.metal.resourcemanager")
    private let maxBufferSize: Int

    private class WeakBuffer {
        weak var buffer: MTLBuffer?
        let creationTime: Date

        init(_ buffer: MTLBuffer) {
            self.buffer = buffer
            self.creationTime = Date()
        }
    }

    public init() throws {
        guard let device = MTLCreateSystemDefaultDevice() else {
            throw MetalError.deviceNotFound
        }
        self.device = device
        self.maxBufferSize = device.maxBufferLength

        // Start cache cleanup timer
        startCacheCleanupTimer()
    }

    public func createBuffer(
        size: Int,
        options: MTLResourceOptions = []
    ) throws -> MTLBuffer {
        guard size > 0 && size <= maxBufferSize else {
            throw MetalError.bufferCreationFailed
        }

        guard let buffer = device.makeBuffer(length: size, options: options) else {
            throw MetalError.bufferCreationFailed
        }

        return buffer
    }

    public func getOrCreateBuffer(
            identifier: String,
            size: Int,
            options: MTLResourceOptions = []
        ) throws -> MTLBuffer {
            return try queue.sync {
                // Clean up expired cache entries
                cleanupExpiredBuffers()

                // Check cache for existing buffer
                if let weakBuffer = bufferCache[identifier],
                   let buffer = weakBuffer.buffer,
                   buffer.length >= size {
                    return buffer
                }

                // Create new buffer
                let buffer = try createBuffer(size: size, options: options)
                bufferCache[identifier] = WeakBuffer(buffer)
                return buffer
            }
        }

        public func clearCache() {
            queue.sync {
                bufferCache.removeAll()
            }
        }

        private func cleanupExpiredBuffers() {
            let now = Date()
            bufferCache = bufferCache.filter { identifier, weakBuffer in
                guard let _ = weakBuffer.buffer else { return false }
                // Keep buffers that are less than 5 minutes old
                return now.timeIntervalSince(weakBuffer.creationTime) < 300
            }
        }

        private func startCacheCleanupTimer() {
            Timer.scheduledTimer(withTimeInterval: 60, repeats: true) { [weak self] _ in
                self?.queue.async {
                    self?.cleanupExpiredBuffers()
                }
            }
        }

        // Advanced buffer management methods
        public func copyBuffer(_ sourceBuffer: MTLBuffer,
                             to destinationBuffer: MTLBuffer,
                             size: Int) throws {
            guard size <= sourceBuffer.length && size <= destinationBuffer.length else {
                throw MetalError.bufferCreationFailed
            }

            guard let commandBuffer = device.makeCommandQueue()?.makeCommandBuffer(),
                  let blitEncoder = commandBuffer.makeBlitCommandEncoder() else {
                throw MetalError.commandCreationFailed
            }

            blitEncoder.copy(from: sourceBuffer,
                            sourceOffset: 0,
                            to: destinationBuffer,
                            destinationOffset: 0,
                            size: size)

            blitEncoder.endEncoding()
            commandBuffer.commit()
            commandBuffer.waitUntilCompleted()
        }

        public func fillBuffer(_ buffer: MTLBuffer,
                             with value: UInt8,
                             range: Range<Int>? = nil) throws {
            let fillRange = range ?? 0..<buffer.length

            guard let commandBuffer = device.makeCommandQueue()?.makeCommandBuffer(),
                  let blitEncoder = commandBuffer.makeBlitCommandEncoder() else {
                throw MetalError.commandCreationFailed
            }

            blitEncoder.fill(buffer: buffer,
                            range: fillRange,
                            value: value)

            blitEncoder.endEncoding()
            commandBuffer.commit()
            commandBuffer.waitUntilCompleted()
        }

        // Texture management
        public func createTexture(
            width: Int,
            height: Int,
            pixelFormat: MTLPixelFormat,
            usage: MTLTextureUsage = [.shaderRead, .shaderWrite]
        ) throws -> MTLTexture {
            let descriptor = MTLTextureDescriptor()
            descriptor.textureType = .type2D
            descriptor.width = width
            descriptor.height = height
            descriptor.pixelFormat = pixelFormat
            descriptor.usage = usage

            guard let texture = device.makeTexture(descriptor: descriptor) else {
                throw MetalError.resourceAllocationFailure
            }

            return texture
        }

        // Buffer synchronization
        public func synchronizeBuffer(_ buffer: MTLBuffer) throws {
            guard let commandBuffer = device.makeCommandQueue()?.makeCommandBuffer(),
                  let blitEncoder = commandBuffer.makeBlitCommandEncoder() else {
                throw MetalError.commandCreationFailed
            }

            blitEncoder.synchronize(resource: buffer)
            blitEncoder.endEncoding()
            commandBuffer.commit()
            commandBuffer.waitUntilCompleted()
        }

        // Memory management helpers
        public func purgeableState(for buffer: MTLBuffer) -> MTLPurgeableState {
            return buffer.setPurgeableState(.empty)
        }

        public func makeBufferPurgeable(_ buffer: MTLBuffer) {
            _ = buffer.setPurgeableState(.volatile)
        }

        public func makeBufferNonPurgeable(_ buffer: MTLBuffer) {
            _ = buffer.setPurgeableState(.nonVolatile)
        }

        // Memory statistics
        public func getMemoryStats() -> (used: Int, total: Int) {
            var used = 0
            queue.sync {
                for (_, weakBuffer) in bufferCache {
                    if let buffer = weakBuffer.buffer {
                        used += buffer.length
                    }
                }
            }
            return (used, maxBufferSize)
        }

        // Resource barriers
        public func deviceMemoryBarrier() throws {
            guard let commandBuffer = device.makeCommandQueue()?.makeCommandBuffer(),
                  let blitEncoder = commandBuffer.makeBlitCommandEncoder() else {
                throw MetalError.commandCreationFailed
            }

            blitEncoder.endEncoding()
            commandBuffer.commit()
            commandBuffer.waitUntilCompleted()
        }
    }

    // Extension for convenience methods
    extension MetalResourceManager {
        public func withMappedBuffer<T>(
            _ buffer: MTLBuffer,
            type: T.Type,
            body: (UnsafeMutableBufferPointer<T>) throws -> Void
        ) throws {
            guard let contents = buffer.contents().bindMemory(
                to: type,
                capacity: buffer.length / MemoryLayout<T>.stride
            ) else {
                throw MetalError.resourceAllocationFailure
            }

            let bufferPointer = UnsafeMutableBufferPointer(
                start: contents,
                count: buffer.length / MemoryLayout<T>.stride
            )

            try body(bufferPointer)
        }

        public func createTypedBuffer<T>(
            _ type: T.Type,
            count: Int,
            options: MTLResourceOptions = []
        ) throws -> MTLBuffer {
            let size = count * MemoryLayout<T>.stride
            return try createBuffer(size: size, options: options)
        }
    }

    // Utility extensions for Metal types
    extension MTLSize {
        public static func make(_ width: Int, _ height: Int = 1, _ depth: Int = 1) -> MTLSize {
            return MTLSizeMake(width, height, depth)
        }

        public var total: Int {
            return width * height * depth
        }
    }

    extension MTLBuffer {
        public func contents<T>(as type: T.Type) -> UnsafeMutablePointer<T> {
            return contents().assumingMemoryBound(to: type)
        }
    }
Class: ('MetalKernelExecutor', '')
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\optimization\barrier_optimizer.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\optimization\kernel_optimizer.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\optimization\memory_optimizer.py

from typing import Dict, List, Optional, Set, Tuple, Any
from dataclasses import dataclass
from enum import Enum
import logging

from ..parser.ast_nodes import (
    CUDANode, CUDAType, CUDAKernel, CUDASharedMemory,
    CUDAThreadIdx, CUDABlockIdx
)

class MemoryAccessPattern(Enum):
    COALESCED = "coalesced"
    STRIDED = "strided"
    RANDOM = "random"
    BROADCAST = "broadcast"
    SEQUENTIAL = "sequential"

@dataclass
class MemoryAccess:
    """Information about a memory access"""
    node: CUDANode
    type: MemoryAccessPattern
    stride: Optional[int] = None
    scope: str = "global"
    is_read: bool = True
    is_atomic: bool = False
    alignment: int = 16
    vector_width: Optional[int] = None

class MemoryOptimizer:
    """
    Optimizes memory access patterns for Metal GPU following NVIDIA best practices
    """

    def __init__(self):
        self.simd_width = 32  # Metal SIMD width
        self.max_threads_per_group = 1024
        self.shared_memory_limit = 32768  # 32KB for Metal
        self.l1_cache_line_size = 128  # Metal cache line size
        self.vector_sizes = {2, 4, 8, 16}  # Supported vector widths
        self.memory_accesses: List[MemoryAccess] = []

    def optimize_kernel(self, kernel: CUDAKernel) -> CUDAKernel:
        """Apply memory optimizations to kernel"""
        # Analyze memory access patterns
        self._analyze_memory_accesses(kernel)

        # Apply optimizations
        kernel = self._optimize_global_memory(kernel)
        kernel = self._optimize_shared_memory(kernel)
        kernel = self._optimize_texture_memory(kernel)
        kernel = self._optimize_atomics(kernel)

        return kernel

    def _analyze_memory_accesses(self, kernel: CUDAKernel):
        """Analyze all memory accesses in kernel"""
        self.memory_accesses.clear()

        def visit_node(node: CUDANode):
            if access := self._detect_memory_access(node):
                self.memory_accesses.append(access)

        kernel.traverse(visit_node)

        # Group and analyze patterns
        self._analyze_access_patterns()

    def _detect_memory_access(self, node: CUDANode) -> Optional[MemoryAccess]:
        """Detect memory access type and pattern"""
        if not hasattr(node, 'cuda_type'):
            return None

        # Check for array access
        if self._is_array_access(node):
            pattern = self._determine_access_pattern(node)
            scope = self._determine_memory_scope(node)

            return MemoryAccess(
                node=node,
                type=pattern,
                scope=scope,
                stride=self._calculate_stride(node),
                vector_width=self._detect_vector_width(node),
                alignment=self._check_alignment(node)
            )

        return None

    def _is_array_access(self, node: CUDANode) -> bool:
        """Check if node represents array access"""
        return hasattr(node, 'is_pointer') and node.is_pointer

    def _determine_access_pattern(self, node: CUDANode) -> MemoryAccessPattern:
        """Determine memory access pattern"""
        thread_idx = self._find_thread_index(node)
        if not thread_idx:
            return MemoryAccessPattern.RANDOM

        # Check for coalesced access
        if self._is_coalesced_access(node, thread_idx):
            return MemoryAccessPattern.COALESCED

        # Check for strided access
        stride = self._calculate_stride(node)
        if stride:
            return MemoryAccessPattern.STRIDED

        # Check for broadcast
        if self._is_broadcast_access(node):
            return MemoryAccessPattern.BROADCAST

        return MemoryAccessPattern.RANDOM

    def _optimize_global_memory(self, kernel: CUDAKernel) -> CUDAKernel:
        """Optimize global memory access patterns"""
        coalescing_opportunities = [
            access for access in self.memory_accesses
            if access.scope == "global" and access.type != MemoryAccessPattern.COALESCED
        ]

        # Apply vectorization where possible
        for access in coalescing_opportunities:
            if self._can_vectorize(access):
                kernel = self._apply_vectorization(kernel, access)

        # Optimize array indexing
        kernel = self._optimize_array_indexing(kernel)

        # Add padding for alignment
        kernel = self._add_memory_padding(kernel)

        return kernel

    def _optimize_shared_memory(self, kernel: CUDAKernel) -> CUDAKernel:
        """Optimize shared memory usage"""
        shared_vars = [
            node for node in kernel.children
            if isinstance(node, CUDASharedMemory)
        ]

        total_size = 0
        for var in shared_vars:
            # Optimize bank conflicts
            var = self._resolve_bank_conflicts(var)

            # Track size
            size = self._calculate_shared_memory_size(var)
            total_size += size

            if total_size > self.shared_memory_limit:
                logging.warning(f"Shared memory usage {total_size} exceeds Metal limit {self.shared_memory_limit}")

        return kernel

    def _optimize_texture_memory(self, kernel: CUDAKernel) -> CUDAKernel:
        """Optimize texture memory usage"""
        # Find read-only array accesses that could use textures
        candidate_arrays = [
            access for access in self.memory_accesses
            if access.scope == "global" and access.is_read and not access.is_atomic
        ]

        for access in candidate_arrays:
            if self._should_use_texture(access):
                kernel = self._convert_to_texture(kernel, access)

        return kernel

    def _optimize_atomics(self, kernel: CUDAKernel) -> CUDAKernel:
        """Optimize atomic operations"""
        atomic_accesses = [
            access for access in self.memory_accesses
            if access.is_atomic
        ]

        for access in atomic_accesses:
            # Try to use simdgroup operations
            if self._can_use_simdgroup(access):
                kernel = self._convert_to_simdgroup(kernel, access)
            else:
                # Optimize atomic memory layout
                kernel = self._optimize_atomic_layout(kernel, access)

        return kernel

    def _resolve_bank_conflicts(self, shared_var: CUDASharedMemory) -> CUDASharedMemory:
        """Resolve shared memory bank conflicts"""
        if not self._has_bank_conflicts(shared_var):
            return shared_var

        # Add padding to avoid conflicts
        padding = self._calculate_padding(shared_var)
        shared_var.size += padding

        return shared_var

    def _calculate_padding(self, var: CUDASharedMemory) -> int:
        """Calculate padding to avoid bank conflicts"""
        type_size = self._get_type_size(var.cuda_type)
        banks = 32  # Metal uses 32 banks

        if var.size % banks == 0:
            return 0

        return banks - (var.size % banks)

    def _can_vectorize(self, access: MemoryAccess) -> bool:
        """Check if memory access can be vectorized"""
        if not access.stride:
            return False

        # Check if stride matches vector size
        return (
                access.stride in self.vector_sizes and
                access.alignment >= access.stride * 4 and  # 4 bytes per element
                not access.is_atomic
        )

    def _should_use_texture(self, access: MemoryAccess) -> bool:
        """Determine if array should use texture memory"""
        return (
                access.is_read and
                not access.is_atomic and
                access.type in {MemoryAccessPattern.RANDOM, MemoryAccessPattern.STRIDED} and
                self._get_type_size(access.node.cuda_type) <= 16  # Max texture element size
        )

    def _can_use_simdgroup(self, access: MemoryAccess) -> bool:
        """Check if atomic can use simdgroup operations"""
        return (
                access.is_atomic and
                access.type == MemoryAccessPattern.SEQUENTIAL and
                self._is_reduction_pattern(access)
        )

    def _get_type_size(self, cuda_type: CUDAType) -> int:
        """Get size of CUDA type in bytes"""
        size_map = {
            CUDAType.CHAR: 1,
            CUDAType.SHORT: 2,
            CUDAType.INT: 4,
            CUDAType.FLOAT: 4,
            CUDAType.DOUBLE: 8,
        }
        return size_map.get(cuda_type, 4)  # Default to 4 bytes

    def get_optimization_report(self) -> Dict[str, Any]:
        """Generate memory optimization report"""
        return {
            "access_patterns": {
                pattern.value: len([a for a in self.memory_accesses if a.type == pattern])
                for pattern in MemoryAccessPattern
            },
            "vectorization_opportunities": len([
                a for a in self.memory_accesses if self._can_vectorize(a)
            ]),
            "texture_candidates": len([
                a for a in self.memory_accesses if self._should_use_texture(a)
            ]),
            "bank_conflicts": len([
                a for a in self.memory_accesses
                if a.scope == "shared" and self._has_bank_conflicts(a.node)
            ]),
            "simdgroup_opportunities": len([
                a for a in self.memory_accesses if self._can_use_simdgroup(a)
            ])
        }
Class: ('MemoryAccessPattern', '(Enum)')
--------------------------------------------------------------------------------
  Method: get(cuda_type, 4)

Class: ('MemoryAccess', '')
--------------------------------------------------------------------------------
  Method: get(cuda_type, 4)

Class: ('MemoryOptimizer', '')
--------------------------------------------------------------------------------
  Method: get(cuda_type, 4)


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\optimizer\unified_optimizer_metal.py

from typing import Dict, List, Optional, Tuple, Union, Set, Any
from dataclasses import dataclass
from enum import Enum
import logging
from concurrent.futures import ThreadPoolExecutor
from threading import Lock

from ..utils.error_handler import CudaTranslationError
from ..utils.logger import get_logger
from ..core.parser.ast_nodes import (
    CUDANode, CUDAKernel, CUDAThreadIdx, CUDABlockIdx
)
from ..utils.metal_math_functions import MetalMathFunction
from ..utils.cuda_to_metal_type_mapping import map_cuda_type_to_metal

logger = get_logger(__name__)

@dataclass
class OptimizationMetrics:
    compute_intensity: float = 0.0
    memory_pressure: float = 0.0
    thread_divergence: float = 0.0
    bank_conflicts: int = 0
    simd_efficiency: float = 0.0
    register_pressure: int = 0

class OptimizationType(Enum):
    MEMORY_COALESCING = "memory_coalescing"
    SIMD_GROUP = "simd_group"
    THREADGROUP_MEMORY = "threadgroup_memory"
    TEXTURE_SAMPLING = "texture_sampling"
    BARRIER_REDUCTION = "barrier_reduction"
    ARITHMETIC = "arithmetic"
    LOOP_UNROLLING = "loop_unrolling"
    VECTORIZATION = "vectorization"

class UnifiedMetalOptimizer:
    """
    Unified Metal optimization system following NVIDIA patterns.
    """
    def __init__(self):
        # Constants following NVIDIA GPU patterns
        self.WARP_SIZE = 32
        self.MAX_THREADS_PER_BLOCK = 1024
        self.MAX_BLOCKS_PER_GRID = (2**31-1, 65535, 65535)
        self.MAX_SHARED_MEMORY = 48 * 1024  # 48KB
        self.L1_CACHE_LINE_SIZE = 128
        self.VECTOR_SIZES = {2, 4, 8, 16}

        # Metal-specific limits
        self.metal_limits = {
            'max_threads_per_group': 1024,
            'max_threadgroups': (2048, 2048, 2048),
            'shared_memory_size': 32768,  # 32KB
            'simd_width': 32
        }

        # State management
        self.lock = Lock()
        self.thread_pool = ThreadPoolExecutor(max_workers=4)
        self._optimization_cache: Dict[str, Any] = {}
        self.metrics = OptimizationMetrics()
        self.applied_optimizations: Set[OptimizationType] = set()

    def optimize(self, kernel: CUDAKernel) -> CUDAKernel:
        """
        Main optimization entry point following NVIDIA's optimization hierarchy.
        """
        try:
            with self.lock:
                # Step 1: Analyze kernel characteristics
                analysis = self._analyze_kernel(kernel)

                # Step 2: Memory optimizations (highest priority)
                kernel = self._optimize_memory_access(kernel, analysis)
                kernel = self._optimize_shared_memory(kernel, analysis)
                kernel = self._optimize_texture_memory(kernel, analysis)

                # Step 3: Thread hierarchy optimizations
                kernel = self._optimize_thread_configuration(kernel, analysis)
                kernel = self._optimize_simd_groups(kernel, analysis)

                # Step 4: Arithmetic optimizations
                kernel = self._optimize_math_operations(kernel)
                kernel = self._optimize_vectorization(kernel)

                # Step 5: Control flow optimizations
                kernel = self._optimize_barriers(kernel)
                kernel = self._optimize_divergent_code(kernel)

                # Update metrics
                self._update_metrics(kernel, analysis)

                return kernel

        except Exception as e:
            logger.error(f"Optimization failed: {str(e)}")
            raise CudaTranslationError(f"Optimization failed: {str(e)}")

    def _analyze_kernel(self, kernel: CUDAKernel) -> Dict[str, Any]:
        """
        Comprehensive kernel analysis following NVIDIA profiling patterns.
        """
        analysis = {
            'memory_patterns': self._analyze_memory_patterns(kernel),
            'thread_hierarchy': self._analyze_thread_hierarchy(kernel),
            'compute_intensity': self._calculate_compute_intensity(kernel),
            'register_pressure': self._estimate_register_pressure(kernel),
            'shared_memory_usage': self._analyze_shared_memory_usage(kernel),
            'thread_divergence': self._analyze_thread_divergence(kernel),
            'bank_conflicts': self._detect_bank_conflicts(kernel),
            'optimization_opportunities': self._identify_optimization_opportunities(kernel)
        }

        # Cache analysis results
        self._optimization_cache[kernel.name] = analysis
        return analysis

    def _optimize_memory_access(self, kernel: CUDAKernel, analysis: Dict[str, Any]) -> CUDAKernel:
        """
        Memory access optimization following NVIDIA coalescing patterns.
        """
        memory_patterns = analysis['memory_patterns']

        # Global memory coalescing
        if memory_patterns.get('uncoalesced_accesses'):
            kernel = self._apply_memory_coalescing(kernel, memory_patterns['uncoalesced_accesses'])
            self.applied_optimizations.add(OptimizationType.MEMORY_COALESCING)

        # Shared memory bank conflict resolution
        if memory_patterns.get('bank_conflicts'):
            kernel = self._resolve_bank_conflicts(kernel, memory_patterns['bank_conflicts'])
            self.applied_optimizations.add(OptimizationType.THREADGROUP_MEMORY)

        return kernel

    def _optimize_thread_configuration(self, kernel: CUDAKernel, analysis: Dict[str, Any]) -> CUDAKernel:
        """
        Thread configuration optimization following NVIDIA occupancy patterns.
        """
        thread_hierarchy = analysis['thread_hierarchy']

        # Calculate optimal thread block size
        optimal_block_size = self._calculate_optimal_block_size(
            thread_hierarchy['current_block_size'],
            analysis['register_pressure'],
            analysis['shared_memory_usage']
        )

        # Adjust grid size based on block size
        optimal_grid_size = self._calculate_optimal_grid_size(
            thread_hierarchy['total_threads_needed'],
            optimal_block_size
        )

        # Update kernel configuration
        kernel.thread_config.block_size = optimal_block_size
        kernel.thread_config.grid_size = optimal_grid_size

        return kernel

    def _optimize_simd_groups(self, kernel: CUDAKernel, analysis: Dict[str, Any]) -> CUDAKernel:
        """
        SIMD group optimization following NVIDIA warp optimization patterns.
        """
        opportunities = analysis['optimization_opportunities']

        if opportunities.get('simd_operations'):
            # Convert appropriate operations to SIMD
            kernel = self._convert_to_simd_operations(kernel, opportunities['simd_operations'])
            self.applied_optimizations.add(OptimizationType.SIMD_GROUP)

        # Optimize SIMD group synchronization
        if opportunities.get('sync_points'):
            kernel = self._optimize_simd_sync(kernel, opportunities['sync_points'])

        return kernel

    def _optimize_barriers(self, kernel: CUDAKernel) -> CUDAKernel:
        """
        Barrier optimization following NVIDIA synchronization patterns.
        """
        sync_points = self._find_sync_points(kernel)

        optimized_sync_points = []
        for sync in sync_points:
            if self._is_barrier_necessary(sync, kernel):
                optimized_sync_points.append(self._optimize_barrier_type(sync))

        kernel = self._replace_sync_points(kernel, optimized_sync_points)
        self.applied_optimizations.add(OptimizationType.BARRIER_REDUCTION)

        return kernel

    def _optimize_math_operations(self, kernel: CUDAKernel) -> CUDAKernel:
        """
        Math operation optimization following NVIDIA intrinsics patterns.
        """
        def optimize_node(node: CUDANode) -> CUDANode:
            if isinstance(node, CUDAKernel):
                # Optimize math function calls
                node = self._optimize_math_functions(node)

                # Apply fast math where appropriate
                node = self._apply_fast_math(node)

                # Optimize compound operations
                node = self._optimize_compound_operations(node)

                self.applied_optimizations.add(OptimizationType.ARITHMETIC)

            return node

        return self._traverse_and_transform(kernel, optimize_node)

    def _optimize_vectorization(self, kernel: CUDAKernel) -> CUDAKernel:
        """
        Vectorization optimization following NVIDIA vectorization patterns.
        """
        vectorizable_ops = self._find_vectorizable_operations(kernel)

        if vectorizable_ops:
            for op in vectorizable_ops:
                vector_width = self._determine_vector_width(op)
                if vector_width:
                    kernel = self._apply_vectorization(kernel, op, vector_width)
                    self.applied_optimizations.add(OptimizationType.VECTORIZATION)

        return kernel

    def _update_metrics(self, kernel: CUDAKernel, analysis: Dict[str, Any]) -> None:
        """
        Update optimization metrics following NVIDIA profiling patterns.
        """
        with self.lock:
            self.metrics.compute_intensity = analysis['compute_intensity']
            self.metrics.memory_pressure = analysis['memory_patterns'].get('pressure', 0.0)
            self.metrics.thread_divergence = len(analysis['thread_divergence'])
            self.metrics.bank_conflicts = len(analysis['bank_conflicts'])
            self.metrics.simd_efficiency = self._calculate_simd_efficiency(kernel)
            self.metrics.register_pressure = analysis['register_pressure']

    def get_optimization_report(self) -> Dict[str, Any]:
        """
        Generate comprehensive optimization report.
        """
        return {
            'applied_optimizations': [opt.value for opt in self.applied_optimizations],
            'metrics': {
                'compute_intensity': self.metrics.compute_intensity,
                'memory_pressure': self.metrics.memory_pressure,
                'thread_divergence': self.metrics.thread_divergence,
                'bank_conflicts': self.metrics.bank_conflicts,
                'simd_efficiency': self.metrics.simd_efficiency,
                'register_pressure': self.metrics.register_pressure
            },
            'recommendations': self._generate_optimization_recommendations(),
            'metal_specific': {
                'threadgroup_size': self._get_optimal_threadgroup_size(),
                'memory_layout': self._get_optimal_memory_layout(),
                'barrier_usage': self._get_barrier_statistics()
            }
        }

    def _calculate_simd_efficiency(self, kernel: CUDAKernel) -> float:
        """Calculate SIMD efficiency based on thread utilization."""
        active_threads = self._count_active_threads(kernel)
        total_threads = kernel.thread_config.block_size[0] * \
                        kernel.thread_config.block_size[1] * \
                        kernel.thread_config.block_size[2]

        return active_threads / (total_threads * self.metal_limits['simd_width'])

    def _generate_optimization_recommendations(self) -> List[Dict[str, str]]:
        """Generate optimization recommendations based on metrics."""
        recommendations = []

        if self.metrics.memory_pressure > 0.8:
            recommendations.append({
                'type': 'memory_access',
                'message': 'High memory pressure detected. Consider using threadgroup memory.'
            })

        if self.metrics.thread_divergence > 0.2:
            recommendations.append({
                'type': 'divergence',
                'message': 'Significant thread divergence detected. Consider restructuring conditionals.'
            })

        if self.metrics.simd_efficiency < 0.7:
            recommendations.append({
                'type': 'simd_usage',
                'message': 'Low SIMD efficiency. Consider adjusting thread group size.'
            })

        return recommendations

    def cleanup(self):
        """Cleanup resources."""
        self.thread_pool.shutdown()
        self._optimization_cache.clear()
Class: ('OptimizationMetrics', '')
--------------------------------------------------------------------------------
  Method: get('uncoalesced_accesses')
  Method: get('bank_conflicts')
  Method: get('simd_operations')
  Method: get('sync_points')
  Method: get('pressure', 0.0)

Class: ('OptimizationType', '(Enum)')
--------------------------------------------------------------------------------
  Method: get('uncoalesced_accesses')
  Method: get('bank_conflicts')
  Method: get('simd_operations')
  Method: get('sync_points')
  Method: get('pressure', 0.0)

Class: ('UnifiedMetalOptimizer', '')
--------------------------------------------------------------------------------
  Method: get('uncoalesced_accesses')
  Method: get('bank_conflicts')
  Method: get('simd_operations')
  Method: get('sync_points')
  Method: get('pressure', 0.0)


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\parser\ast.py

# ast.py
# Complete AST implementation for CUDA to Metal translation system
# Production-ready with full optimization and error handling
# Author:
# Version: 1.0.0

from typing import List, Dict, Any, Optional, Union, Set, Tuple
from dataclasses import dataclass, field
from enum import Enum, auto
import logging
from pathlib import Path
import json
import math

logger = logging.getLogger(__name__)

# Import Metal translation mappings
from .mapping_tables import (
    CUDA_TO_METAL_TYPE_MAP,
    CUDA_TO_METAL_OPERATORS,
    CUDA_TO_METAL_FUNCTION_MAP,
    METAL_SPECIFIC_LIMITATIONS
)

class NodeType(Enum):
    """AST node types with complete Metal translation support"""
    TRANSLATION_UNIT = auto()
    FUNCTION = auto()
    KERNEL = auto()
    VARIABLE = auto()
    EXPRESSION = auto()
    STATEMENT = auto()
    COMPOUND = auto()
    TYPE = auto()

@dataclass
class SourceLocation:
    """Source code location tracking"""
    file: str
    line: int
    column: int
    offset: Optional[int] = None

@dataclass
class MetalOptimizationMetadata:
    """Comprehensive Metal optimization metadata"""
    vectorizable: bool = False
    coalesced_access: bool = False
    requires_simd_group: bool = False
    threadgroup_memory_size: int = 0
    atomic_operations: List[str] = field(default_factory=list)
    barrier_points: List[Dict[str, Any]] = field(default_factory=list)
    simd_width: int = 32
    compute_occupancy: float = 0.0
    memory_access_pattern: str = "random"
    thread_divergence: bool = False
    bank_conflict_risk: bool = False

@dataclass
class MetalResourceLimits:
    """Metal hardware and API limitations"""
    max_threads_per_threadgroup: int = 1024
    max_threadgroups_per_grid: Tuple[int, int, int] = (2048, 2048, 2048)
    max_total_threadgroup_memory: int = 32768  # 32KB
    max_buffer_size: int = 1 << 30  # 1GB
    simd_group_size: int = 32
    max_total_threads_per_grid: int = 1 << 32
    max_texture_size: int = 16384

@dataclass
class ValidationError:
    """Validation error details"""
    error_type: str
    message: str
    location: Optional[SourceLocation] = None
    severity: str = "error"

class CudaASTNode:
    """Production-ready AST node base class for CUDA to Metal translation"""
    
    def __init__(self,
                 node_type: NodeType,
                 spelling: Optional[str] = None,
                 source_type: Optional[str] = None,
                 location: Optional[SourceLocation] = None):
                 
        # Core attributes
        self.node_type = node_type
        self.spelling = spelling
        self.source_type = source_type
        self.location = location
        self.children: List['CudaASTNode'] = []
        self.parent: Optional['CudaASTNode'] = None
        
        # Metal translation attributes
        self.metal_translation: Optional[str] = None
        self.metal_type: Optional[str] = None
        self.metal_qualifiers: List[str] = []
        self.optimization_metadata = MetalOptimizationMetadata()
        self.resource_requirements = MetalResourceLimits()
        
        # Validation and analysis state
        self.validation_errors: List[ValidationError] = []
        self.translation_warnings: List[str] = []
        self.dependency_graph: Dict[str, Set[str]] = {}
        self.optimization_opportunities: Set[str] = set()
        
    def add_child(self, child: 'CudaASTNode') -> None:
        """Add child node with proper parent linking and validation"""
        # Validate child type compatibility
        if not self._validate_child_type(child):
            self.validation_errors.append(
                ValidationError(
                    error_type="invalid_child",
                    message=f"Invalid child type {child.node_type} for parent {self.node_type}",
                    location=child.location
                )
            )
            return
            
        self.children.append(child)
        child.parent = self
        
        # Update dependency graph
        self._update_dependencies(child)
        
    def _validate_child_type(self, child: 'CudaASTNode') -> bool:
        """Validate child type compatibility with current node"""
        # Implementation depends on specific node type rules
        return True
        
    def _update_dependencies(self, child: 'CudaASTNode') -> None:
        """Update node dependency graph for optimization"""
        child_deps = child.get_dependency_info()
        self.dependency_graph[child.spelling] = child_deps['dependencies']
        
    def get_metal_translation(self) -> str:
        """Get or generate Metal translation with caching and validation"""
        if self.metal_translation is None:
            try:
                # Validate before translation
                if not self.validate():
                    raise ValueError(f"Node validation failed: {self.get_validation_errors()}")
                    
                # Generate and optimize translation
                self.metal_translation = self._generate_metal_translation()
                self._optimize_metal_translation()
                
            except Exception as e:
                logger.error(f"Translation error in {self.node_type}: {str(e)}")
                raise
                
        return self.metal_translation
        
    def _generate_metal_translation(self) -> str:
        """Generate Metal translation - must be implemented by subclasses"""
        raise NotImplementedError(
            f"_generate_metal_translation not implemented for {self.__class__.__name__}"
        )
        
    def _optimize_metal_translation(self) -> None:
        """Apply Metal-specific optimizations to generated code"""
        if not self.metal_translation:
            return
            
        # Apply optimization opportunities
        for opt in self.optimization_opportunities:
            self.metal_translation = self._apply_optimization(
                opt, self.metal_translation
            )
            
    def _apply_optimization(self, optimization: str, code: str) -> str:
        """Apply specific Metal optimization to code"""
        # Implementation depends on optimization type
        return code
        
    def validate(self) -> bool:
        """Validate node and children for Metal compatibility"""
        self.validation_errors.clear()
        
        # Validate current node
        self._validate_node()
        
        # Validate children recursively
        for child in self.children:
            if not child.validate():
                self.validation_errors.extend(child.validation_errors)
                
        return len(self.validation_errors) == 0
        
    def _validate_node(self) -> None:
        """Node-specific validation"""
        # Validate Metal type mapping
        if self.source_type and not self._validate_metal_type():
            self.validation_errors.append(
                ValidationError(
                    error_type="invalid_type_mapping",
                    message=f"No Metal equivalent for type {self.source_type}",
                    location=self.location
                )
            )
            
        # Validate resource limits
        self._validate_resource_limits()
        
    def _validate_metal_type(self) -> bool:
        """Validate Metal type mapping exists"""
        if not self.source_type:
            return True
            
        base_type = self.source_type.replace('*', '').strip()
        return base_type in CUDA_TO_METAL_TYPE_MAP
        
    def _validate_resource_limits(self) -> None:
        """Validate against Metal resource limits"""
        if self.optimization_metadata.threadgroup_memory_size > self.resource_requirements.max_total_threadgroup_memory:
            self.validation_errors.append(
                ValidationError(
                    error_type="resource_limit",
                    message="Threadgroup memory size exceeds Metal limit",
                    location=self.location
                )
            )
            
    def get_validation_errors(self) -> List[str]:
        """Get formatted validation errors"""
        return [
            f"{err.severity.upper()}: {err.message} at {err.location}"
            for err in self.validation_errors
        ]
        
    def get_dependency_info(self) -> Dict[str, Any]:
        """Get node dependencies for optimization"""
        deps = {
            'reads': set(),
            'writes': set(),
            'dependencies': set(),
            'scope': self.get_scope()
        }
        
        # Collect dependencies from children
        for child in self.children:
            child_deps = child.get_dependency_info()
            deps['reads'].update(child_deps['reads'])
            deps['writes'].update(child_deps['writes'])
            deps['dependencies'].update(child_deps['dependencies'])
            
        return deps
        
    def get_scope(self) -> str:
        """Get node scope for Metal translation"""
        if hasattr(self, 'metal_scope'):
            return getattr(self, 'metal_scope')
        return self.parent.get_scope() if self.parent else 'global'
        
    def get_ancestor_of_type(self, node_type: NodeType) -> Optional['CudaASTNode']:
        """Find nearest ancestor of specified type"""
        current = self.parent
        while current is not None:
            if current.node_type == node_type:
                return current
            current = current.parent
        return None
        
    def find_children_of_type(self, node_type: NodeType) -> List['CudaASTNode']:
        """Find all children of specified type"""
        result = []
        for child in self.children:
            if child.node_type == node_type:
                result.append(child)
            result.extend(child.find_children_of_type(node_type))
        return result
        
    def optimize(self) -> None:
        """Apply Metal-specific optimizations"""
        # Identify optimization opportunities
        self._analyze_optimization_opportunities()
        
        # Apply optimizations
        self._optimize_node()
        
        # Optimize children
        for child in self.children:
            child.optimize()
            
    def _analyze_optimization_opportunities(self) -> None:
        """Analyze node for Metal optimization opportunities"""
        # Check vectorization
        if self._can_vectorize():
            self.optimization_opportunities.add('vectorize')
            
        # Check memory access patterns
        if self._can_optimize_memory_access():
            self.optimization_opportunities.add('coalesce_memory')
            
        # Check SIMD opportunities
        if self._can_use_simd():
            self.optimization_opportunities.add('simd_optimize')
            
    def _can_vectorize(self) -> bool:
        """Check if node operations can be vectorized"""
        return False  # Base implementation
        
    def _can_optimize_memory_access(self) -> bool:
        """Check if memory access can be optimized"""
        return False  # Base implementation
        
    def _can_use_simd(self) -> bool:
        """Check if SIMD optimizations can be applied"""
        return False  # Base implementation
        
    def _optimize_node(self) -> None:
        """Apply node-specific optimizations"""
        pass  # Base implementation
        
    def to_json(self) -> Dict[str, Any]:
        """Convert node to JSON for serialization"""
        return {
            'node_type': self.node_type.name,
            'spelling': self.spelling,
            'source_type': self.source_type,
            'location': vars(self.location) if self.location else None,
            'metal_translation': self.metal_translation,
            'metal_type': self.metal_type,
            'metal_qualifiers': self.metal_qualifiers,
            'optimization_metadata': vars(self.optimization_metadata),
            'validation_errors': [vars(err) for err in self.validation_errors],
            'translation_warnings': self.translation_warnings,
            'children': [child.to_json() for child in self.children]
        }

    @classmethod
    def from_json(cls, data: Dict[str, Any]) -> 'CudaASTNode':
        """Create node from JSON representation"""
        node = cls(
            node_type=NodeType[data['node_type']],
            spelling=data['spelling'],
            source_type=data['source_type'],
            location=SourceLocation(**data['location']) if data['location'] else None
        )
        
        node.metal_translation = data['metal_translation']
        node.metal_type = data['metal_type']
        node.metal_qualifiers = data['metal_qualifiers']
        
        # Restore optimization metadata
        for key, value in data['optimization_metadata'].items():
            setattr(node.optimization_metadata, key, value)
            
        # Restore validation state
        node.validation_errors = [
            ValidationError(**err) for err in data['validation_errors']
        ]
        node.translation_warnings = data['translation_warnings']
        
        # Restore children
        for child_data in data['children']:
            child = CudaASTNode.from_json(child_data)
            node.add_child(child)
            
        return node
        
    def __repr__(self) -> str:
        """String representation for debugging"""
        return (
            f"{self.__class__.__name__}("
            f"type={self.node_type.name}, "
            f"spelling='{self.spelling}', "
            f"metal_type='{self.metal_type}', "
            f"opt_opportunities={self.optimization_opportunities})"
        )

    def __eq__(self, other: object) -> bool:
        """Equality comparison"""
        if not isinstance(other, CudaASTNode):
            return NotImplemented
            
        return (
            self.node_type == other.node_type and
            self.spelling == other.spelling and
            self.source_type == other.source_type and
            self.metal_type == other.metal_type and
            self.children == other.children
        )

    def __hash__(self) -> int:
        """Hash for collections"""
        return hash((
            self.node_type,
            self.spelling,
            self.source_type,
            self.metal_type
        ))

# Register logger
logger.info("CudaASTNode base class initialized with complete Metal support")
Class: ('NodeType', '(Enum)')
--------------------------------------------------------------------------------

Class: ('SourceLocation', '')
--------------------------------------------------------------------------------

Class: ('MetalOptimizationMetadata', '')
--------------------------------------------------------------------------------

Class: ('MetalResourceLimits', '')
--------------------------------------------------------------------------------

Class: ('ValidationError', '')
--------------------------------------------------------------------------------

Class: ('CudaASTNode', '')
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\parser\cuda_parser.py


import clang.cindex
from clang.cindex import Index, TranslationUnit, Cursor, CursorKind, TypeKind
from typing import Dict, List, Optional, Union, Tuple, Any
from threading import Lock
import os
import platform
import logging
import hashlib
import time

from ..utils.error_handler import CudaParseError, CudaTranslationError
from ..utils.logger import get_logger
from ..core.parser.ast_nodes import (
    CUDANode, CUDAKernel, CUDAParameter, CUDAType, CUDAQualifier,
    CUDAExpressionNode, CUDAStatement, KernelNode, FunctionNode, VariableNode
)

logger = get_logger(__name__)

class CudaParser:

    def __init__(self, cuda_include_paths: Optional[List[str]] = None):
        # Initialize clang parser
        self.index = Index.create()
        self.cuda_include_paths = cuda_include_paths or self._find_cuda_paths()
        self._lock = Lock()
        self._ast_cache: Dict[str, CUDANode] = {}
        self._setup_clang_args()

    def _find_cuda_paths(self) -> List[str]:
        """Find CUDA installation paths based on platform."""
        cuda_paths = []

        # Common locations by platform
        if platform.system() == 'Windows':
            program_files = os.environ.get('ProgramFiles', 'C:\\Program Files')
            cuda_base = os.path.join(program_files, 'NVIDIA GPU Computing Toolkit', 'CUDA')
            if os.path.exists(cuda_base):
                for version_dir in sorted(os.listdir(cuda_base), reverse=True):
                    if version_dir.startswith('v'):
                        include_path = os.path.join(cuda_base, version_dir, 'include')
                        if os.path.exists(include_path):
                            cuda_paths.append(include_path)
                            break
        elif platform.system() == 'Linux':
            for path in ['/usr/local/cuda/include', '/usr/include/cuda']:
                if os.path.exists(path):
                    cuda_paths.append(path)
        elif platform.system() == 'Darwin':
            for path in ['/usr/local/cuda/include', '/opt/cuda/include']:
                if os.path.exists(path):
                    cuda_paths.append(path)

        # Add standard system paths
        cuda_paths.extend(['/usr/include', '/usr/local/include'])
        return cuda_paths

    def _setup_clang_args(self):
        """Set up clang compilation arguments for CUDA parsing."""
        self.clang_args = [
            '-x', 'cuda',                      # Treat input as CUDA source
            '--cuda-gpu-arch=sm_70',           # Target compute capability
            '-std=c++14',                      # C++ standard
            '-D__CUDACC__',                    # Define CUDACC preprocessor macro
            '-D__CUDA_ARCH__=700',             # Define CUDA architecture
            '-DNDEBUG',                        # Define NDEBUG for release mode
        ]

        # Add include paths
        for path in self.cuda_include_paths:
            self.clang_args.extend(['-I', path])

    def parse_file(self, file_path: str) -> Optional[CUDANode]:
        """
        Parse CUDA source file into AST with full error handling and caching.

        Args:
            file_path: Path to CUDA source file

        Returns:
            CUDANode: Root AST node

        Raises:
            CudaParseError: If parsing fails
            FileNotFoundError: If file doesn't exist
        """
        # Input validation
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"CUDA source file not found: {file_path}")

        # Check cache using file hash
        file_hash = self._get_file_hash(file_path)
        cache_key = f"{file_path}:{file_hash}"

        with self._lock:
            if cache_key in self._ast_cache:
                logger.debug(f"Using cached AST for {file_path}")
                return self._ast_cache[cache_key]

        try:
            # Parse with clang
            start_time = time.time()
            logger.info(f"Parsing CUDA file: {file_path}")

            tu = self.index.parse(
                file_path,
                args=self.clang_args,
                options=(
                        TranslationUnit.PARSE_DETAILED_PROCESSING_RECORD |
                        TranslationUnit.PARSE_INCOMPLETE
                )
            )

            # Check for fatal errors
            if self._has_fatal_errors(tu):
                return None

            # Convert to our AST
            root = self._process_translation_unit(tu.cursor)

            # Cache the result
            with self._lock:
                self._ast_cache[cache_key] = root

            parse_time = time.time() - start_time
            logger.info(f"Successfully parsed {file_path} in {parse_time:.2f}s")

            return root

        except Exception as e:
            logger.error(f"Failed to parse {file_path}: {str(e)}")
            raise CudaParseError(f"Parse error: {str(e)}")

    def _get_file_hash(self, file_path: str) -> str:
        """Generate hash for file content."""
        try:
            with open(file_path, 'rb') as f:
                file_content = f.read()
                return hashlib.md5(file_content).hexdigest()
        except Exception as e:
            logger.warning(f"Failed to hash file {file_path}: {str(e)}")
            # Fall back to modification time if hashing fails
            return str(os.path.getmtime(file_path))

    def _has_fatal_errors(self, tu: TranslationUnit) -> bool:
        """Check for fatal parsing errors."""
        has_fatal = False
        for diag in tu.diagnostics:
            if diag.severity >= diag.Error:
                logger.error(
                    f"{diag.location.file}:{diag.location.line} - {diag.spelling}"
                )
                has_fatal = True
        return has_fatal

    def _process_translation_unit(self, cursor: Cursor) -> CUDANode:
        """Process translation unit cursor into CUDANode."""
        root = CUDANode(
            kind=str(cursor.kind),
            spelling=cursor.spelling,
            line=cursor.location.line,
            column=cursor.location.column
        )

        # Process all top-level declarations
        for child in cursor.get_children():
            if child.location.file and child.location.file.name.endswith(('.cu', '.cuh')):
                node = self._process_cursor(child)
                if node:
                    root.add_child(node)

        return root

    def _process_cursor(self, cursor: Cursor) -> Optional[CUDANode]:
        """Process a cursor into the appropriate CUDA AST node."""
        try:
            # Identify cursor type
            if cursor.kind == CursorKind.FUNCTION_DECL:
                # Check if it's a CUDA __global__ function (kernel)
                if any(c.kind == CursorKind.CUDA_GLOBAL_ATTR for c in cursor.get_children()):
                    return self._process_kernel(cursor)
                else:
                    return self._process_function(cursor)
            elif cursor.kind == CursorKind.VAR_DECL:
                return self._process_variable(cursor)
            elif cursor.kind in (CursorKind.STRUCT_DECL, CursorKind.CLASS_DECL):
                return self._process_struct_or_class(cursor)
            elif cursor.kind == CursorKind.TYPEDEF_DECL:
                return self._process_typedef(cursor)

            # Other node types can be added as needed
            return None

        except Exception as e:
            logger.error(f"Error processing cursor {cursor.spelling}: {str(e)}")
            return None

    def _process_kernel(self, cursor: Cursor) -> KernelNode:
        """Process a CUDA kernel function."""
        # Extract location information
        location = {
            'file': cursor.location.file.name if cursor.location.file else '',
            'line': cursor.location.line,
            'column': cursor.location.column
        }

        # Process parameters
        parameters = []
        for child in cursor.get_arguments():
            param = self._process_parameter(child)
            if param:
                parameters.append(param)

        # Process function body
        body = []
        for child in cursor.get_children():
            if child.kind == CursorKind.COMPOUND_STMT:
                for stmt in child.get_children():
                    node = self._process_statement(stmt)
                    if node:
                        body.append(node)

        # Create kernel node
        kernel = KernelNode(
            name=cursor.spelling,
            return_type=self._get_type_spelling(cursor.result_type),
            parameters=parameters,
            body=body,
            line=location['line'],
            column=location['column']
        )

        # Set kernel-specific attributes
        kernel.is_kernel = True

        # Process any CUDA specific attributes
        for child in cursor.get_children():
            if child.kind == CursorKind.CUDA_GLOBAL_ATTR:
                self._process_kernel_attributes(child, kernel)

        return kernel

    def _process_function(self, cursor: Cursor) -> FunctionNode:
        """Process a regular CUDA function."""
        # Similar to _process_kernel but for non-kernel functions
        location = {
            'file': cursor.location.file.name if cursor.location.file else '',
            'line': cursor.location.line,
            'column': cursor.location.column
        }

        # Process parameters
        parameters = []
        for child in cursor.get_arguments():
            param = self._process_parameter(child)
            if param:
                parameters.append(param)

        # Process function body
        body = []
        for child in cursor.get_children():
            if child.kind == CursorKind.COMPOUND_STMT:
                for stmt in child.get_children():
                    node = self._process_statement(stmt)
                    if node:
                        body.append(node)

        # Create function node
        function = FunctionNode(
            name=cursor.spelling,
            return_type=self._get_type_spelling(cursor.result_type),
            parameters=parameters,
            body=body,
            line=location['line'],
            column=location['column']
        )

        # Check for device attribute
        function.is_device = any(c.kind == CursorKind.CUDA_DEVICE_ATTR for c in cursor.get_children())

        return function

    def _process_parameter(self, cursor: Cursor) -> CUDAParameter:
        """Process a function parameter."""
        return CUDAParameter(
            name=cursor.spelling,
            param_type=self._get_type_spelling(cursor.type),
            is_pointer=cursor.type.kind == TypeKind.POINTER,
            qualifiers=self._get_qualifiers(cursor),
            line=cursor.location.line,
            column=cursor.location.column
        )

    def _process_variable(self, cursor: Cursor) -> VariableNode:
        """Process a variable declaration."""
        # Check if it's a special memory space variable
        is_shared = any(c.kind == CursorKind.CUDA_SHARED_ATTR for c in cursor.get_children())
        is_constant = any(c.kind == CursorKind.CUDA_CONSTANT_ATTR for c in cursor.get_children())
        is_device = any(c.kind == CursorKind.CUDA_DEVICE_ATTR for c in cursor.get_children())

        qualifiers = []
        if is_shared:
            qualifiers.append(CUDAQualifier.SHARED)
        if is_constant:
            qualifiers.append(CUDAQualifier.CONST)
        if is_device:
            qualifiers.append(CUDAQualifier.DEVICE)

        return VariableNode(
            name=cursor.spelling,
            var_type=self._get_type_spelling(cursor.type),
            qualifiers=qualifiers,
            is_pointer=cursor.type.kind == TypeKind.POINTER,
            line=cursor.location.line,
            column=cursor.location.column
        )

    def _process_statement(self, cursor: Cursor) -> Optional[CUDAStatement]:
        """Process a statement in the function body."""
        stmt_kind = str(cursor.kind)

        # Basic statement processing - can be expanded with more detailed processing
        if cursor.kind == CursorKind.COMPOUND_STMT:
            return self._process_compound_statement(cursor)
        elif cursor.kind == CursorKind.IF_STMT:
            return self._process_if_statement(cursor)
        elif cursor.kind == CursorKind.FOR_STMT:
            return self._process_for_statement(cursor)
        elif cursor.kind == CursorKind.WHILE_STMT:
            return self._process_while_statement(cursor)
        elif cursor.kind == CursorKind.RETURN_STMT:
            return self._process_return_statement(cursor)
        elif cursor.kind == CursorKind.DECL_STMT:
            return self._process_declaration_statement(cursor)
        elif cursor.kind == CursorKind.CALL_EXPR:
            return self._process_call_expression(cursor)

        # Create a generic statement for other cases
        return CUDAStatement(
            kind=stmt_kind,
            line=cursor.location.line,
            column=cursor.location.column
        )

    def _process_struct_or_class(self, cursor: Cursor) -> CUDANode:
        """Process a struct or class declaration."""
        # Basic processing for struct/class - can be expanded
        node = CUDANode(
            kind=str(cursor.kind),
            spelling=cursor.spelling,
            line=cursor.location.line,
            column=cursor.location.column
        )

        # Process members
        for child in cursor.get_children():
            member = self._process_cursor(child)
            if member:
                node.add_child(member)

        return node

    def _process_typedef(self, cursor: Cursor) -> CUDANode:
        """Process a typedef declaration."""
        return CUDANode(
            kind=str(cursor.kind),
            spelling=cursor.spelling,
            line=cursor.location.line,
            column=cursor.location.column
        )

    def _process_compound_statement(self, cursor: Cursor) -> CUDAStatement:
        """Process a compound statement (block)."""
        stmt = CUDAStatement(
            kind="compound",
            line=cursor.location.line,
            column=cursor.location.column
        )

        for child in cursor.get_children():
            child_stmt = self._process_statement(child)
            if child_stmt:
                stmt.add_child(child_stmt)

        return stmt

    def _process_if_statement(self, cursor: Cursor) -> CUDAStatement:
        """Process an if statement."""
        stmt = CUDAStatement(
            kind="if",
            line=cursor.location.line,
            column=cursor.location.column
        )

        # Process condition, then-branch, and else-branch
        children = list(cursor.get_children())
        if len(children) >= 1:
            stmt.condition = self._process_expression(children[0])

        if len(children) >= 2:
            then_branch = self._process_statement(children[1])
            if then_branch:
                stmt.then_branch = [then_branch]

        if len(children) >= 3:
            else_branch = self._process_statement(children[2])
            if else_branch:
                stmt.else_branch = [else_branch]

        return stmt

    def _process_for_statement(self, cursor: Cursor) -> CUDAStatement:
        """Process a for statement."""
        stmt = CUDAStatement(
            kind="for",
            line=cursor.location.line,
            column=cursor.location.column
        )

        children = list(cursor.get_children())

        # Process initialization, condition, increment, and body
        if len(children) >= 3:
            stmt.init = self._process_expression(children[0])
            stmt.condition = self._process_expression(children[1])
            stmt.increment = self._process_expression(children[2])

        if len(children) >= 4:
            body = self._process_statement(children[3])
            if body:
                stmt.body = [body]

        return stmt

    def _process_while_statement(self, cursor: Cursor) -> CUDAStatement:
        """Process a while statement."""
        stmt = CUDAStatement(
            kind="while",
            line=cursor.location.line,
            column=cursor.location.column
        )

        children = list(cursor.get_children())

        # Process condition and body
        if len(children) >= 1:
            stmt.condition = self._process_expression(children[0])

        if len(children) >= 2:
            body = self._process_statement(children[1])
            if body:
                stmt.body = [body]

        return stmt

    def _process_return_statement(self, cursor: Cursor) -> CUDAStatement:
        """Process a return statement."""
        stmt = CUDAStatement(
            kind="return",
            line=cursor.location.line,
            column=cursor.location.column
        )

        # Process return value if any
        children = list(cursor.get_children())
        if children:
            stmt.expression = self._process_expression(children[0])

        return stmt

    def _process_declaration_statement(self, cursor: Cursor) -> CUDAStatement:
        """Process a declaration statement."""
        stmt = CUDAStatement(
            kind="declaration",
            line=cursor.location.line,
            column=cursor.location.column
        )

        # Process all declarations in this statement
        for child in cursor.get_children():
            var = self._process_variable(child)
            if var:
                stmt.add_child(var)

        return stmt

    def _process_call_expression(self, cursor: Cursor) -> CUDAStatement:
        """Process a function call."""
        stmt = CUDAStatement(
            kind="call",
            line=cursor.location.line,
            column=cursor.location.column
        )

        # Set the function name
        stmt.expression = CUDAExpressionNode(
            spelling=cursor.spelling,
            kind="call_expr",
            line=cursor.location.line,
            column=cursor.location.column
        )

        # Process arguments
        for arg in cursor.get_arguments():
            arg_expr = self._process_expression(arg)
            if arg_expr:
                stmt.expression.add_argument(arg_expr)

        return stmt

    def _process_expression(self, cursor: Cursor) -> CUDAExpressionNode:
        """Process an expression."""
        expr = CUDAExpressionNode(
            spelling=cursor.spelling,
            kind=str(cursor.kind),
            line=cursor.location.line,
            column=cursor.location.column
        )

        # Process different expression types
        if cursor.kind == CursorKind.BINARY_OPERATOR:
            self._process_binary_operator(cursor, expr)
        elif cursor.kind == CursorKind.UNARY_OPERATOR:
            self._process_unary_operator(cursor, expr)
        elif cursor.kind == CursorKind.CALL_EXPR:
            self._process_call_expr(cursor, expr)

        return expr

    def _process_binary_operator(self, cursor: Cursor, expr: CUDAExpressionNode):
        """Process a binary operator expression."""
        children = list(cursor.get_children())
        if len(children) >= 2:
            expr.left = self._process_expression(children[0])
            expr.right = self._process_expression(children[1])

            # Try to determine the operator
            tokens = list(cursor.get_tokens())
            for i, token in enumerate(tokens):
                if i > 0 and token.kind.name == 'PUNCTUATION':
                    expr.operator = token.spelling
                    break

    def _process_unary_operator(self, cursor: Cursor, expr: CUDAExpressionNode):
        """Process a unary operator expression."""
        children = list(cursor.get_children())
        if children:
            expr.operand = self._process_expression(children[0])

            # Try to determine the operator
            tokens = list(cursor.get_tokens())
            if tokens and tokens[0].kind.name == 'PUNCTUATION':
                expr.operator = tokens[0].spelling

    def _process_call_expr(self, cursor: Cursor, expr: CUDAExpressionNode):
        """Process a function call expression."""
        # Get function name
        func_cursor = cursor.referenced
        if func_cursor:
            expr.function = func_cursor.spelling

        # Process arguments
        for arg in cursor.get_arguments():
            arg_expr = self._process_expression(arg)
            if arg_expr:
                expr.add_argument(arg_expr)

    def _process_kernel_attributes(self, cursor: Cursor, kernel: KernelNode):
        """Process CUDA kernel attributes like __launch_bounds__."""
        # Extract launch bounds if present
        for child in cursor.get_children():
            if child.kind == CursorKind.INTEGER_LITERAL:
                # Try to extract the value
                tokens = list(child.get_tokens())
                if tokens:
                    try:
                        value = int(tokens[0].spelling)
                        kernel.max_threads_per_block = value
                    except (ValueError, IndexError):
                        pass

    def _get_type_spelling(self, type_obj) -> str:
        """Get string representation of a type."""
        return type_obj.spelling

    def _get_qualifiers(self, cursor: Cursor) -> List[CUDAQualifier]:
        """Extract qualifiers from a cursor."""
        qualifiers = []

        # Check for const qualifier
        if cursor.type.is_const_qualified():
            qualifiers.append(CUDAQualifier.CONST)

        # Check for CUDA specific qualifiers
        for child in cursor.get_children():
            if child.kind == CursorKind.CUDA_SHARED_ATTR:
                qualifiers.append(CUDAQualifier.SHARED)
            elif child.kind == CursorKind.CUDA_DEVICE_ATTR:
                qualifiers.append(CUDAQualifier.DEVICE)
            elif child.kind == CursorKind.CUDA_CONSTANT_ATTR:
                qualifiers.append(CUDAQualifier.CONST)

        return qualifiers
Class: ('CudaParser', '')
--------------------------------------------------------------------------------
  Method: get('ProgramFiles', 'C:\\Program Files')


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\parser\cuda_syntax_validator.py

# cuda_syntax_validator.py

import re
from typing import List, Dict, Set, Optional, Tuple, Any
from enum import Enum
import clang.cindex
from clang.cindex import CursorKind, TypeKind

from ..utils.error_handler import CudaParseError, raise_cuda_parse_error
from ..utils.logger import get_logger

logger = get_logger(__name__)

class CudaVersion(Enum):
    """Supported CUDA versions"""
    CUDA_8_0 = "8.0"
    CUDA_9_0 = "9.0"
    CUDA_10_0 = "10.0"
    CUDA_11_0 = "11.0"
    CUDA_12_0 = "12.0"

class CudaSyntaxValidator:
    """
    Validates CUDA syntax and ensures compatibility with Metal translation.
    Provides detailed error reporting and suggestions for incompatible features.
    """

    def __init__(self, cuda_version: CudaVersion = CudaVersion.CUDA_11_0):
        self.cuda_version = cuda_version
        self.index = clang.cindex.Index.create()
        self.translation_unit = None

        # Initialize validation rules
        self._init_validation_rules()

        # Tracking state
        self.errors: List[Dict] = []
        self.warnings: List[Dict] = []
        self.unsupported_features: Set[str] = set()

    def _init_validation_rules(self):
        """Initialize validation rules based on CUDA version."""
        self.disallowed_features = {
            # Features not supported in Metal
            'texture1D',
            'texture3D',
            'cudaTextureObject3D',
            '__launch_bounds__',
            'cooperative_groups',
            'dynamic_parallelism',

            # CUDA-specific intrinsics without direct Metal equivalents
            '__ballot_sync',
            '__match_all_sync',
            '__match_any_sync',
            '__activemask',
        }

        self.warning_features = {
            # Features that may need manual optimization
            'atomicAdd',  # Needs special handling in Metal
            'warpSize',   # Different in Metal
            '__syncthreads',  # Different synchronization model
        }

        self.version_specific_features = {
            CudaVersion.CUDA_11_0: {
                'cooperative_groups',
                'cudaLaunchCooperativeKernel',
            }
        }

    def validate_file(self, file_path: str) -> Tuple[bool, List[Dict]]:
        """
        Validate a CUDA source file.

        Args:
            file_path: Path to CUDA source file

        Returns:
            Tuple of (is_valid, list of errors/warnings)
        """
        try:
            self.translation_unit = self.index.parse(
                file_path,
                args=['-x', 'cuda', '--cuda-gpu-arch=sm_70'],
                options=clang.cindex.TranslationUnit.PARSE_DETAILED_PROCESSING_RECORD
            )
        except Exception as e:
            raise_cuda_parse_error(f"Failed to parse CUDA file: {str(e)}", filename=file_path)

        # Clear previous state
        self.errors.clear()
        self.warnings.clear()
        self.unsupported_features.clear()

        # Validate translation unit
        self._validate_translation_unit(self.translation_unit.cursor)

        # Check for errors in the translation unit
        for diag in self.translation_unit.diagnostics:
            if diag.severity >= diag.Error:
                self.errors.append({
                    'line': diag.location.line,
                    'column': diag.location.column,
                    'message': diag.spelling,
                    'severity': 'error'
                })
            elif diag.severity == diag.Warning:
                self.warnings.append({
                    'line': diag.location.line,
                    'column': diag.location.column,
                    'message': diag.spelling,
                    'severity': 'warning'
                })

        return len(self.errors) == 0, self.errors + self.warnings

    def _validate_translation_unit(self, cursor: clang.cindex.Cursor):
        """Recursively validate the translation unit."""
        self._validate_node(cursor)
        for child in cursor.get_children():
            self._validate_translation_unit(child)

    def _validate_node(self, node: clang.cindex.Cursor):
        """Validate a single AST node."""
        # Check for disallowed features
        if self._is_disallowed_feature(node):
            self.errors.append({
                'line': node.location.line,
                'column': node.location.column,
                'message': f"Feature '{node.spelling}' is not supported in Metal",
                'severity': 'error',
                'feature': node.spelling
            })
            self.unsupported_features.add(node.spelling)

        # Check for warning features
        if self._is_warning_feature(node):
            self.warnings.append({
                'line': node.location.line,
                'column': node.location.column,
                'message': f"Feature '{node.spelling}' may require manual optimization in Metal",
                'severity': 'warning',
                'feature': node.spelling
            })

        # Validate memory spaces
        if node.kind == CursorKind.VAR_DECL:
            self._validate_memory_space(node)

        # Validate kernel functions
        if self._is_kernel_function(node):
            self._validate_kernel_function(node)

        # Validate atomic operations
        if self._is_atomic_operation(node):
            self._validate_atomic_operation(node)

        # Validate texture operations
        if self._is_texture_operation(node):
            self._validate_texture_operation(node)

    def _validate_memory_space(self, node: clang.cindex.Cursor):
        """Validate memory space declarations."""
        storage_class = node.storage_class

        if storage_class == clang.cindex.StorageClass.CUDA_DEVICE:
            # Validate device memory usage
            pass
        elif storage_class == clang.cindex.StorageClass.CUDA_CONSTANT:
            # Validate constant memory usage
            self._validate_constant_memory(node)
        elif storage_class == clang.cindex.StorageClass.CUDA_SHARED:
            # Validate shared memory usage
            self._validate_shared_memory(node)

    def _validate_kernel_function(self, node: clang.cindex.Cursor):
        """Validate CUDA kernel function."""
        # Check parameter types
        for param in node.get_arguments():
            param_type = param.type
            if not self._is_valid_kernel_parameter_type(param_type):
                self.errors.append({
                    'line': param.location.line,
                    'column': param.location.column,
                    'message': f"Invalid kernel parameter type: {param_type.spelling}",
                    'severity': 'error'
                })

        # Check function attributes
        attrs = node.get_children()
        for attr in attrs:
            if attr.kind == CursorKind.CUDA_GLOBAL_ATTR:
                self._validate_kernel_attributes(attr)

    def _validate_atomic_operation(self, node: clang.cindex.Cursor):
        """Validate atomic operations."""
        # Check if atomic operation is supported in Metal
        op_name = node.spelling
        if not self._is_supported_atomic_operation(op_name):
            self.errors.append({
                'line': node.location.line,
                'column': node.location.column,
                'message': f"Atomic operation '{op_name}' is not supported in Metal",
                'severity': 'error'
            })

        # Check operand types
        for arg in node.get_arguments():
            if not self._is_valid_atomic_operand_type(arg.type):
                self.warnings.append({
                    'line': arg.location.line,
                    'column': arg.location.column,
                    'message': f"Atomic operation on type {arg.type.spelling} may have different behavior in Metal",
                    'severity': 'warning'
                })

    def _validate_texture_operation(self, node: clang.cindex.Cursor):
        """Validate texture operations."""
        # Check texture dimensionality
        tex_type = node.type
        if self._is_unsupported_texture_type(tex_type):
            self.errors.append({
                'line': node.location.line,
                'column': node.location.column,
                'message': f"Texture type {tex_type.spelling} is not supported in Metal",
                'severity': 'error'
            })

        # Check texture access patterns
        for child in node.get_children():
            if child.kind == CursorKind.MEMBER_REF_EXPR:
                self._validate_texture_access(child)

    def _is_disallowed_feature(self, node: clang.cindex.Cursor) -> bool:
        """Check if node represents a disallowed feature."""
        if node.spelling in self.disallowed_features:
            return True

        # Check version-specific features
        if self.cuda_version in self.version_specific_features:
            version_features = self.version_specific_features[self.cuda_version]
            return node.spelling in version_features

        return False

    def _is_warning_feature(self, node: clang.cindex.Cursor) -> bool:
        """Check if node represents a feature that should generate a warning."""
        return node.spelling in self.warning_features

    def _is_kernel_function(self, node: clang.cindex.Cursor) -> bool:
        """Check if node is a CUDA kernel function."""
        return (node.kind == CursorKind.FUNCTION_DECL and
                any(child.kind == CursorKind.CUDA_GLOBAL_ATTR
                    for child in node.get_children()))

    def _is_atomic_operation(self, node: clang.cindex.Cursor) -> bool:
        """Check if node is an atomic operation."""
        return (node.kind == CursorKind.CALL_EXPR and
                node.spelling.startswith('atomic'))

    def _is_texture_operation(self, node: clang.cindex.Cursor) -> bool:
        """Check if node is a texture operation."""
        return (node.kind == CursorKind.CALL_EXPR and
                ('tex' in node.spelling.lower() or
                 'texture' in node.spelling.lower()))

    def _is_valid_kernel_parameter_type(self, type_obj: clang.cindex.Type) -> bool:
        """Check if type is valid for kernel parameters."""
        # Basic types are always valid
        if type_obj.kind in [TypeKind.VOID, TypeKind.BOOL, TypeKind.INT,
                             TypeKind.FLOAT, TypeKind.DOUBLE]:
            return True

        # Pointer types need to be checked
        if type_obj.kind == TypeKind.POINTER:
            pointee = type_obj.get_pointee()
            return self._is_valid_kernel_parameter_type(pointee)

        # Array types need special handling
        if type_obj.kind == TypeKind.CONSTANTARRAY:
            element_type = type_obj.get_array_element_type()
            return self._is_valid_kernel_parameter_type(element_type)

        return False

    def _is_supported_atomic_operation(self, op_name: str) -> bool:
        """Check if atomic operation is supported in Metal."""
        supported_atomics = {
            'atomicAdd',
            'atomicSub',
            'atomicExch',
            'atomicMin',
            'atomicMax',
            'atomicAnd',
            'atomicOr',
            'atomicXor',
        }
        return op_name in supported_atomics

    def _is_valid_atomic_operand_type(self, type_obj: clang.cindex.Type) -> bool:
        """Check if type is valid for atomic operations."""
        valid_types = [
            TypeKind.INT,
            TypeKind.UINT,
            TypeKind.LONG,
            TypeKind.ULONG,
        ]
        return type_obj.kind in valid_types

    def _is_unsupported_texture_type(self, type_obj: clang.cindex.Type) -> bool:
        """Check if texture type is unsupported in Metal."""
        type_spelling = type_obj.spelling.lower()
        return ('texture1d' in type_spelling or
                'texture3d' in type_spelling or
                'cubemap' in type_spelling)

    def _validate_constant_memory(self, node: clang.cindex.Cursor):
        """Validate constant memory usage."""
        # Check size limitations
        if hasattr(node, 'type') and hasattr(node.type, 'get_size'):
            size = node.type.get_size()
            if size > 64 * 1024:  # Metal constant buffer size limit
                self.warnings.append({
                    'line': node.location.line,
                    'column': node.location.column,
                    'message': f"Constant memory size ({size} bytes) exceeds Metal's recommended limit",
                    'severity': 'warning'
                })

    def _validate_shared_memory(self, node: clang.cindex.Cursor):
        """Validate shared memory usage."""
        # Check size limitations
        if hasattr(node, 'type') and hasattr(node.type, 'get_size'):
            size = node.type.get_size()
            if size > 32 * 1024:  # Metal threadgroup memory size limit
                self.errors.append({
                    'line': node.location.line,
                    'column': node.location.column,
                    'message': f"Shared memory size ({size} bytes) exceeds Metal's limit",
                    'severity': 'error'
                })

    def _validate_kernel_attributes(self, attr_node: clang.cindex.Cursor):
        """Validate kernel attributes."""
        # Check for unsupported attributes
        unsupported_attrs = {
            'maxntidx',
            'maxnreg',
            'dynamic_shared_mem_size'
        }

        for child in attr_node.get_children():
            if child.spelling in unsupported_attrs:
                self.warnings.append({
                    'line': child.location.line,
                    'column': child.location.column,
                    'message': f"Kernel attribute '{child.spelling}' is not supported in Metal",
                    'severity': 'warning'
                })

    def _validate_texture_access(self, node: clang.cindex.Cursor):
        """Validate texture access patterns."""
        # Check for unsupported texture operations
        unsupported_ops = {
            'getLod',
            'getGrad',
            'fetch',
        }

        if node.spelling in unsupported_ops:
            self.warnings.append({
                'line': node.location.line,
                'column': node.location.column,
                'message': f"Texture operation '{node.spelling}' may not have direct equivalent in Metal",
                'severity': 'warning'
            })

        # Validate texture coordinates
        for arg in node.get_arguments():
            if not self._is_valid_texture_coordinate(arg):
                self.errors.append({
                    'line': arg.location.line,
                    'column': arg.location.column,
                    'message': f"Invalid texture coordinate type: {arg.type.spelling}",
                    'severity': 'error'
                })

    def _is_valid_texture_coordinate(self, node: clang.cindex.Cursor) -> bool:
        """Check if node represents a valid texture coordinate."""
        valid_types = {
            TypeKind.FLOAT,
            TypeKind.INT,
            TypeKind.UINT
        }
        return node.type.kind in valid_types

    def get_diagnostics(self) -> Dict[str, List[Dict]]:
        """Get all diagnostic messages."""
        return {
            'errors': self.errors,
            'warnings': self.warnings,
            'unsupported_features': list(self.unsupported_features)
        }

    def get_metal_compatibility_report(self) -> Dict[str, Any]:
        """Generate a detailed Metal compatibility report."""
        return {
            'cuda_version': self.cuda_version.value,
            'is_compatible': len(self.errors) == 0,
            'error_count': len(self.errors),
            'warning_count': len(self.warnings),
            'unsupported_features': list(self.unsupported_features),
            'required_changes': self._generate_required_changes(),
            'optimization_suggestions': self._generate_optimization_suggestions()
        }

    def _generate_required_changes(self) -> List[Dict]:
        """Generate list of required changes for Metal compatibility."""
        changes = []

        # Group errors by type
        error_types = {}
        for error in self.errors:
            error_type = error.get('feature', 'other')
            if error_type not in error_types:
                error_types[error_type] = []
            error_types[error_type].append(error)

        # Generate change requirements
        for feature, errors in error_types.items():
            change = {
                'feature': feature,
                'count': len(errors),
                'locations': [{'line': e['line'], 'column': e['column']} for e in errors],
                'suggestion': self._get_change_suggestion(feature)
            }
            changes.append(change)

        return changes

    def _generate_optimization_suggestions(self) -> List[Dict]:
        """Generate optimization suggestions for better Metal performance."""
        suggestions = []

        # Memory access patterns
        if self._has_uncoalesced_memory_access():
            suggestions.append({
                'type': 'memory_access',
                'description': 'Optimize memory access patterns for coalescing',
                'importance': 'high'
            })

        # Thread hierarchy
        if self._has_suboptimal_thread_hierarchy():
            suggestions.append({
                'type': 'thread_hierarchy',
                'description': 'Adjust thread hierarchy for Metal\'s SIMD width',
                'importance': 'medium'
            })

        # Atomic operations
        if self._has_heavy_atomic_usage():
            suggestions.append({
                'type': 'atomic_operations',
                'description': 'Consider alternative algorithms to reduce atomic operations',
                'importance': 'high'
            })

        return suggestions

    def _get_change_suggestion(self, feature: str) -> str:
        """Get suggestion for handling unsupported feature."""
        suggestions = {
            'texture1D': 'Use texture2D with height=1 instead',
            'texture3D': 'Consider restructuring algorithm to use multiple texture2D layers',
            '__launch_bounds__': 'Remove launch bounds and use Metal\'s threadgroup size defaults',
            'cooperative_groups': 'Restructure algorithm to use Metal\'s threading model',
            'dynamic_parallelism': 'Flatten kernel hierarchy or split into multiple passes',
            '__ballot_sync': 'Use Metal\'s simd_vote instead',
            '__match_all_sync': 'Use Metal\'s simd_all instead',
            '__match_any_sync': 'Use Metal\'s simd_any instead',
            '__activemask': 'Use Metal\'s simd_active_threads_mask instead'
        }

        return suggestions.get(feature, 'Requires manual adaptation for Metal')

    def _has_uncoalesced_memory_access(self) -> bool:
        """Check for uncoalesced memory access patterns."""
        # Analyze memory access patterns in the AST
        uncoalesced = False

        def visit(node):
            nonlocal uncoalesced
            if self._is_array_access(node):
                if not self._is_coalesced_access(node):
                    uncoalesced = True
            for child in node.get_children():
                visit(child)

        if self.translation_unit:
            visit(self.translation_unit.cursor)

        return uncoalesced

    def _has_suboptimal_thread_hierarchy(self) -> bool:
        """Check for suboptimal thread hierarchy."""
        for node in self.translation_unit.cursor.walk_preorder():
            if self._is_kernel_function(node):
                dim = self._get_thread_dimensions(node)
                if not self._is_optimal_thread_dim(dim):
                    return True
        return False

    def _has_heavy_atomic_usage(self) -> bool:
        """Check for heavy atomic operation usage."""
        atomic_count = 0
        threshold = 10  # Arbitrary threshold for "heavy" usage

        for node in self.translation_unit.cursor.walk_preorder():
            if self._is_atomic_operation(node):
                atomic_count += 1
                if atomic_count > threshold:
                    return True

        return False

    def _is_array_access(self, node: clang.cindex.Cursor) -> bool:
        """Check if node represents array access."""
        return node.kind == CursorKind.ARRAY_SUBSCRIPT_EXPR

    def _is_coalesced_access(self, node: clang.cindex.Cursor) -> bool:
        """Check if array access is coalesced."""
        # Check if innermost index is thread index
        index = None
        for child in node.get_children():
            if child.kind == CursorKind.INTEGER_LITERAL:
                index = child

        if not index:
            return False

        return self._is_thread_index_based(index)

    def _is_thread_index_based(self, node: clang.cindex.Cursor) -> bool:
        """Check if expression is based on thread index."""
        if node.kind == CursorKind.UNEXPOSED_EXPR:
            for child in node.get_children():
                if 'threadIdx' in child.spelling:
                    return True
        return False

    def _get_thread_dimensions(self, kernel_node: clang.cindex.Cursor) -> Optional[Tuple[int, int, int]]:
        """Extract thread dimensions from kernel launch parameters."""
        for node in kernel_node.walk_preorder():
            if node.spelling == 'blockDim':
                dims = []
                for child in node.get_children():
                    if child.kind == CursorKind.INTEGER_LITERAL:
                        dims.append(child.get_tokens().next().spelling)
                if len(dims) == 3:
                    return tuple(map(int, dims))
        return None

    def _is_optimal_thread_dim(self, dim: Optional[Tuple[int, int, int]]) -> bool:
        """Check if thread dimensions are optimal for Metal."""
        if not dim:
            return False

        x, y, z = dim

        # Check if total threads is within Metal limits
        total_threads = x * y * z
        if total_threads > 1024:  # Metal maximum threads per threadgroup
            return False

        # Check if x dimension is multiple of SIMD width
        if x % 32 != 0:  # Metal SIMD width is 32
            return False

        return True

logger.info("CudaSyntaxValidator initialized for CUDA code validation.")

Class: ('CudaVersion', '(Enum)')
--------------------------------------------------------------------------------
  Method: get('feature', 'other')
  Method: get(feature, 'Requires manual adaptation for Metal')

Class: ('CudaSyntaxValidator', '')
--------------------------------------------------------------------------------
  Method: get('feature', 'other')
  Method: get(feature, 'Requires manual adaptation for Metal')


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\parser\__init__.py

"""
CUDA Parser Module Initialization
Provides complete type system and node hierarchy for CUDA to Metal translation.

Usage:
    from CUDAM.parser import CUDAKernel, CUDAType, CUDAQualifier
"""

# Core node system imports using absolute imports
from core.parser.ast_nodes import (
    # Core node types and enums
    CUDANode,
    CUDAKernel,
    CUDAParameter,
    CUDAType,
    CUDAQualifier,
    CUDASharedMemory,
    CUDAThreadIdx,
    CUDABarrier,
    CUDACompoundStmt,
    CUDAExpressionNode,
    CUDAStatement,
    FunctionNode,
    KernelNode,
    VariableNode,
    StructNode,
    EnumNode,
    TypedefNode,
    ClassNode,
    NamespaceNode,
    TemplateNode,
    CudaASTNode,
    CudaTranslationContext
)

# Core configuration
VERSION = "1.0.0"
METAL_TARGET = "2.4"
OPTIMIZATION_LEVEL = 2

# Public API - Defines exactly what gets exported
__all__ = [
    "CUDANode",
    "CUDAKernel",
    "CUDAParameter",
    "CUDAType",
    "CUDAQualifier",
    "CUDASharedMemory",
    "CUDAThreadIdx",
    "CUDABarrier",
    "CUDACompoundStmt",
    "CUDAExpressionNode",
    "CUDAStatement",
    "FunctionNode",
    "KernelNode",
    "VariableNode",
    "StructNode",
    "EnumNode",
    "TypedefNode",
    "ClassNode",
    "NamespaceNode",
    "TemplateNode",
    "CudaASTNode",
    "CudaTranslationContext"
]

# Convenience aliases
KernelNode = CUDAKernel
ParameterNode = CUDAParameter
CompoundStmtNode = CUDACompoundStmt

# Initialize configuration
def init_translation(
        source_file: str,
        metal_target: str = METAL_TARGET,
        optimization_level: int = OPTIMIZATION_LEVEL
) -> CudaTranslationContext:
    """Initialize AST translation context with specified parameters."""
    return CudaTranslationContext(
        source_file=source_file,
        metal_target=metal_target,
        optimization_level=optimization_level
    )

# Error checking and validation
def validate_ast(node: CUDANode) -> bool:
    """Validate AST node and its children for Metal compatibility."""
    if not isinstance(node, CUDANode):
        return False
    return all(validate_ast(child) for child in node.children)


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\templates\unifier.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\templates\metal\header_template.h

#ifndef CUDAMetalKernel_h
#define CUDAMetalKernel_h

#include <metal_stdlib>
#include <metal_atomic>
#include <metal_simdgroup>
#include <metal_math>

using namespace metal;

// CUDA-style vector types
struct int2 { int x, y; };
struct int3 { int x, y, z; };
struct int4 { int x, y, z, w; };
struct uint2 { uint x, y; };
struct uint3 { uint x, y, z; };
struct uint4 { uint x, y, z, w; };
struct float2 { float x, y; };
struct float3 { float x, y, z; };
struct float4 { float x, y, z, w; };

// Thread indexing
#define threadIdx_x (thread_position_in_threadgroup.x)
#define threadIdx_y (thread_position_in_threadgroup.y)
#define threadIdx_z (thread_position_in_threadgroup.z)
#define blockIdx_x (threadgroup_position_in_grid.x)
#define blockIdx_y (threadgroup_position_in_grid.y)
#define blockIdx_z (threadgroup_position_in_grid.z)
#define blockDim_x (threads_per_threadgroup.x)
#define blockDim_y (threads_per_threadgroup.y)
#define blockDim_z (threads_per_threadgroup.z)
#define gridDim_x (threadgroups_per_grid.x)
#define gridDim_y (threadgroups_per_grid.y)
#define gridDim_z (threadgroups_per_grid.z)

// Common kernel parameters structure
struct KernelParameters {
    uint problemSize;
    uint batchSize;
    float learningRate;
    float4 reserved;  // For alignment
};

// CUDA synchronization primitives
#define __syncthreads() threadgroup_barrier(mem_flags::mem_threadgroup)
#define __threadfence() threadgroup_barrier(mem_flags::mem_device)
#define __threadfence_block() threadgroup_barrier(mem_flags::mem_threadgroup)

// CUDA atomic operations
template<typename T>
METAL_FUNC T atomicAdd(device atomic_uint* addr, T val) {
    return atomic_fetch_add_explicit(addr, val, memory_order_relaxed);
}

template<typename T>
METAL_FUNC T atomicMax(device atomic_uint* addr, T val) {
    return atomic_fetch_max_explicit(addr, val, memory_order_relaxed);
}

// CUDA math functions
#define __fdividef(x, y) ((x) / (y))
#define __expf(x) metal::exp(x)
#define __logf(x) metal::log(x)
#define __powf(x, y) metal::pow(x, y)

// SIMD group operations
#define METAL_WARP_SIZE 32
#define warpSize METAL_WARP_SIZE

METAL_FUNC uint get_lane_id() {
    return threadIdx_x & (METAL_WARP_SIZE - 1);
}

METAL_FUNC uint get_warp_id() {
    return threadIdx_x >> 5;
}

// Memory space qualifiers
#define __shared__ threadgroup
#define __constant__ constant
#define __device__ device

#endif /* CUDAMetalKernel_h */

--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\templates\metal\kernel_template.metal

#include <metal_stdlib>
#include <metal_atomic>
#include <metal_simdgroup>
#include <metal_math>

using namespace metal;

// Utility functions for thread/block mapping
namespace cuda {
    // Thread indexing
    struct uint3 {
        uint x, y, z;
    };

    struct float3 {
        float x, y, z;
    };

    // Device functions for CUDA compatibility
    METAL_FUNC uint3 get_thread_idx(
        uint3 thread_position_in_threadgroup,
        uint3 threads_per_threadgroup
    ) {
        return uint3{
            thread_position_in_threadgroup.x,
            thread_position_in_threadgroup.y,
            thread_position_in_threadgroup.z
        };
    }

    METAL_FUNC uint3 get_block_idx(
        uint3 threadgroup_position_in_grid,
        uint3 threads_per_threadgroup
    ) {
        return uint3{
            threadgroup_position_in_grid.x,
            threadgroup_position_in_grid.y,
            threadgroup_position_in_grid.z
        };
    }

    // Atomic operations
    template<typename T>
    METAL_FUNC T atomicAdd(device atomic_uint* addr, T val) {
        return atomic_fetch_add_explicit(addr, val, memory_order_relaxed);
    }

    template<typename T>
    METAL_FUNC T atomicMax(device atomic_uint* addr, T val) {
        return atomic_fetch_max_explicit(addr, val, memory_order_relaxed);
    }

    // Sync functions
    METAL_FUNC void __syncthreads() {
        threadgroup_barrier(mem_flags::mem_threadgroup);
    }

    METAL_FUNC void __threadfence() {
        threadgroup_barrier(mem_flags::mem_device);
    }

    // Math functions
    METAL_FUNC float __fdividef(float a, float b) {
        return a / b;
    }

    METAL_FUNC float __expf(float x) {
        return metal::exp(x);
    }
}

// Kernel struct for shared state
struct KernelState {
    uint3 thread_idx;
    uint3 block_idx;
    uint3 block_dim;
    uint3 grid_dim;
    uint simd_lane_id;
    uint simd_group_id;
};

// Initialize kernel state
METAL_FUNC KernelState init_kernel_state(
    uint3 thread_position_in_threadgroup [[thread_position_in_threadgroup]],
    uint3 threadgroup_position_in_grid [[threadgroup_position_in_grid]],
    uint3 threads_per_threadgroup [[threads_per_threadgroup]],
    uint3 threadgroups_per_grid [[threadgroups_per_grid]]
) {
    KernelState state;

    state.thread_idx = cuda::get_thread_idx(
        thread_position_in_threadgroup,
        threads_per_threadgroup
    );

    state.block_idx = cuda::get_block_idx(
        threadgroup_position_in_grid,
        threads_per_threadgroup
    );

    state.block_dim = threads_per_threadgroup;
    state.grid_dim = threadgroups_per_grid;

    state.simd_lane_id = thread_position_in_threadgroup.x & 0x1F;
    state.simd_group_id = thread_position_in_threadgroup.x >> 5;

    return state;
}

// Common kernel parameters struct
struct KernelParams {
    uint problem_size;
    uint batch_size;
    float learning_rate;
    // Add other common parameters
};

// Example kernel - will be replaced by translation
kernel void example_kernel(
    device float* input [[buffer(0)]],
    device float* output [[buffer(1)]],
    constant KernelParams& params [[buffer(2)]],
    uint3 thread_position_in_threadgroup [[thread_position_in_threadgroup]],
    uint3 threadgroup_position_in_grid [[threadgroup_position_in_grid]],
    uint3 threads_per_threadgroup [[threads_per_threadgroup]],
    uint3 threadgroups_per_grid [[threadgroups_per_grid]]
) {
    // Initialize kernel state
    KernelState state = init_kernel_state(
        thread_position_in_threadgroup,
        threadgroup_position_in_grid,
        threads_per_threadgroup,
        threadgroups_per_grid
    );

    // Example shared memory
    threadgroup float shared_data[1024];

    // Example CUDA-style indexing
    uint idx = (state.block_idx.x * state.block_dim.x) + state.thread_idx.x;
    if (idx >= params.problem_size) return;

    // Example computation with shared memory
    shared_data[state.thread_idx.x] = input[idx];
    cuda::__syncthreads();

    output[idx] = shared_data[state.thread_idx.x] * params.learning_rate;
}
// CUDA Performance Primitives (cuBLAS-like functions)
namespace cublas {
    // Matrix multiply
    METAL_FUNC void gemm(
        device const float* A,
        device const float* B,
        device float* C,
        uint M, uint N, uint K,
        threadgroup float* shared_mem [[threadgroup(0)]]
    ) {
        constexpr uint TILE_SIZE = 16;
        uint2 tid = uint2(threadIdx_x, threadIdx_y);
        uint2 bid = uint2(blockIdx_x, blockIdx_y);

        // Tile start positions
        uint row = bid.y * TILE_SIZE + tid.y;
        uint col = bid.x * TILE_SIZE + tid.x;

        // Accumulator for dot product
        float acc = 0.0f;

        // Loop over tiles
        for (uint t = 0; t < K; t += TILE_SIZE) {
            // Load tile into shared memory
            threadgroup float* tile_A = shared_mem;
            threadgroup float* tile_B = shared_mem + TILE_SIZE * TILE_SIZE;

            if (row < M && (t + tid.x) < K)
                tile_A[tid.y * TILE_SIZE + tid.x] = A[row * K + t + tid.x];
            if (col < N && (t + tid.y) < K)
                tile_B[tid.y * TILE_SIZE + tid.x] = B[(t + tid.y) * N + col];

            threadgroup_barrier(mem_flags::mem_threadgroup);

            // Compute partial dot product
            for (uint k = 0; k < TILE_SIZE; k++) {
                acc += tile_A[tid.y * TILE_SIZE + k] *
                       tile_B[k * TILE_SIZE + tid.x];
            }

            threadgroup_barrier(mem_flags::mem_threadgroup);
        }

        // Store result
        if (row < M && col < N)
            C[row * N + col] = acc;
    }

    // Vector operations
    METAL_FUNC void axpy(
        device const float* x,
        device float* y,
        float alpha,
        uint n
    ) {
        uint idx = (blockIdx_x * blockDim_x) + threadIdx_x;
        if (idx < n)
            y[idx] = alpha * x[idx] + y[idx];
    }
}

// Common Deep Learning Primitives
namespace cudnn {
    // ReLU activation
    METAL_FUNC void relu(
        device const float* input,
        device float* output,
        uint size
    ) {
        uint idx = (blockIdx_x * blockDim_x) + threadIdx_x;
        if (idx < size)
            output[idx] = max(0.0f, input[idx]);
    }

    // Softmax
    METAL_FUNC void softmax(
        device const float* input,
        device float* output,
        uint batch_size,
        uint feature_size,
        threadgroup float* shared_mem [[threadgroup(0)]]
    ) {
        uint tid = threadIdx_x;
        uint bid = blockIdx_x;

        if (bid >= batch_size) return;

        // Find max value
        float max_val = -INFINITY;
        for (uint i = tid; i < feature_size; i += blockDim_x)
            max_val = max(max_val, input[bid * feature_size + i]);

        threadgroup float* shared_max = shared_mem;
        shared_max[tid] = max_val;
        threadgroup_barrier(mem_flags::mem_threadgroup);

        // Reduce to find global max
        for (uint stride = blockDim_x/2; stride > 0; stride >>= 1) {
            if (tid < stride)
                shared_max[tid] = max(shared_max[tid], shared_max[tid + stride]);
            threadgroup_barrier(mem_flags::mem_threadgroup);
        }
        max_val = shared_max[0];

        // Compute exp and sum
        float sum = 0.0f;
        for (uint i = tid; i < feature_size; i += blockDim_x) {
            float val = exp(input[bid * feature_size + i] - max_val);
            output[bid * feature_size + i] = val;
            sum += val;
        }

        threadgroup float* shared_sum = shared_mem;
        shared_sum[tid] = sum;
        threadgroup_barrier(mem_flags::mem_threadgroup);

        // Reduce to find global sum
        for (uint stride = blockDim_x/2; stride > 0; stride >>= 1) {
            if (tid < stride)
                shared_sum[tid] += shared_sum[tid + stride];
            threadgroup_barrier(mem_flags::mem_threadgroup);
        }
        sum = shared_sum[0];

        // Normalize
        for (uint i = tid; i < feature_size; i += blockDim_x)
            output[bid * feature_size + i] /= sum;
    }
}

// Memory optimization utilities
namespace cuda_utils {
    // Coalesced memory copy
    METAL_FUNC void coalesced_copy(
        device const float* src,
        device float* dst,
        uint size
    ) {
        uint idx = (blockIdx_x * blockDim_x) + threadIdx_x;
        if (idx >= size) return;

        // Vector load/store when possible
        if ((idx + 3) < size && (idx % 4) == 0) {
            float4 vec = *reinterpret_cast<device const float4*>(&src[idx]);
            *reinterpret_cast<device float4*>(&dst[idx]) = vec;
        } else if (idx < size) {
            dst[idx] = src[idx];
        }
    }

    // Strided memory access pattern
    METAL_FUNC void strided_copy(
        device const float* src,
        device float* dst,
        uint size,
        uint stride
    ) {
        uint idx = threadIdx_x + blockDim_x * blockIdx_x;
        uint offset = idx * stride;

        if (offset >= size) return;

        for (uint i = 0; i < stride && (offset + i) < size; i++)
            dst[offset + i] = src[offset + i];
    }
}

// Warp-level primitives
namespace cuda_warp {
    // Warp reduce sum
    METAL_FUNC float warp_reduce_sum(float val) {
        const uint lane_id = get_lane_id();

        // Butterfly reduction
        for (uint offset = METAL_WARP_SIZE/2; offset > 0; offset >>= 1)
            val += simd_shuffle_xor(val, offset);

        return val;
    }

    // Warp reduce max
    METAL_FUNC float warp_reduce_max(float val) {
        const uint lane_id = get_lane_id();

        for (uint offset = METAL_WARP_SIZE/2; offset > 0; offset >>= 1)
            val = max(val, simd_shuffle_xor(val, offset));

        return val;
    }

    // Warp broadcast
    METAL_FUNC float warp_broadcast(float val, uint src_lane) {
        return simd_broadcast(val, src_lane);
    }
}

--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\templates\msl\device_functions.metal

#include <metal_stdlib>
using namespace metal;

// Helper function that can be used by kernels
float compute_something(float value) {
    return value * 2.0;
}


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\templates\msl\kernel_template.metal

#include <metal_stdlib>
#include "device_functions.metal"
using namespace metal;

kernel void example_kernel(const device float* input [[buffer(0)]],
                           device float* output [[buffer(1)]],
                           uint id [[thread_position_in_grid]]) {
    output[id] = compute_something(input[id]);
}


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\templates\objc\cudnn_wrapper.h

#import <Foundation/Foundation.h>
#import <MetalPerformanceShaders/MetalPerformanceShaders.h>

@interface CUDNNWrapper : NSObject

- (instancetype)initWithDevice:(id<MTLDevice>)device;
- (void)performConvolutionWithInput:(MPSImage *)input
                             output:(MPSImage *)output;

@end


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\templates\objc\cudnn_wrapper.m

#import "cudnn_wrapper.h"

@implementation CUDNNWrapper {
    id<MTLDevice> _device;
    MPSNNConvolution *convolution;
}

- (instancetype)initWithDevice:(id<MTLDevice>)device {
    self = [super init];
    if (self) {
        _device = device;
        // Setup Metal Performance Shader convolution kernel
        MPSNNConvolutionDescriptor *convDesc = [[MPSNNConvolutionDescriptor alloc] initWithKernelWidth:3
                                                                                          kernelHeight:3
                                                                                      inputFeatureChannels:1
                                                                                     outputFeatureChannels:1];
        convolution = [[MPSNNConvolution alloc] initWithDevice:_device
                                              convolutionDescriptor:convDesc];
    }
    return self;
}

- (void)performConvolutionWithInput:(MPSImage *)input
                             output:(MPSImage *)output {
    // Code to perform convolution
    // Example only: Ensure input/output handling is correct in actual code
    [convolution encodeToCommandBuffer:commandBuffer
                                sourceImage:input
                           destinationImage:output];
}

@end


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\templates\objc\kernel_wrapper.m

#import <Metal/Metal.h>
#import <MetalKit/MetalKit.h>
#import "kernel_wrapper.h"

// CUDA-style error codes
typedef NS_ENUM(NSInteger, CUDAError) {
    cudaSuccess = 0,
    cudaErrorDeviceNotFound = 1,
    cudaErrorMemoryAllocation = 2,
    cudaErrorInvalidValue = 3,
    cudaErrorLaunchFailure = 4
};

@implementation CUDAMetalDevice {
    id<MTLDevice> _device;
    id<MTLCommandQueue> _commandQueue;
    NSMutableDictionary<NSString*, id<MTLComputePipelineState>>* _kernelPipelineStates;
    NSMutableDictionary<NSString*, id<MTLFunction>>* _kernelFunctions;
    NSMutableDictionary* _allocatedBuffers;
}

- (instancetype)init {
    self = [super init];
    if (self) {
        _device = MTLCreateSystemDefaultDevice();
        if (!_device) {
            return nil;
        }

        _commandQueue = [_device newCommandQueue];
        if (!_commandQueue) {
            return nil;
        }

        _kernelPipelineStates = [NSMutableDictionary new];
        _kernelFunctions = [NSMutableDictionary new];
        _allocatedBuffers = [NSMutableDictionary new];
    }
    return self;
}

// CUDA Memory Management
- (CUDAError)cudaMalloc:(void**)ptr size:(size_t)size {
    id<MTLBuffer> buffer = [_device newBufferWithLength:size
                                              options:MTLResourceStorageModeShared];
    if (!buffer) {
        return cudaErrorMemoryAllocation;
    }

    *ptr = buffer.contents;
    [_allocatedBuffers setObject:buffer forKey:[NSValue valueWithPointer:*ptr]];

    return cudaSuccess;
}

- (CUDAError)cudaFree:(void*)ptr {
    [_allocatedBuffers removeObjectForKey:[NSValue valueWithPointer:ptr]];
    return cudaSuccess;
}

- (CUDAError)cudaMemcpy:(void*)dst
                   src:(const void*)src
                  size:(size_t)size
                  kind:(CUDAMemcpyKind)kind {
    switch (kind) {
        case cudaMemcpyHostToDevice: {
            id<MTLBuffer> buffer = [_allocatedBuffers objectForKey:[NSValue valueWithPointer:dst]];
            if (!buffer) return cudaErrorInvalidValue;
            memcpy(buffer.contents, src, size);
            break;
        }

        case cudaMemcpyDeviceToHost: {
            id<MTLBuffer> buffer = [_allocatedBuffers objectForKey:[NSValue valueWithPointer:src]];
            if (!buffer) return cudaErrorInvalidValue;
            memcpy(dst, buffer.contents, size);
            break;
        }

        case cudaMemcpyDeviceToDevice: {
            id<MTLBuffer> srcBuffer = [_allocatedBuffers objectForKey:[NSValue valueWithPointer:src]];
            id<MTLBuffer> dstBuffer = [_allocatedBuffers objectForKey:[NSValue valueWithPointer:dst]];
            if (!srcBuffer || !dstBuffer) return cudaErrorInvalidValue;

            id<MTLCommandBuffer> commandBuffer = [_commandQueue commandBuffer];
            id<MTLBlitCommandEncoder> blitEncoder = [commandBuffer blitCommandEncoder];

            [blitEncoder copyFromBuffer:srcBuffer
                         sourceOffset:0
                             toBuffer:dstBuffer
                    destinationOffset:0
                                size:size];

            [blitEncoder endEncoding];
                        [commandBuffer commit];
                        [commandBuffer waitUntilCompleted];
                        break;
                    }
                }
                return cudaSuccess;
            }

            // Kernel Management
            - (CUDAError)loadMetalLibraryWithURL:(NSURL*)url error:(NSError**)error {
                id<MTLLibrary> library = [_device newLibraryWithURL:url error:error];
                if (!library) {
                    return cudaErrorLaunchFailure;
                }

                // Load all kernel functions
                for (NSString* functionName in library.functionNames) {
                    id<MTLFunction> function = [library newFunctionWithName:functionName];
                    if (!function) continue;

                    _kernelFunctions[functionName] = function;

                    // Create pipeline state
                    id<MTLComputePipelineState> pipelineState =
                        [_device newComputePipelineStateWithFunction:function error:error];
                    if (pipelineState) {
                        _kernelPipelineStates[functionName] = pipelineState;
                    }
                }

                return cudaSuccess;
            }

            // CUDA Kernel Launch
            - (CUDAError)launchKernel:(NSString*)name
                            gridDim:(MTLSize)gridDim
                           blockDim:(MTLSize)blockDim
                          arguments:(NSArray<id<MTLBuffer>>*)arguments {

                id<MTLComputePipelineState> pipelineState = _kernelPipelineStates[name];
                if (!pipelineState) {
                    return cudaErrorLaunchFailure;
                }

                id<MTLCommandBuffer> commandBuffer = [_commandQueue commandBuffer];
                id<MTLComputeCommandEncoder> computeEncoder = [commandBuffer computeCommandEncoder];

                // Set compute pipeline state
                [computeEncoder setComputePipelineState:pipelineState];

                // Set buffer arguments
                [arguments enumerateObjectsUsingBlock:^(id<MTLBuffer> buffer, NSUInteger idx, BOOL *stop) {
                    [computeEncoder setBuffer:buffer offset:0 atIndex:idx];
                }];

                // Calculate threadgroup size
                NSUInteger threadGroupWidth = blockDim.width;
                NSUInteger threadGroupHeight = blockDim.height;
                NSUInteger threadGroupDepth = blockDim.depth;

                MTLSize threadsPerThreadgroup = MTLSizeMake(threadGroupWidth,
                                                           threadGroupHeight,
                                                           threadGroupDepth);

                // Dispatch threads
                [computeEncoder dispatchThreadgroups:gridDim
                             threadsPerThreadgroup:threadsPerThreadgroup];

                [computeEncoder endEncoding];
                [commandBuffer commit];

                return cudaSuccess;
            }

            // Helper Methods
            - (CUDAError)setBuffer:(void*)data
                             size:(size_t)size
                        forKernel:(NSString*)kernelName
                           atIndex:(NSUInteger)index {

                id<MTLBuffer> buffer = [_device newBufferWithBytes:data
                                                           length:size
                                                          options:MTLResourceStorageModeShared];
                if (!buffer) {
                    return cudaErrorMemoryAllocation;
                }

                _allocatedBuffers[[NSValue valueWithPointer:buffer.contents]] = buffer;
                return cudaSuccess;
            }

            // CUDA Event Management
            - (CUDAError)cudaEventCreate:(cudaEvent_t*)event {
                *event = (cudaEvent_t)[_device newEvent];
                return cudaSuccess;
            }

            - (CUDAError)cudaEventRecord:(cudaEvent_t)event stream:(cudaStream_t)stream {
                id<MTLCommandBuffer> commandBuffer = (__bridge id<MTLCommandBuffer>)stream;
                [commandBuffer encodeWait:(__bridge id<MTLEvent>)event value:0];
                return cudaSuccess;
            }

            - (CUDAError)cudaEventSynchronize:(cudaEvent_t)event {
                [(id<MTLEvent>)event notifyListener:nil
                                          atValue:0
                                          block:^(id<MTLEvent> event, uint64_t value){}];
                return cudaSuccess;
            }

            // CUDA Stream Management
            - (CUDAError)cudaStreamCreate:(cudaStream_t*)stream {
                *stream = (cudaStream_t)CFBridgingRetain([_commandQueue commandBuffer]);
                return cudaSuccess;
            }

            - (CUDAError)cudaStreamSynchronize:(cudaStream_t)stream {
                id<MTLCommandBuffer> commandBuffer = (__bridge id<MTLCommandBuffer>)stream;
                [commandBuffer waitUntilCompleted];
                return cudaSuccess;
            }

            // Device Synchronization
            - (CUDAError)cudaDeviceSynchronize {
                [_commandQueue insertDebugCaptureBoundary];
                return cudaSuccess;
            }

            @end

            // Kernel Parameters
            @implementation KernelParameters

            - (instancetype)initWithProblemSize:(NSUInteger)problemSize
                                    batchSize:(NSUInteger)batchSize
                               learningRate:(float)learningRate {
                self = [super init];
                if (self) {
                    _problemSize = problemSize;
                    _batchSize = batchSize;
                    _learningRate = learningRate;
                }
                return self;
            }

            - (id<MTLBuffer>)asMetalBufferWithDevice:(id<MTLDevice>)device {
                return [device newBufferWithBytes:self
                                         length:sizeof(KernelParameters)
                                        options:MTLResourceStorageModeShared];
            }

            @end

            // Header file for the above implementation
            @interface CUDAMetalDevice : NSObject

            // CUDA Memory Management
            - (CUDAError)cudaMalloc:(void**)ptr size:(size_t)size;
            - (CUDAError)cudaFree:(void*)ptr;
            - (CUDAError)cudaMemcpy:(void*)dst
                               src:(const void*)src
                              size:(size_t)size
                              kind:(CUDAMemcpyKind)kind;

            // Kernel Management
            - (CUDAError)loadMetalLibraryWithURL:(NSURL*)url error:(NSError**)error;
            - (CUDAError)launchKernel:(NSString*)name
                            gridDim:(MTLSize)gridDim
                           blockDim:(MTLSize)blockDim
                          arguments:(NSArray<id<MTLBuffer>>*)arguments;

            // Event Management
            - (CUDAError)cudaEventCreate:(cudaEvent_t*)event;
            - (CUDAError)cudaEventRecord:(cudaEvent_t)event stream:(cudaStream_t)stream;
            - (CUDAError)cudaEventSynchronize:(cudaEvent_t)event;

            // Stream Management
            - (CUDAError)cudaStreamCreate:(cudaStream_t*)stream;
            - (CUDAError)cudaStreamSynchronize:(cudaStream_t)stream;

            // Device Synchronization
            - (CUDAError)cudaDeviceSynchronize;

            @end

--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\templates\objc\main.m

#import <Foundation/Foundation.h>
#import <Metal/Metal.h>
#import "metal_manager.h"

int main(int argc, const char * argv[]) {
    @autoreleasepool {
        // Check if Metal is supported
        id<MTLDevice> device = MTLCreateSystemDefaultDevice();
        if (!device) {
            NSLog(@"Metal is not supported on this device.");
            return -1;
        }

        // Initialize Metal manager
        MetalManager *metalManager = [[MetalManager alloc] initWithDevice:device];

        // Create input and output buffers
        id<MTLBuffer> inputBuffer = [device newBufferWithLength:sizeof(float) * 256 options:MTLResourceStorageModeShared];
        id<MTLBuffer> outputBuffer = [device newBufferWithLength:sizeof(float) * 256 options:MTLResourceStorageModeShared];

        // Fill input buffer with data
        float *inputPointer = (float *)[inputBuffer contents];
        for (int i = 0; i < 256; i++) {
            inputPointer[i] = (float)i;
        }

        // Execute the kernel
        [metalManager executeKernelWithName:@"example_kernel" withInput:inputBuffer outputBuffer:outputBuffer];

        // Output the results
        float *outputPointer = (float *)[outputBuffer contents];
        for (int i = 0; i < 256; i++) {
            NSLog(@"Output[%d]: %f", i, outputPointer[i]);
        }
    }
    return 0;
}


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\templates\objc\metal_manager.h

#import <Foundation/Foundation.h>
#import <Metal/Metal.h>

@interface MetalManager : NSObject

- (instancetype)initWithDevice:(id<MTLDevice>)device;
- (void)executeKernelWithName:(NSString *)kernelName
                    withInput:(id<MTLBuffer>)inputBuffer
                   outputBuffer:(id<MTLBuffer>)outputBuffer;

@end


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\templates\objc\metal_manager.m

#import "metal_manager.h"

@implementation MetalManager {
    id<MTLDevice> _device;
    id<MTLCommandQueue> _commandQueue;
}

- (instancetype)initWithDevice:(id<MTLDevice>)device {
    self = [super init];
    if (self) {
        _device = device;
        _commandQueue = [_device newCommandQueue];
    }
    return self;
}

- (void)executeKernelWithName:(NSString *)kernelName
                    withInput:(id<MTLBuffer>)inputBuffer
                   outputBuffer:(id<MTLBuffer>)outputBuffer {
    NSError *error = nil;
    id<MTLLibrary> library = [_device newDefaultLibrary];
    id<MTLFunction> function = [library newFunctionWithName:kernelName];

    if (!function) {
        NSLog(@"Failed to load kernel function: %@", kernelName);
        return;
    }

    id<MTLComputePipelineState> pipelineState = [_device newComputePipelineStateWithFunction:function error:&error];
    if (error) {
        NSLog(@"Error creating pipeline state: %@", error.localizedDescription);
        return;
    }

    id<MTLCommandBuffer> commandBuffer = [_commandQueue commandBuffer];
    id<MTLComputeCommandEncoder> commandEncoder = [commandBuffer computeCommandEncoder];

    [commandEncoder setComputePipelineState:pipelineState];
    [commandEncoder setBuffer:inputBuffer offset:0 atIndex:0];
    [commandEncoder setBuffer:outputBuffer offset:0 atIndex:1];

    MTLSize gridSize = MTLSizeMake(256, 1, 1);
    MTLSize threadGroupSize = MTLSizeMake(16, 1, 1);
    [commandEncoder dispatchThreads:gridSize threadsPerThreadgroup:threadGroupSize];

    [commandEncoder endEncoding];
    [commandBuffer commit];
    [commandBuffer waitUntilCompleted];

    NSLog(@"Kernel execution complete.");
}

@end


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\templates\objc\metal_setup.m



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\templates\swift\cudnn_wrapper.swift

import MetalPerformanceShaders

class CUDNNWrapper {
    private let device: MTLDevice
    private var convolution: MPSCNNConvolution

    init(device: MTLDevice) {
        self.device = device

        let convDesc = MPSCNNConvolutionDescriptor(kernelWidth: 3, kernelHeight: 3,
                                                   inputFeatureChannels: 1, outputFeatureChannels: 1)

        convolution = MPSCNNConvolution(device: device, convolutionDescriptor: convDesc, kernelWeights: [], biasTerms: nil)
    }

    func performConvolution(input: MPSImage, output: MPSImage, commandBuffer: MTLCommandBuffer) {
        convolution.encode(commandBuffer: commandBuffer, sourceImage: input, destinationImage: output)
    }
}


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\templates\swift\kernel_wrapper.swift

import Metal
import MetalKit

// CUDA-like host wrapper for Metal GPU kernels
class CUDAMetalDevice {
    // Metal objects
    private let device: MTLDevice
    private let commandQueue: MTLCommandQueue
    private var kernelPipelineStates: [String: MTLComputePipelineState] = [:]
    private var kernelFunctions: [String: MTLFunction] = [:]

    // Buffer management
    private var allocatedBuffers: [UnsafeMutableRawPointer: MTLBuffer] = [:]
    private var bufferSizes: [MTLBuffer: Int] = [:]

    // CUDA-like error handling
    enum CUDAError: Error {
        case deviceNotFound
        case kernelNotFound
        case outOfMemory
        case invalidValue
        case launchFailure
    }

    init() throws {
        guard let metalDevice = MTLCreateSystemDefaultDevice() else {
            throw CUDAError.deviceNotFound
        }
        self.device = metalDevice
        guard let queue = device.makeCommandQueue() else {
            throw CUDAError.deviceNotFound
        }
        self.commandQueue = queue
    }

    // CUDA Memory Management
    func cudaMalloc<T>(_ size: Int) throws -> UnsafeMutablePointer<T> {
        guard let buffer = device.makeBuffer(length: size, options: .storageModeShared) else {
            throw CUDAError.outOfMemory
        }

        let pointer = UnsafeMutableRawPointer(buffer.contents())
        allocatedBuffers[pointer] = buffer
        bufferSizes[buffer] = size

        return pointer.assumingMemoryBound(to: T.self)
    }

    func cudaFree(_ pointer: UnsafeMutableRawPointer) {
        allocatedBuffers.removeValue(forKey: pointer)
    }

    func cudaMemcpy<T>(_ dst: UnsafeMutablePointer<T>,
                       _ src: UnsafePointer<T>,
                       _ size: Int,
                       _ direction: CudaMemcpyKind) throws {
        switch direction {
        case .hostToDevice:
            guard let buffer = allocatedBuffers[UnsafeMutableRawPointer(mutating: dst)] else {
                throw CUDAError.invalidValue
            }
            memcpy(buffer.contents(), src, size)

        case .deviceToHost:
            guard let buffer = allocatedBuffers[UnsafeMutableRawPointer(mutating: src)] else {
                throw CUDAError.invalidValue
            }
            memcpy(dst, buffer.contents(), size)

        case .deviceToDevice:
            guard let srcBuffer = allocatedBuffers[UnsafeMutableRawPointer(mutating: src)],
                  let dstBuffer = allocatedBuffers[UnsafeMutableRawPointer(mutating: dst)] else {
                throw CUDAError.invalidValue
            }
            let commandBuffer = commandQueue.makeCommandBuffer()
            let blitEncoder = commandBuffer?.makeBlitCommandEncoder()
            blitEncoder?.copy(from: srcBuffer, sourceOffset: 0,
                            to: dstBuffer, destinationOffset: 0,
                            size: size)
            blitEncoder?.endEncoding()
            commandBuffer?.commit()
        }
    }

    // Kernel Management
    func loadMetalLibrary(url: URL) throws {
        guard let library = try? device.makeLibrary(URL: url) else {
            throw CUDAError.kernelNotFound
        }

        // Load all kernel functions
        for functionName in library.functionNames {
            guard let function = library.makeFunction(name: functionName) else { continue }
            kernelFunctions[functionName] = function

            // Create pipeline state
            if let pipelineState = try? device.makeComputePipelineState(function: function) {
                kernelPipelineStates[functionName] = pipelineState
            }
        }
    }

    // CUDA Kernel Launch
    func launchKernel(name: String,
                     gridSize: (Int, Int, Int),
                     blockSize: (Int, Int, Int),
                     arguments: [MTLBuffer],
                     completion: ((Error?) -> Void)? = nil) throws {
        guard let pipelineState = kernelPipelineStates[name] else {
            throw CUDAError.kernelNotFound
        }

        // Create command buffer and encoder
        guard let commandBuffer = commandQueue.makeCommandBuffer(),
              let computeEncoder = commandBuffer.makeComputeCommandEncoder() else {
            throw CUDAError.launchFailure
        }

        computeEncoder.setComputePipelineState(pipelineState)

        // Set buffers
        for (index, buffer) in arguments.enumerated() {
            computeEncoder.setBuffer(buffer, offset: 0, index: index)
        }

        // Convert sizes to Metal
        let threadsPerGrid = MTLSize(width: gridSize.0, height: gridSize.1, depth: gridSize.2)
        let threadsPerThreadgroup = MTLSize(width: blockSize.0, height: blockSize.1, depth: blockSize.2)

        // Dispatch
        computeEncoder.dispatchThreadgroups(threadsPerGrid,
                                          threadsPerThreadgroup: threadsPerThreadgroup)

        computeEncoder.endEncoding()

        if let completion = completion {
            commandBuffer.addCompletedHandler { _ in
                completion(nil)
            }
        }

        commandBuffer.commit()
    }

    // CUDA Synchronization
    func cudaDeviceSynchronize() {
        commandQueue.insertDebugCaptureBoundary()
    }

    enum CudaMemcpyKind {
        case hostToDevice
        case deviceToHost
        case deviceToDevice
    }
}

// Example usage extension
extension CUDAMetalDevice {
    func createBuffer<T>(_ data: [T]) throws -> MTLBuffer {
        let size = MemoryLayout<T>.stride * data.count
        guard let buffer = device.makeBuffer(length: size, options: .storageModeShared) else {
            throw CUDAError.outOfMemory
        }
        memcpy(buffer.contents(), data, size)
        return buffer
    }
// Advanced Memory Management
extension CUDAMetalDevice {
    // 2D Memory Allocation
    func cudaMallocPitch<T>(width: Int, height: Int) throws -> (UnsafeMutablePointer<T>, Int) {
        let pitch = (width * MemoryLayout<T>.stride + 255) & ~255 // 256-byte alignment
        let size = pitch * height

        guard let buffer = device.makeBuffer(length: size, options: .storageModeShared) else {
            throw CUDAError.outOfMemory
        }

        let pointer = buffer.contents().assumingMemoryBound(to: T.self)
        allocatedBuffers[pointer] = buffer

        return (pointer, pitch)
    }

    // Array Memory Management
    func cudaMallocArray<T>(_ shape: [Int]) throws -> UnsafeMutablePointer<T> {
        let size = shape.reduce(1, *) * MemoryLayout<T>.stride
        return try cudaMalloc(size)
    }

    // Managed Memory
    func cudaMallocManaged<T>(_ size: Int) throws -> UnsafeMutablePointer<T> {
        guard let buffer = device.makeBuffer(length: size,
                                           options: [.storageModeShared, .hazardTrackingModeTracked]) else {
            throw CUDAError.outOfMemory
        }

        let pointer = buffer.contents().assumingMemoryBound(to: T.self)
        allocatedBuffers[pointer] = buffer

        return pointer
    }

    // Memory Prefetch
    func cudaMemPrefetchAsync<T>(_ pointer: UnsafeMutablePointer<T>,
                                count: Int,
                                location: MemoryLocation) throws {
        guard let buffer = allocatedBuffers[pointer] else {
            throw CUDAError.invalidValue
        }

        let commandBuffer = commandQueue.makeCommandBuffer()
        let blitEncoder = commandBuffer?.makeBlitCommandEncoder()

        switch location {
        case .device:
            blitEncoder?.synchronize(resource: buffer)
        case .host:
            buffer.didModifyRange(0..<buffer.length)
        }

        blitEncoder?.endEncoding()
        commandBuffer?.commit()
    }
}

// Advanced Kernel Management
extension CUDAMetalDevice {
    // Dynamic Shared Memory
    func setDynamicSharedMemorySize(_ size: Int, for kernelName: String) throws {
        guard let pipelineState = kernelPipelineStates[kernelName] else {
            throw CUDAError.kernelNotFound
        }

        guard size <= pipelineState.maxTotalThreadsPerThreadgroup else {
            throw CUDAError.invalidValue
        }

        // Store for kernel launch
        kernelSharedMemorySizes[kernelName] = size
    }

    // Multiple Kernel Launch
    func launchKernels(_ launches: [(name: String,
                                   gridSize: (Int, Int, Int),
                                   blockSize: (Int, Int, Int),
                                   arguments: [MTLBuffer])]) throws {
        let commandBuffer = commandQueue.makeCommandBuffer()

        for launch in launches {
            guard let pipelineState = kernelPipelineStates[launch.name] else {
                throw CUDAError.kernelNotFound
            }

            let computeEncoder = commandBuffer?.makeComputeCommandEncoder()
            computeEncoder?.setComputePipelineState(pipelineState)

            // Set arguments
            for (index, buffer) in launch.arguments.enumerated() {
                computeEncoder?.setBuffer(buffer, offset: 0, index: index)
            }

            let threadsPerGrid = MTLSize(width: launch.gridSize.0,
                                       height: launch.gridSize.1,
                                       depth: launch.gridSize.2)

            let threadsPerThreadgroup = MTLSize(width: launch.blockSize.0,
                                              height: launch.blockSize.1,
                                              depth: launch.blockSize.2)

            computeEncoder?.dispatchThreadgroups(threadsPerGrid,
                                             threadsPerThreadgroup: threadsPerThreadgroup)

            computeEncoder?.endEncoding()
        }

        commandBuffer?.commit()
    }

    // Kernel Profiling
    func profileKernel(name: String,
                      gridSize: (Int, Int, Int),
                      blockSize: (Int, Int, Int),
                      arguments: [MTLBuffer]) throws -> KernelProfile {
        guard let pipelineState = kernelPipelineStates[name] else {
            throw CUDAError.kernelNotFound
        }

        let commandBuffer = commandQueue.makeCommandBuffer()

        let computeEncoder = commandBuffer?.makeComputeCommandEncoder()
        computeEncoder?.setComputePipelineState(pipelineState)

        // Set arguments
        for (index, buffer) in arguments.enumerated() {
            computeEncoder?.setBuffer(buffer, offset: 0, index: index)
        }

        let threadsPerGrid = MTLSize(width: gridSize.0,
                                   height: gridSize.1,
                                   depth: gridSize.2)

        let threadsPerThreadgroup = MTLSize(width: blockSize.0,
                                          height: blockSize.1,
                                          depth: blockSize.2)

        computeEncoder?.dispatchThreadgroups(threadsPerGrid,
                                         threadsPerThreadgroup: threadsPerThreadgroup)

        computeEncoder?.endEncoding()

        var profile = KernelProfile()

        commandBuffer?.addCompletedHandler { buffer in
            profile.executionTime = buffer.gpuEndTime - buffer.gpuStartTime
            profile.threadgroups = gridSize.0 * gridSize.1 * gridSize.2
            profile.threadsPerThreadgroup = blockSize.0 * blockSize.1 * blockSize.2
        }

        commandBuffer?.commit()
        commandBuffer?.waitUntilCompleted()

        return profile
    }
}

struct KernelProfile {
    var executionTime: Double = 0
    var threadgroups: Int = 0
    var threadsPerThreadgroup: Int = 0
}

enum MemoryLocation {
    case device
    case host
}


}

--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\templates\swift\main.swift

import Metal
import MetalKit

// Entry point for the application using Metal
class MetalApp {
    private let device: MTLDevice
    private let metalManager: MetalManager

    init() {
        guard let device = MTLCreateSystemDefaultDevice() else {
            fatalError("Metal is not supported on this device.")
        }
        self.device = device
        self.metalManager = MetalManager(device: device)
    }

    func run() {
        // Input and output buffers setup
        let inputBuffer = device.makeBuffer(length: MemoryLayout<Float>.size * 256, options: [])
        let outputBuffer = device.makeBuffer(length: MemoryLayout<Float>.size * 256, options: [])

        // Fill the input buffer with data
        let inputPointer = inputBuffer?.contents().bindMemory(to: Float.self, capacity: 256)
        for i in 0..<256 {
            inputPointer?[i] = Float(i)
        }

        // Execute kernel
        metalManager.executeKernel(functionName: "example_kernel", inputBuffer: inputBuffer!, outputBuffer: outputBuffer!)
    }
}

// Running the Metal app
let app = MetalApp()
app.run()


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\templates\swift\metal_manager.swift

import Metal
import Foundation

class MetalManager {
    private let device: MTLDevice
    private let commandQueue: MTLCommandQueue

    init(device: MTLDevice) {
        self.device = device
        self.commandQueue = device.makeCommandQueue()!
    }

    func executeKernel(functionName: String, inputBuffer: MTLBuffer, outputBuffer: MTLBuffer) {
        guard let library = device.makeDefaultLibrary(),
              let function = library.makeFunction(name: functionName) else {
            print("Failed to find the function \(functionName)")
            return
        }

        do {
            let pipelineState = try device.makeComputePipelineState(function: function)
            guard let commandBuffer = commandQueue.makeCommandBuffer(),
                  let commandEncoder = commandBuffer.makeComputeCommandEncoder() else {
                print("Failed to create command encoder")
                return
            }

            commandEncoder.setComputePipelineState(pipelineState)
            commandEncoder.setBuffer(inputBuffer, offset: 0, index: 0)
            commandEncoder.setBuffer(outputBuffer, offset: 0, index: 1)

            let gridSize = MTLSize(width: 256, height: 1, depth: 1)
            let threadGroupSize = MTLSize(width: 16, height: 1, depth: 1)
            commandEncoder.dispatchThreads(gridSize, threadsPerThreadgroup: threadGroupSize)

            commandEncoder.endEncoding()
            commandBuffer.commit()
            commandBuffer.waitUntilCompleted()

            print("Kernel execution completed")
        } catch {
            print("Error creating pipeline state: \(error)")
        }
    }
}


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\templates\swift\metal_setup.swift



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\tests\test_cli.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\tests\test_code_optimizer.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\tests\test_cuda_parser.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\tests\test_cudnn_mapper.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\tests\test_host_adapter.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\tests\test_kernel_translator.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\tests\__init__.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\tests\integration\test_basic_kernels.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\tests\integration\test_complex_kernels.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\tests\integration_tests\test_end_to_end.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\tests\integration_tests\__init__.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\tests\unit\test_generator.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\tests\unit\test_parser.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\tests\unit\test_translator.py



--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\translator\cudnn_mapper.py

from typing import Dict, List, Any
from ..utils.error_handler import CudaTranslationError
from ..utils.logger import get_logger

logger = get_logger(__name__)

class CudnnMapper:
    def __init__(self):
        self.cudnn_to_mps_map: Dict[str, str] = {
            'cudnnConvolutionForward': 'MPSCNNConvolution',
            'cudnnPoolingForward': 'MPSCNNPooling',
            'cudnnActivationForward': 'MPSCNNNeuron',
            'cudnnSoftmaxForward': 'MPSCNNSoftMax',
            'cudnnBatchNormalizationForward': 'MPSCNNBatchNormalization',
            'cudnnRNNForward': 'MPSNNGRU',
            'cudnnDropoutForward': 'MPSCNNDropout',
            'cudnnOpTensor': 'MPSNNAdd',
        }

    def map_function(self, cudnn_function: str, args: List[Any]) -> str:
        if cudnn_function not in self.cudnn_to_mps_map:
            raise CudaTranslationError(f"Unsupported cuDNN function: {cudnn_function}")

        mps_function = self.cudnn_to_mps_map[cudnn_function]
        return self._generate_mps_call(mps_function, args)

    def _generate_mps_call(self, mps_function: str, args: List[Any]) -> str:
        if mps_function == 'MPSCNNConvolution':
            return self._generate_convolution_call(args)
        elif mps_function == 'MPSCNNPooling':
            return self._generate_pooling_call(args)
        elif mps_function == 'MPSCNNNeuron':
            return self._generate_activation_call(args)
        elif mps_function == 'MPSCNNSoftMax':
            return self._generate_softmax_call(args)
        elif mps_function == 'MPSCNNBatchNormalization':
            return self._generate_batchnorm_call(args)
        else:
            return f"{mps_function}({', '.join(map(str, args))})"

    def _generate_convolution_call(self, args: List[Any]) -> str:
        return f"""
        MPSCNNConvolution *convLayer = [[MPSCNNConvolution alloc]
            initWithDevice:device
            kernelWidth:{args[0]}
            kernelHeight:{args[1]}
            inputFeatureChannels:{args[2]}
            outputFeatureChannels:{args[3]}
            neuronFilter:nil];
        [convLayer encodeToCommandBuffer:commandBuffer
            sourceImage:sourceTexture
            destinationImage:destTexture];
        """

    def _generate_pooling_call(self, args: List[Any]) -> str:
        return f"""
        MPSCNNPooling *poolLayer = [[MPSCNNPooling alloc]
            initWithDevice:device
            kernelWidth:{args[0]}
            kernelHeight:{args[1]}
            strideInPixelsX:{args[2]}
            strideInPixelsY:{args[3]}];
        [poolLayer encodeToCommandBuffer:commandBuffer
            sourceImage:sourceTexture
            destinationImage:destTexture];
        """

    def _generate_activation_call(self, args: List[Any]) -> str:
        return f"""
        MPSCNNNeuron *activationLayer = [MPSCNNNeuronReLU nodeWithSource:nil];
        [activationLayer encodeToCommandBuffer:commandBuffer
            sourceImage:sourceTexture
            destinationImage:destTexture];
        """

    def _generate_softmax_call(self, args: List[Any]) -> str:
        return f"""
        MPSCNNSoftMax *softmaxLayer = [[MPSCNNSoftMax alloc] initWithDevice:device];
        [softmaxLayer encodeToCommandBuffer:commandBuffer
            sourceImage:sourceTexture
            destinationImage:destTexture];
        """

    def _generate_batchnorm_call(self, args: List[Any]) -> str:
        return f"""
        MPSCNNBatchNormalization *batchNormLayer = [[MPSCNNBatchNormalization alloc]
            initWithDevice:device
            featureChannels:{args[0]}];
        [batchNormLayer encodeToCommandBuffer:commandBuffer
            sourceImage:sourceTexture
            destinationImage:destTexture];
        """

    def translate_cudnn_descriptor(self, descriptor_type: str, params: Dict[str, Any]) -> str:
        if descriptor_type == 'cudnnTensorDescriptor':
            return self._translate_tensor_descriptor(params)
        elif descriptor_type == 'cudnnFilterDescriptor':
            return self._translate_filter_descriptor(params)
        elif descriptor_type == 'cudnnConvolutionDescriptor':
            return self._translate_convolution_descriptor(params)
        else:
            raise CudaTranslationError(f"Unsupported descriptor type: {descriptor_type}")

    def _translate_tensor_descriptor(self, params: Dict[str, Any]) -> str:
        return f"""
        MPSImageDescriptor *tensorDescriptor = [MPSImageDescriptor
            imageDescriptorWithChannelFormat:MPSImageFeatureChannelFormatFloat32
            width:{params['width']}
            height:{params['height']}
            featureChannels:{params['channels']}];
        """

    def _translate_filter_descriptor(self, params: Dict[str, Any]) -> str:
        return f"""
        MPSCNNConvolutionDescriptor *filterDescriptor = [MPSCNNConvolutionDescriptor
            cnnConvolutionDescriptorWithKernelWidth:{params['kernelWidth']}
            kernelHeight:{params['kernelHeight']}
            inputFeatureChannels:{params['inputChannels']}
            outputFeatureChannels:{params['outputChannels']}];
        """

    def _translate_convolution_descriptor(self, params: Dict[str, Any]) -> str:
        return f"""
        MPSNNDefaultPadding *convolutionDescriptor = [MPSNNDefaultPadding
            paddingWithMethod:MPSNNPaddingMethodSizeSame];
        convolutionDescriptor.kernelOffsetX = {params['padWidth']};
        convolutionDescriptor.kernelOffsetY = {params['padHeight']};
        """

logger.info("CudnnMapper initialized for cuDNN to Metal Performance Shaders translation.")
Class: ('CudnnMapper', '')
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\translator\host_adapter.py

import re
from typing import Dict, Any
from ..utils.error_handler import CudaTranslationError
from ..utils.logger import get_logger
from ..translator.kernel_translator import KernelTranslator
from ..translator.memory_model_translator import MemoryModelTranslator

logger = get_logger(__name__)

class HostAdapter:
    def __init__(self, kernel_translator: KernelTranslator, memory_translator: MemoryModelTranslator):
        self.kernel_translator = kernel_translator
        self.memory_translator = memory_translator
        self.cuda_to_metal_api = {
            'cudaMalloc': 'newBufferWithLength',
            'cudaFree': None,
            'cudaMemcpy': 'contents',
            'cudaStreamCreate': 'newCommandQueue',
            'cudaStreamDestroy': None,
            'cudaEventCreate': 'newEvent',
            'cudaEventRecord': 'enqueue',
            'cudaEventSynchronize': 'waitUntilCompleted',
            'cudaDeviceSynchronize': 'commit'
        }

    def translate_host_code(self, cuda_code: str) -> str:
        metal_code = cuda_code

        for cuda_api, metal_api in self.cuda_to_metal_api.items():
            if metal_api:
                metal_code = metal_code.replace(cuda_api, metal_api)
            else:
                metal_code = self.remove_unsupported_call(metal_code, cuda_api)

        metal_code = self.adapt_kernel_launches(metal_code)
        metal_code = self.translate_memory_management(metal_code)
        return metal_code

    def remove_unsupported_call(self, code: str, api_call: str) -> str:
        pattern = rf'{api_call}\s*\([^)]*\);'
        return re.sub(pattern, f'// Removed unsupported CUDA call: {api_call}', code)

    def adapt_kernel_launches(self, code: str) -> str:
        kernel_launch_pattern = r'(\w+)<<<(.+?)>>>(.+?);'

        def replace_kernel_launch(match):
            kernel_name = match.group(1)
            launch_params = match.group(2).split(',')
            kernel_args = match.group(3)

            grid_dim = launch_params[0].strip()
            block_dim = launch_params[1].strip()

            return f"""
            MTLSize gridSize = MTLSizeMake({grid_dim}, 1, 1);
            MTLSize threadGroupSize = MTLSizeMake({block_dim}, 1, 1);
            [commandEncoder setComputePipelineState:{kernel_name}PipelineState];
            [commandEncoder dispatchThreadgroups:gridSize threadsPerThreadgroup:threadGroupSize];
            {self.kernel_translator.translate_kernel(kernel_name)}{kernel_args};
            """

        return re.sub(kernel_launch_pattern, replace_kernel_launch, code)

    def translate_memory_management(self, code: str) -> str:
        malloc_pattern = r'cudaMalloc\(\(void\*\*\)&(\w+),\s*(.+?)\);'
        code = re.sub(malloc_pattern, lambda m: f"{m.group(1)} = [device newBufferWithLength:{m.group(2)} options:MTLResourceStorageModeShared];", code)

        memcpy_pattern = r'cudaMemcpy\((.+?),\s*(.+?),\s*(.+?),\s*cudaMemcpy(.+?)\);'
        code = re.sub(memcpy_pattern, lambda m: f"memcpy({m.group(1)}.contents, {m.group(2)}, {m.group(3)});", code)

        return code

    def generate_metal_setup(self) -> str:
        return """
        id<MTLDevice> device = MTLCreateSystemDefaultDevice();
        id<MTLCommandQueue> commandQueue = [device newCommandQueue];
        id<MTLCommandBuffer> commandBuffer = [commandQueue commandBuffer];
        id<MTLComputeCommandEncoder> commandEncoder = [commandBuffer computeCommandEncoder];
        """

    def generate_metal_cleanup(self) -> str:
        return """
        [commandEncoder endEncoding];
        [commandBuffer commit];
        [commandBuffer waitUntilCompleted];
        """

logger.info("HostAdapter initialized for CUDA to Metal host code translation.")
Class: ('HostAdapter', '')
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\translator\intrinsic_function_mapper.py


from typing import Dict, Optional, List, Tuple, Union, Set
from dataclasses import dataclass
from enum import Enum
import logging

from ..utils.error_handler import CudaTranslationError
from ..utils.logger import get_logger

logger = get_logger(__name__)

class IntrinsicType(Enum):
    MATH = "math"
    ATOMIC = "atomic"
    SYNC = "sync"
    MEMORY = "memory"
    THREAD = "thread"
    WARP = "warp"
    SPECIAL = "special"

@dataclass
class IntrinsicFunction:
    """Represents a CUDA intrinsic function with its Metal equivalent."""
    cuda_name: str
    metal_name: str
    return_type: str
    arg_types: List[str]
    type: IntrinsicType
    needs_wrapper: bool = False
    has_metal_equivalent: bool = True
    requires_memory_order: bool = False
    requires_scope: bool = False
    is_simd_function: bool = False
    vectorizable: bool = False
    custom_translation: Optional[str] = None

class IntrinsicFunctionMapper:
    """Maps CUDA intrinsic functions to their Metal equivalents."""

    def __init__(self):
        self.intrinsics: Dict[str, IntrinsicFunction] = self._init_intrinsics()
        self.used_intrinsics: Set[str] = set()
        self.required_headers: Set[str] = set()

    def _init_intrinsics(self) -> Dict[str, IntrinsicFunction]:
        """Initialize all supported intrinsic functions."""
        return {
            # Math intrinsics
            "__sinf": IntrinsicFunction(
                cuda_name="__sinf",
                metal_name="metal::fast::sin",
                return_type="float",
                arg_types=["float"],
                type=IntrinsicType.MATH,
                vectorizable=True
            ),
            "__cosf": IntrinsicFunction(
                cuda_name="__cosf",
                metal_name="metal::fast::cos",
                return_type="float",
                arg_types=["float"],
                type=IntrinsicType.MATH,
                vectorizable=True
            ),
            # ... other intrinsic definitions ...
        }

    def map_intrinsic(self, node: dict) -> str:
        """Map CUDA intrinsic function call to Metal equivalent."""
        try:
            func_name = node.get('function', {}).get('name')
            if not func_name:
                raise CudaTranslationError(f"Invalid intrinsic function call: {node}")

            if func_name not in self.intrinsics:
                raise CudaTranslationError(f"Unknown intrinsic function: {func_name}")

            intrinsic = self.intrinsics[func_name]
            self.used_intrinsics.add(func_name)

            # Handle custom translations
            if intrinsic.custom_translation:
                return intrinsic.custom_translation

            # Generate Metal function call
            args = self._translate_arguments(node.get('arguments', []), intrinsic)
            metal_call = f"{intrinsic.metal_name}({', '.join(args)})"

            # Add memory order if required
            if intrinsic.requires_memory_order:
                metal_call += ", memory_order_relaxed"

            # Add scope if required
            if intrinsic.requires_scope:
                metal_call += "(mem_flags::mem_threadgroup)"

            return metal_call

        except Exception as e:
            logger.error(f"Error mapping intrinsic function: {str(e)}")
            raise CudaTranslationError(f"Failed to map intrinsic function: {str(e)}")

    def _translate_arguments(self, args: List[dict], intrinsic: IntrinsicFunction) -> List[str]:
        """Translate function arguments to Metal."""
        if len(args) != len(intrinsic.arg_types):
            raise CudaTranslationError(
                f"Wrong number of arguments for {intrinsic.cuda_name}: "
                f"expected {len(intrinsic.arg_types)}, got {len(args)}"
            )

        translated_args = []
        for arg, expected_type in zip(args, intrinsic.arg_types):
            arg_str = self._translate_argument(arg, expected_type)
            translated_args.append(arg_str)

        return translated_args

    def _translate_argument(self, arg: dict, expected_type: str) -> str:
        """Translate single argument with type checking."""
        if 'value' in arg:
            return str(arg['value'])
        elif 'name' in arg:
            return arg['name']
        return str(arg)

    def get_required_headers(self) -> Set[str]:
        """Get required Metal headers based on used intrinsics."""
        headers = set()
        for intrinsic_name in self.used_intrinsics:
            intrinsic = self.intrinsics[intrinsic_name]
            if intrinsic.type == IntrinsicType.MATH:
                headers.add("#include <metal_math>")
            elif intrinsic.type == IntrinsicType.ATOMIC:
                headers.add("#include <metal_atomic>")
            elif intrinsic.is_simd_function:
                headers.add("#include <metal_simdgroup>")
        return headers

    def get_vectorizable_intrinsics(self) -> Set[str]:
        """Get list of vectorizable intrinsic functions."""
        return {name for name, func in self.intrinsics.items() if func.vectorizable}

    def get_simd_functions(self) -> Set[str]:
        """Get list of SIMD-specific functions."""
        return {name for name, func in self.intrinsics.items() if func.is_simd_function}

    def validate_intrinsic_usage(self, node: dict) -> bool:
        """Validate intrinsic function usage."""
        func_name = node.get('function', {}).get('name')
        if not func_name or func_name not in self.intrinsics:
            return False

        intrinsic = self.intrinsics[func_name]
        return len(node.get('arguments', [])) == len(intrinsic.arg_types)

logger.info("IntrinsicFunctionMapper initialized with complete mappings")

Class: ('IntrinsicType', '(Enum)')
--------------------------------------------------------------------------------
  Method: get('function', {})
  Method: get('name')
  Method: get('arguments', [])
  Method: get('function', {})
  Method: get('name')
  Method: get('arguments', [])

Class: ('IntrinsicFunction', '')
--------------------------------------------------------------------------------
  Method: get('function', {})
  Method: get('name')
  Method: get('arguments', [])
  Method: get('function', {})
  Method: get('name')
  Method: get('arguments', [])

Class: ('IntrinsicFunctionMapper', '')
--------------------------------------------------------------------------------
  Method: get('function', {})
  Method: get('name')
  Method: get('arguments', [])
  Method: get('function', {})
  Method: get('name')
  Method: get('arguments', [])


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\translator\thread_hierarchy_mapper.py

from typing import Dict, Tuple, Any
from ..utils.error_handler import CudaTranslationError
from ..utils.logger import get_logger

logger = get_logger(__name__)

class ThreadHierarchyMapper:
    def __init__(self):
        self.cuda_to_metal_map = {
            'threadIdx': 'thread_position_in_threadgroup',
            'blockIdx': 'threadgroup_position_in_grid',
            'blockDim': 'threadgroup_size',
            'gridDim': 'grid_size'
        }
        self.max_threads_per_threadgroup = 1024  # This may vary depending on the Metal device

    def map_thread_id(self, cuda_expr: str) -> str:
        for cuda_var, metal_var in self.cuda_to_metal_map.items():
            if cuda_var in cuda_expr:
                return cuda_expr.replace(cuda_var, metal_var)
        raise CudaTranslationError(f"Unsupported CUDA thread hierarchy expression: {cuda_expr}")

    def calculate_global_id(self, dim: str) -> str:
        return f"(thread_position_in_threadgroup.{dim} + (threadgroup_position_in_grid.{dim} * threadgroup_size.{dim}))"

    def translate_launch_parameters(self, grid_dim: Tuple[int, int, int], block_dim: Tuple[int, int, int]) -> Dict[str, Any]:
        optimized_grid_dim, optimized_block_dim = self.optimize_thread_hierarchy(grid_dim, block_dim)
        return {
            'threads_per_threadgroup': self._create_metal_size(optimized_block_dim),
            'threadgroups_per_grid': self._create_metal_size(optimized_grid_dim)
        }

    def _create_metal_size(self, dim: Tuple[int, int, int]) -> str:
        return f"MTLSizeMake({dim[0]}, {dim[1]}, {dim[2]})"

    def generate_metal_dispatch(self, kernel_name: str, grid_dim: Tuple[int, int, int], block_dim: Tuple[int, int, int]) -> str:
        launch_params = self.translate_launch_parameters(grid_dim, block_dim)
        return f"""
        [commandEncoder setComputePipelineState:{kernel_name}PipelineState];
        [commandEncoder dispatchThreadgroups:{launch_params['threadgroups_per_grid']}
                        threadsPerThreadgroup:{launch_params['threads_per_threadgroup']}];
        """

    def translate_shared_memory(self, cuda_shared_mem: str) -> str:
        return cuda_shared_mem.replace("__shared__", "threadgroup")

    def translate_syncthreads(self) -> str:
        return "threadgroup_barrier(metal::mem_flags::mem_threadgroup);"

    def translate_block_sync(self) -> str:
        return "threadgroup_barrier(metal::mem_flags::mem_device);"

    def translate_grid_sync(self) -> str:
        logger.warning("Grid-wide synchronization is not directly supported in Metal. Using device memory barrier.")
        return "threadgroup_barrier(metal::mem_flags::mem_device);"

    def optimize_thread_hierarchy(self, grid_dim: Tuple[int, int, int], block_dim: Tuple[int, int, int]) -> Tuple[Tuple[int, int, int], Tuple[int, int, int]]:
        total_threads = block_dim[0] * block_dim[1] * block_dim[2]
        if total_threads > self.max_threads_per_threadgroup:
            scale_factor = (self.max_threads_per_threadgroup / total_threads) ** (1/3)
            new_block_dim = tuple(int(dim * scale_factor) for dim in block_dim)
            new_grid_dim = tuple(int(grid_dim[i] * (block_dim[i] / new_block_dim[i])) for i in range(3))
            return new_grid_dim, new_block_dim

        # Ensure block dimensions are multiples of the SIMD width (usually 32 for Metal GPUs)
        simd_width = 32
        optimized_block_dim = tuple(((dim + simd_width - 1) // simd_width) * simd_width for dim in block_dim)

        # Adjust grid dimensions to account for changes in block dimensions
        optimized_grid_dim = tuple((grid_dim[i] * block_dim[i] + optimized_block_dim[i] - 1) // optimized_block_dim[i] for i in range(3))

        return optimized_grid_dim, optimized_block_dim

    def translate_warp_level_operations(self, cuda_expr: str) -> str:
        warp_ops = {
            '__shfl': 'simd_shuffle',
            '__shfl_up': 'simd_shuffle_up',
            '__shfl_down': 'simd_shuffle_down',
            '__shfl_xor': 'simd_shuffle_xor',
            '__all': 'simd_all',
            '__any': 'simd_any',
            '__ballot': 'simd_ballot'
        }
        for cuda_op, metal_op in warp_ops.items():
            if cuda_op in cuda_expr:
                return cuda_expr.replace(cuda_op, metal_op)
        return cuda_expr

    def adjust_kernel_launch(self, kernel_name: str, grid_dim: Tuple[int, int, int], block_dim: Tuple[int, int, int]) -> str:
        optimized_grid_dim, optimized_block_dim = self.optimize_thread_hierarchy(grid_dim, block_dim)
        return self.generate_metal_dispatch(kernel_name, optimized_grid_dim, optimized_block_dim)

logger.info("ThreadHierarchyMapper initialized for CUDA to Metal thread hierarchy translation.")
Class: ('ThreadHierarchyMapper', '')
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\translator\__init__.py

from core import CudaTranslator
from kernel_translator import KernelTranslator
from .host_adapter import HostAdapter

__all__ = ['CudaTranslator', 'KernelTranslator', 'HostAdapter']

--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\utils\cuda_builtin_functions.py

from typing import Dict, List, Tuple

class CudaBuiltinFunction:
    def __init__(self, name: str, return_type: str, parameters: List[Tuple[str, str]],
                 is_device_function: bool, metal_equivalent: str):
        self.name = name
        self.return_type = return_type
        self.parameters = parameters
        self.is_device_function = is_device_function
        self.metal_equivalent = metal_equivalent

    def __str__(self):
        params_str = ', '.join([f'{param_type} {param_name}' for param_name, param_type in self.parameters])
        return f'{self.return_type} {self.name}({params_str})'

CUDA_BUILTIN_FUNCTIONS: Dict[str, CudaBuiltinFunction] = {
    # Thread Management
    'threadIdx': CudaBuiltinFunction('threadIdx', 'uint3', [], True, 'thread_position_in_threadgroup'),
    'blockIdx': CudaBuiltinFunction('blockIdx', 'uint3', [], True, 'threadgroup_position_in_grid'),
    'blockDim': CudaBuiltinFunction('blockDim', 'uint3', [], True, 'threadgroup_size'),
    'gridDim': CudaBuiltinFunction('gridDim', 'uint3', [], True, 'grid_size'),
    'warpSize': CudaBuiltinFunction('warpSize', 'int', [], True, '32'),

    # Synchronization
    '__syncthreads': CudaBuiltinFunction('__syncthreads', 'void', [], True, 'threadgroup_barrier(mem_flags::mem_device)'),
    '__syncwarp': CudaBuiltinFunction('__syncwarp', 'void', [('mask', 'unsigned int')], True, 'simdgroup_barrier(mem_flags::mem_none)'),

    # Atomic Operations
    'atomicAdd': CudaBuiltinFunction('atomicAdd', 'T', [('address', 'T*'), ('val', 'T')], True, 'atomic_fetch_add_explicit'),
    'atomicSub': CudaBuiltinFunction('atomicSub', 'T', [('address', 'T*'), ('val', 'T')], True, 'atomic_fetch_sub_explicit'),
    'atomicExch': CudaBuiltinFunction('atomicExch', 'T', [('address', 'T*'), ('val', 'T')], True, 'atomic_exchange_explicit'),
    'atomicMin': CudaBuiltinFunction('atomicMin', 'T', [('address', 'T*'), ('val', 'T')], True, 'atomic_fetch_min_explicit'),
    'atomicMax': CudaBuiltinFunction('atomicMax', 'T', [('address', 'T*'), ('val', 'T')], True, 'atomic_fetch_max_explicit'),
    'atomicInc': CudaBuiltinFunction('atomicInc', 'unsigned int', [('address', 'unsigned int*'), ('val', 'unsigned int')], True, 'custom_atomic_inc'),
    'atomicDec': CudaBuiltinFunction('atomicDec', 'unsigned int', [('address', 'unsigned int*'), ('val', 'unsigned int')], True, 'custom_atomic_dec'),
    'atomicCAS': CudaBuiltinFunction('atomicCAS', 'T', [('address', 'T*'), ('compare', 'T'), ('val', 'T')], True, 'atomic_compare_exchange_weak_explicit'),

    # Math Functions (subset)
    'sin': CudaBuiltinFunction('sin', 'float', [('x', 'float')], False, 'sin'),
    'cos': CudaBuiltinFunction('cos', 'float', [('x', 'float')], False, 'cos'),
    'exp': CudaBuiltinFunction('exp', 'float', [('x', 'float')], False, 'exp'),
    'log': CudaBuiltinFunction('log', 'float', [('x', 'float')], False, 'log'),
    'sqrt': CudaBuiltinFunction('sqrt', 'float', [('x', 'float')], False, 'sqrt'),

    # Vector Types
    'make_int2': CudaBuiltinFunction('make_int2', 'int2', [('x', 'int'), ('y', 'int')], False, 'int2'),
    'make_float2': CudaBuiltinFunction('make_float2', 'float2', [('x', 'float'), ('y', 'float')], False, 'float2'),

    # Texture Functions
    'tex2D': CudaBuiltinFunction('tex2D', 'float4', [('texObj', 'texture<T, 2>'), ('x', 'float'), ('y', 'float')], True, 'sample'),

    # Memory Management
    'cudaMalloc': CudaBuiltinFunction('cudaMalloc', 'cudaError_t', [('devPtr', 'void**'), ('size', 'size_t')], False, 'device.makeBuffer'),
    'cudaFree': CudaBuiltinFunction('cudaFree', 'cudaError_t', [('devPtr', 'void*')], False, 'None'),
    'cudaMemcpy': CudaBuiltinFunction('cudaMemcpy', 'cudaError_t', [('dst', 'void*'), ('src', 'const void*'), ('count', 'size_t'), ('kind', 'cudaMemcpyKind')], False, 'memcpy'),
}

def is_cuda_builtin(func_name: str) -> bool:
    return func_name in CUDA_BUILTIN_FUNCTIONS

def get_cuda_builtin(func_name: str) -> CudaBuiltinFunction:
    return CUDA_BUILTIN_FUNCTIONS.get(func_name)

def get_metal_equivalent(func_name: str) -> str:
    builtin = get_cuda_builtin(func_name)
    return builtin.metal_equivalent if builtin else None

def is_device_function(func_name: str) -> bool:
    builtin = get_cuda_builtin(func_name)
    return builtin.is_device_function if builtin else False

def get_return_type(func_name: str) -> str:
    builtin = get_cuda_builtin(func_name)
    return builtin.return_type if builtin else None

def get_parameters(func_name: str) -> List[Tuple[str, str]]:
    builtin = get_cuda_builtin(func_name)
    return builtin.parameters if builtin else []


Class: ('CudaBuiltinFunction', '')
--------------------------------------------------------------------------------
  Method: get(func_name)


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\utils\cuda_to_metal_type_mapping.py

from typing import Dict, Optional

class TypeMapping:
    def __init__(self, cuda_type: str, metal_type: str,
                 requires_header: bool = False,
                 metal_header: Optional[str] = None):
        self.cuda_type = cuda_type
        self.metal_type = metal_type
        self.requires_header = requires_header
        self.metal_header = metal_header

    def __str__(self):
        return f"{self.cuda_type} -> {self.metal_type}"

CUDA_TO_METAL_TYPE_MAP: Dict[str, TypeMapping] = {
    # Integer types
    'char': TypeMapping('char', 'char'),
    'signed char': TypeMapping('signed char', 'char'),
    'unsigned char': TypeMapping('unsigned char', 'uchar'),
    'short': TypeMapping('short', 'short'),
    'unsigned short': TypeMapping('unsigned short', 'ushort'),
    'int': TypeMapping('int', 'int'),
    'unsigned int': TypeMapping('unsigned int', 'uint'),
    'long': TypeMapping('long', 'int'),  # In Metal, long is 32-bit
    'unsigned long': TypeMapping('unsigned long', 'uint'),
    'long long': TypeMapping('long long', 'long'),  # In Metal, long long is 64-bit
    'unsigned long long': TypeMapping('unsigned long long', 'ulong'),

    # Floating-point types
    'float': TypeMapping('float', 'float'),
    'double': TypeMapping('double', 'float'),  # Metal doesn't support double, use float

    # Vector types
    'char2': TypeMapping('char2', 'char2', True, '<metal_simdgroup>'),
    'char3': TypeMapping('char3', 'char3', True, '<metal_simdgroup>'),
    'char4': TypeMapping('char4', 'char4', True, '<metal_simdgroup>'),
    'uchar2': TypeMapping('uchar2', 'uchar2', True, '<metal_simdgroup>'),
    'uchar3': TypeMapping('uchar3', 'uchar3', True, '<metal_simdgroup>'),
    'uchar4': TypeMapping('uchar4', 'uchar4', True, '<metal_simdgroup>'),
    'short2': TypeMapping('short2', 'short2', True, '<metal_simdgroup>'),
    'short3': TypeMapping('short3', 'short3', True, '<metal_simdgroup>'),
    'short4': TypeMapping('short4', 'short4', True, '<metal_simdgroup>'),
    'ushort2': TypeMapping('ushort2', 'ushort2', True, '<metal_simdgroup>'),
    'ushort3': TypeMapping('ushort3', 'ushort3', True, '<metal_simdgroup>'),
    'ushort4': TypeMapping('ushort4', 'ushort4', True, '<metal_simdgroup>'),
    'int2': TypeMapping('int2', 'int2', True, '<metal_simdgroup>'),
    'int3': TypeMapping('int3', 'int3', True, '<metal_simdgroup>'),
    'int4': TypeMapping('int4', 'int4', True, '<metal_simdgroup>'),
    'uint2': TypeMapping('uint2', 'uint2', True, '<metal_simdgroup>'),
    'uint3': TypeMapping('uint3', 'uint3', True, '<metal_simdgroup>'),
    'uint4': TypeMapping('uint4', 'uint4', True, '<metal_simdgroup>'),
    'float2': TypeMapping('float2', 'float2', True, '<metal_simdgroup>'),
    'float3': TypeMapping('float3', 'float3', True, '<metal_simdgroup>'),
    'float4': TypeMapping('float4', 'float4', True, '<metal_simdgroup>'),

    # CUDA-specific types
    'dim3': TypeMapping('dim3', 'uint3', True, '<metal_simdgroup>'),
    'cudaError_t': TypeMapping('cudaError_t', 'int'),
    'cudaStream_t': TypeMapping('cudaStream_t', 'metal::command_queue'),
    'cudaEvent_t': TypeMapping('cudaEvent_t', 'metal::event'),
}

def map_cuda_type_to_metal(cuda_type: str) -> str:
    mapping = CUDA_TO_METAL_TYPE_MAP.get(cuda_type)
    return mapping.metal_type if mapping else cuda_type

def requires_metal_header(cuda_type: str) -> bool:
    mapping = CUDA_TO_METAL_TYPE_MAP.get(cuda_type)
    return mapping.requires_header if mapping else False

def get_metal_header(cuda_type: str) -> Optional[str]:
    mapping = CUDA_TO_METAL_TYPE_MAP.get(cuda_type)
    return mapping.metal_header if mapping else None

def is_vector_type(type_name: str) -> bool:
    return type_name.lower() in [
        'char2', 'char3', 'char4',
        'uchar2', 'uchar3', 'uchar4',
        'short2', 'short3', 'short4',
        'ushort2', 'ushort3', 'ushort4',
        'int2', 'int3', 'int4',
        'uint2', 'uint3', 'uint4',
        'float2', 'float3', 'float4'
    ]

def get_vector_component_type(vector_type: str) -> str:
    base_type = vector_type.rstrip('234')
    return map_cuda_type_to_metal(base_type)

def get_vector_size(vector_type: str) -> int:
    return int(vector_type[-1]) if vector_type[-1].isdigit() else 0
Class: ('TypeMapping', '')
--------------------------------------------------------------------------------
  Method: get(cuda_type)
  Method: get(cuda_type)
  Method: get(cuda_type)


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\utils\error_handler.py

from typing import Optional, Dict, Any
import traceback

class CudaError(Exception):
    """Base class for CUDA-related errors."""
    def __init__(self, message: str, error_code: Optional[int] = None, details: Optional[Dict[str, Any]] = None):
        self.message = message
        self.error_code = error_code
        self.details = details or {}
        super().__init__(self.message)

    def __str__(self):
        error_str = f"[Error {self.error_code}] " if self.error_code else ""
        error_str += self.message
        if self.details:
            error_str += "\nDetails:\n" + "\n".join(f"  {k}: {v}" for k, v in self.details.items())
        return error_str

class CudaParseError(CudaError):
    """Exception raised for errors in parsing CUDA code."""
    def __init__(self, message: str, line: Optional[int] = None, column: Optional[int] = None, filename: Optional[str] = None):
        details = {"line": line, "column": column, "filename": filename}
        super().__init__(message, error_code=1001, details=details)

class CudaTranslationError(CudaError):
    """Exception raised for errors in translating CUDA code to Metal."""
    def __init__(self, message: str, cuda_construct: Optional[str] = None, metal_equivalent: Optional[str] = None):
        details = {"cuda_construct": cuda_construct, "metal_equivalent": metal_equivalent}
        super().__init__(message, error_code=2001, details=details)

class CudaTypeError(CudaError):
    """Exception raised for type-related errors in CUDA code."""
    def __init__(self, message: str, expected_type: Optional[str] = None, actual_type: Optional[str] = None):
        details = {"expected_type": expected_type, "actual_type": actual_type}
        super().__init__(message, error_code=3001, details=details)

class CudaNotSupportedError(CudaError):
    """Exception raised for CUDA features not supported in Metal."""
    def __init__(self, message: str, cuda_feature: str):
        details = {"cuda_feature": cuda_feature}
        super().__init__(message, error_code=4001, details=details)

class CudaWarning:
    """Warning class for non-critical issues in CUDA code parsing or translation."""
    def __init__(self, message: str, warning_code: Optional[int] = None, details: Optional[Dict[str, Any]] = None):
        self.message = message
        self.warning_code = warning_code
        self.details = details or {}

    def __str__(self):
        warning_str = f"[Warning {self.warning_code}] " if self.warning_code else ""
        warning_str += self.message
        if self.details:
            warning_str += "\nDetails:\n" + "\n".join(f"  {k}: {v}" for k, v in self.details.items())
        return warning_str

def handle_exception(e: Exception, logger):
    """
    Handle exceptions, log them, and optionally perform additional actions.
    """
    if isinstance(e, CudaError):
        logger.error(str(e))
    else:
        logger.error(f"Unexpected error: {str(e)}")
        logger.debug(f"Stack trace:\n{''.join(traceback.format_tb(e.__traceback__))}")

def raise_cuda_parse_error(message: str, line: Optional[int] = None, column: Optional[int] = None, filename: Optional[str] = None):
    """Convenience function to raise a CudaParseError."""
    raise CudaParseError(message, line, column, filename)

def raise_cuda_translation_error(message: str, cuda_construct: Optional[str] = None, metal_equivalent: Optional[str] = None):
    """Convenience function to raise a CudaTranslationError."""
    raise CudaTranslationError(message, cuda_construct, metal_equivalent)

def raise_cuda_type_error(message: str, expected_type: Optional[str] = None, actual_type: Optional[str] = None):
    """Convenience function to raise a CudaTypeError."""
    raise CudaTypeError(message, expected_type, actual_type)

def raise_cuda_not_supported_error(message: str, cuda_feature: str):
    """Convenience function to raise a CudaNotSupportedError."""
    raise CudaNotSupportedError(message, cuda_feature)

def issue_cuda_warning(message: str, warning_code: Optional[int] = None, details: Optional[Dict[str, Any]] = None, logger=None):
    """Issue a CudaWarning and optionally log it."""
    warning = CudaWarning(message, warning_code, details)
    if logger:
        logger.warning(str(warning))
    return warning
Class: ('CudaError', '(Exception)')
--------------------------------------------------------------------------------

Class: ('CudaParseError', '(CudaError)')
--------------------------------------------------------------------------------

Class: ('CudaTranslationError', '(CudaError)')
--------------------------------------------------------------------------------

Class: ('CudaTypeError', '(CudaError)')
--------------------------------------------------------------------------------

Class: ('CudaNotSupportedError', '(CudaError)')
--------------------------------------------------------------------------------

Class: ('CudaWarning', '')
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\utils\file_utils.py

# utils/file_utils.py

import os
import shutil
import hashlib
import tempfile
from pathlib import Path
from typing import List, Set, Dict, Optional, Generator
from concurrent.futures import ThreadPoolExecutor
from threading import Lock
import logging

from .error_handler import CudaTranslationError
from .logger import get_logger

logger = get_logger(__name__)

class FileCache:
    """Thread-safe file cache manager."""
    def __init__(self, cache_dir: Optional[str] = None):
        self.cache_dir = Path(cache_dir) if cache_dir else Path(tempfile.gettempdir()) / "cuda_metal_cache"
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self._lock = Lock()
        self._cache_index: Dict[str, Path] = {}
        self._load_cache_index()

    def _load_cache_index(self):
        """Load cache index from disk."""
        with self._lock:
            index_file = self.cache_dir / "index.json"
            if index_file.exists():
                import json
                with open(index_file, 'r') as f:
                    self._cache_index = {k: Path(v) for k, v in json.load(f).items()}

    def _save_cache_index(self):
        """Save cache index to disk."""
        with self._lock:
            index_file = self.cache_dir / "index.json"
            import json
            with open(index_file, 'w') as f:
                json.dump({k: str(v) for k, v in self._cache_index.items()}, f)

    def get_cached_path(self, key: str) -> Optional[Path]:
        """Get cached file path if exists."""
        with self._lock:
            return self._cache_index.get(key)

    def add_to_cache(self, key: str, file_path: Path):
        """Add file to cache."""
        with self._lock:
            cache_path = self.cache_dir / hashlib.sha256(key.encode()).hexdigest()
            shutil.copy2(file_path, cache_path)
            self._cache_index[key] = cache_path
            self._save_cache_index()

class FileTracker:
    """Tracks file dependencies and modifications."""
    def __init__(self):
        self.dependencies: Dict[Path, Set[Path]] = {}
        self._lock = Lock()

    def add_dependency(self, source: Path, dependency: Path):
        """Add a dependency relationship."""
        with self._lock:
            if source not in self.dependencies:
                self.dependencies[source] = set()
            self.dependencies[source].add(dependency)

    def get_dependencies(self, source: Path) -> Set[Path]:
        """Get all dependencies for a file."""
        with self._lock:
            return self.dependencies.get(source, set())

    def is_modified(self, source: Path, dependency: Path) -> bool:
        """Check if dependency is modified after source."""
        try:
            source_mtime = source.stat().st_mtime
            dep_mtime = dependency.stat().st_mtime
            return dep_mtime > source_mtime
        except OSError:
            return True

class FileUtils:
    """Utility class for file operations with Metal-specific optimizations."""

    def __init__(self):
        self.cache = FileCache()
        self.tracker = FileTracker()
        self.temp_dir = Path(tempfile.mkdtemp(prefix="cuda_metal_"))
        self._lock = Lock()

    def read_file(self, path: Path, encoding: str = 'utf-8') -> str:
        """Read file with caching and error handling."""
        try:
            with open(path, 'r', encoding=encoding) as f:
                content = f.read()

            # Cache the content
            cache_key = f"{path}:{path.stat().st_mtime}"
            self.cache.add_to_cache(cache_key, path)

            return content

        except UnicodeDecodeError:
            logger.warning(f"Failed to read {path} with {encoding} encoding, trying alternate encodings")
            for alt_encoding in ['latin1', 'cp1252']:
                try:
                    with open(path, 'r', encoding=alt_encoding) as f:
                        return f.read()
                except UnicodeDecodeError:
                    continue
            raise CudaTranslationError(f"Unable to read file {path} with any supported encoding")

        except OSError as e:
            raise CudaTranslationError(f"Failed to read file {path}: {str(e)}")

    def write_file(self, path: Path, content: str, encoding: str = 'utf-8', backup: bool = True):
        """Write file with backup and atomic operation."""
        if backup and path.exists():
            self._create_backup(path)

        # Write to temporary file first
        temp_path = self.temp_dir / f"{path.name}.tmp"
        try:
            with open(temp_path, 'w', encoding=encoding) as f:
                f.write(content)
                f.flush()
                os.fsync(f.fileno())

            # Atomic move
            shutil.move(str(temp_path), str(path))

        except OSError as e:
            raise CudaTranslationError(f"Failed to write file {path}: {str(e)}")
        finally:
            if temp_path.exists():
                temp_path.unlink()

    def _create_backup(self, path: Path):
        """Create backup of existing file."""
        backup_path = path.with_suffix(path.suffix + '.bak')
        try:
            shutil.copy2(path, backup_path)
        except OSError as e:
            logger.warning(f"Failed to create backup of {path}: {str(e)}")

    def process_directory(self,
                          directory: Path,
                          pattern: str = "*.cu",
                          recursive: bool = True) -> Generator[Path, None, None]:
        """Process directory with parallel file scanning."""
        try:
            if recursive:
                paths = directory.rglob(pattern)
            else:
                paths = directory.glob(pattern)

            with ThreadPoolExecutor() as executor:
                yield from executor.map(self._process_file, paths)

        except OSError as e:
            raise CudaTranslationError(f"Failed to process directory {directory}: {str(e)}")

    def _process_file(self, path: Path) -> Path:
        """Process individual file with validation."""
        if not path.is_file():
            logger.warning(f"Skipping non-file path: {path}")
            return None

        return path

    def ensure_directory(self, path: Path):
        """Ensure directory exists with proper permissions."""
        try:
            path.mkdir(parents=True, exist_ok=True)

            # Set appropriate permissions
            if os.name == 'posix':
                os.chmod(path, 0o755)

        except OSError as e:
            raise CudaTranslationError(f"Failed to create directory {path}: {str(e)}")

    def copy_with_metadata(self, src: Path, dst: Path):
        """Copy file with all metadata preserved."""
        try:
            shutil.copy2(src, dst)

            # Track dependency
            self.tracker.add_dependency(dst, src)

        except OSError as e:
            raise CudaTranslationError(f"Failed to copy {src} to {dst}: {str(e)}")

    def get_relative_path(self, path: Path, base: Path) -> Path:
        """Get relative path with validation."""
        try:
            return path.relative_to(base)
        except ValueError:
            return path

    def cleanup(self):
        """Clean up temporary files."""
        try:
            shutil.rmtree(self.temp_dir, ignore_errors=True)
        except OSError as e:
            logger.warning(f"Failed to clean up temporary files: {str(e)}")

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.cleanup()

logger.info("FileUtils initialized with Metal-specific optimizations.")
Class: ('FileCache', '')
--------------------------------------------------------------------------------
  Method: get(key)
  Method: get(source, set()

Class: ('FileTracker', '')
--------------------------------------------------------------------------------
  Method: get(key)
  Method: get(source, set()

Class: ('FileUtils', '')
--------------------------------------------------------------------------------
  Method: get(key)
  Method: get(source, set()


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\utils\logger.py

import logging
import os
from typing import Dict, Optional
from logging.handlers import RotatingFileHandler, TimedRotatingFileHandler

class CudaLogger:
    _instance = None
    _loggers: Dict[str, logging.Logger] = {}

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(CudaLogger, cls).__new__(cls)
            cls._instance._configure_root_logger()
        return cls._instance

    def _configure_root_logger(self):
        root_logger = logging.getLogger()
        root_logger.setLevel(logging.DEBUG)

        # Console handler
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        console_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        console_handler.setFormatter(console_formatter)
        root_logger.addHandler(console_handler)

        # File handler
        log_dir = "logs"
        os.makedirs(log_dir, exist_ok=True)
        file_handler = RotatingFileHandler(
            filename=os.path.join(log_dir, "cuda_to_metal.log"),
            maxBytes=10 * 1024 * 1024,  # 10 MB
            backupCount=5
        )
        file_handler.setLevel(logging.DEBUG)
        file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s')
        file_handler.setFormatter(file_formatter)
        root_logger.addHandler(file_handler)

    def get_logger(self, name: str) -> logging.Logger:
        if name not in self._loggers:
            logger = logging.getLogger(name)
            self._loggers[name] = logger
        return self._loggers[name]

    def set_log_level(self, level: int):
        for logger in self._loggers.values():
            logger.setLevel(level)

    def add_file_handler(self, filename: str, level: int = logging.DEBUG,
                         max_bytes: int = 10 * 1024 * 1024, backup_count: int = 5):
        file_handler = RotatingFileHandler(
            filename=filename,
            maxBytes=max_bytes,
            backupCount=backup_count
        )
        file_handler.setLevel(level)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s')
        file_handler.setFormatter(formatter)
        for logger in self._loggers.values():
            logger.addHandler(file_handler)

    def add_timed_rotating_file_handler(self, filename: str, level: int = logging.DEBUG,
                                        when: str = 'midnight', interval: int = 1, backup_count: int = 7):
        file_handler = TimedRotatingFileHandler(
            filename=filename,
            when=when,
            interval=interval,
            backupCount=backup_count
        )
        file_handler.setLevel(level)
        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(filename)s:%(lineno)d - %(message)s')
        file_handler.setFormatter(formatter)
        for logger in self._loggers.values():
            logger.addHandler(file_handler)

def get_logger(name: str) -> logging.Logger:
    return CudaLogger().get_logger(name)

# Convenience functions for different log levels
def debug(logger: logging.Logger, message: str, *args, **kwargs):
    logger.debug(message, *args, **kwargs)

def info(logger: logging.Logger, message: str, *args, **kwargs):
    logger.info(message, *args, **kwargs)

def warning(logger: logging.Logger, message: str, *args, **kwargs):
    logger.warning(message, *args, **kwargs)

def error(logger: logging.Logger, message: str, *args, **kwargs):
    logger.error(message, *args, **kwargs)

def critical(logger: logging.Logger, message: str, *args, **kwargs):
    logger.critical(message, *args, **kwargs)

def exception(logger: logging.Logger, message: str, *args, exc_info=True, **kwargs):
    logger.exception(message, *args, exc_info=exc_info, **kwargs)

# Performance logging
def log_performance(logger: logging.Logger, operation: str, execution_time: float):
    logger.info(f"Performance: {operation} took {execution_time:.4f} seconds")

# Function entry/exit logging
def log_function_entry(logger: logging.Logger, func_name: str, args: Optional[Dict] = None):
    args_str = ", ".join(f"{k}={v}" for k, v in args.items()) if args else ""
    logger.debug(f"Entering function: {func_name}({args_str})")

def log_function_exit(logger: logging.Logger, func_name: str, result: Any = None):
    logger.debug(f"Exiting function: {func_name} with result: {result}")

# Context manager for function logging
class LogFunction:
    def __init__(self, logger: logging.Logger, func_name: str):
        self.logger = logger
        self.func_name = func_name

    def __enter__(self):
        log_function_entry(self.logger, self.func_name)

    def __exit__(self, exc_type, exc_value, traceback):
        if exc_type:
            self.logger.exception(f"Exception in function {self.func_name}: {exc_value}")
        else:
            log_function_exit(self.logger, self.func_name)
Class: ('CudaLogger', '')
--------------------------------------------------------------------------------

Class: ('LogFunction', '')
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\utils\mapping_tables.py

#some values must be recheked, mackintosh and hackintosh in the futur
# utils/mapping_tables.py

from typing import Dict, Set, Tuple, Optional, Union, List
from enum import Enum
from dataclasses import dataclass
import logging

from .error_handler import CudaTranslationError
from .logger import get_logger

logger = get_logger(__name__)

@dataclass
class MetalType:
    """Metal type information with full metadata"""
    name: str
    size: int
    alignment: int
    can_atomic: bool = False
    texture_format: Optional[str] = None
    sampler_type: Optional[str] = None
    allow_threadgroup: bool = True
    is_builtin: bool = False

@dataclass
class MetalFunction:
    """Metal function metadata"""
    name: str
    return_type: str
    arg_types: List[str]
    has_fast_variant: bool = False
    needs_explicit_cast: bool = False

# Complete Metal type mappings
METAL_TYPES = {
    # Scalar Types
    'bool': MetalType('bool', 1, 1),
    'char': MetalType('char', 1, 1),
    'uchar': MetalType('uchar', 1, 1),
    'short': MetalType('short', 2, 2),
    'ushort': MetalType('ushort', 2, 2),
    'int': MetalType('int', 4, 4, can_atomic=True),
    'uint': MetalType('uint', 4, 4, can_atomic=True),
    'long': MetalType('long', 8, 8),
    'ulong': MetalType('ulong', 8, 8),
    'half': MetalType('half', 2, 2),
    'float': MetalType('float', 4, 4),

    # Vector Types
    'char2': MetalType('char2', 2, 2),
    'char3': MetalType('char3', 4, 4),
    'char4': MetalType('char4', 4, 4),
    'uchar2': MetalType('uchar2', 2, 2),
    'uchar3': MetalType('uchar3', 4, 4),
    'uchar4': MetalType('uchar4', 4, 4),
    'short2': MetalType('short2', 4, 4),
    'short3': MetalType('short3', 8, 8),
    'short4': MetalType('short4', 8, 8),
    'ushort2': MetalType('ushort2', 4, 4),
    'ushort3': MetalType('ushort3', 8, 8),
    'ushort4': MetalType('ushort4', 8, 8),
    'int2': MetalType('int2', 8, 8),
    'int3': MetalType('int3', 16, 16),
    'int4': MetalType('int4', 16, 16),
    'uint2': MetalType('uint2', 8, 8),
    'uint3': MetalType('uint3', 16, 16),
    'uint4': MetalType('uint4', 16, 16),
    'float2': MetalType('float2', 8, 8),
    'float3': MetalType('float3', 16, 16),
    'float4': MetalType('float4', 16, 16),
    'half2': MetalType('half2', 4, 4),
    'half3': MetalType('half3', 8, 8),
    'half4': MetalType('half4', 8, 8),

    # Matrix Types
    'float2x2': MetalType('float2x2', 16, 8),
    'float2x3': MetalType('float2x3', 24, 8),
    'float2x4': MetalType('float2x4', 32, 8),
    'float3x2': MetalType('float3x2', 24, 8),
    'float3x3': MetalType('float3x3', 36, 8),
    'float3x4': MetalType('float3x4', 48, 8),
    'float4x2': MetalType('float4x2', 32, 8),
    'float4x3': MetalType('float4x3', 48, 8),
    'float4x4': MetalType('float4x4', 64, 8),

    # Texture Types
    'texture1d': MetalType('texture1d<float>', 8, 8, texture_format='float'),
    'texture2d': MetalType('texture2d<float>', 8, 8, texture_format='float'),
    'texture3d': MetalType('texture3d<float>', 8, 8, texture_format='float'),
    'texturecube': MetalType('texturecube<float>', 8, 8, texture_format='float'),

    # Sampler Types
    'sampler': MetalType('sampler', 8, 8, sampler_type='sampler'),

    # Atomic Types
    'atomic_int': MetalType('atomic_int', 4, 4, can_atomic=True),
    'atomic_uint': MetalType('atomic_uint', 4, 4, can_atomic=True),

    # SIMD Types
    'simd_float4': MetalType('simd_float4', 16, 16, is_builtin=True),
    'simd_int4': MetalType('simd_int4', 16, 16, is_builtin=True),
    'simd_uint4': MetalType('simd_uint4', 16, 16, is_builtin=True),
}

# Complete Metal function mappings
METAL_FUNCTIONS = {
    # Math Functions
    'sin': MetalFunction('metal::sin', 'float', ['float'], has_fast_variant=True),
    'cos': MetalFunction('metal::cos', 'float', ['float'], has_fast_variant=True),
    'tan': MetalFunction('metal::tan', 'float', ['float'], has_fast_variant=True),
    'asin': MetalFunction('metal::asin', 'float', ['float']),
    'acos': MetalFunction('metal::acos', 'float', ['float']),
    'atan': MetalFunction('metal::atan', 'float', ['float']),
    'sinh': MetalFunction('metal::sinh', 'float', ['float']),
    'cosh': MetalFunction('metal::cosh', 'float', ['float']),
    'tanh': MetalFunction('metal::tanh', 'float', ['float']),
    'exp': MetalFunction('metal::exp', 'float', ['float'], has_fast_variant=True),
    'exp2': MetalFunction('metal::exp2', 'float', ['float'], has_fast_variant=True),
    'log': MetalFunction('metal::log', 'float', ['float'], has_fast_variant=True),
    'log2': MetalFunction('metal::log2', 'float', ['float'], has_fast_variant=True),
    'log10': MetalFunction('metal::log10', 'float', ['float']),
    'pow': MetalFunction('metal::pow', 'float', ['float', 'float'], has_fast_variant=True),
    'sqrt': MetalFunction('metal::sqrt', 'float', ['float'], has_fast_variant=True),
    'rsqrt': MetalFunction('metal::rsqrt', 'float', ['float'], has_fast_variant=True),
    'abs': MetalFunction('metal::abs', 'float', ['float']),
    'min': MetalFunction('metal::min', 'float', ['float', 'float']),
    'max': MetalFunction('metal::max', 'float', ['float', 'float']),
    'ceil': MetalFunction('metal::ceil', 'float', ['float']),
    'floor': MetalFunction('metal::floor', 'float', ['float']),
    'fract': MetalFunction('metal::fract', 'float', ['float']),
    'mod': MetalFunction('metal::fmod', 'float', ['float', 'float']),

    # Atomic Functions
    'atomic_store': MetalFunction('atomic_store_explicit', 'void', ['atomic_type*', 'T'], needs_explicit_cast=True),
    'atomic_load': MetalFunction('atomic_load_explicit', 'T', ['atomic_type*'], needs_explicit_cast=True),
    'atomic_exchange': MetalFunction('atomic_exchange_explicit', 'T', ['atomic_type*', 'T'], needs_explicit_cast=True),
    'atomic_compare_exchange_weak': MetalFunction('atomic_compare_exchange_weak_explicit', 'bool', ['atomic_type*', 'T*', 'T'], needs_explicit_cast=True),
    'atomic_fetch_add': MetalFunction('atomic_fetch_add_explicit', 'T', ['atomic_type*', 'T'], needs_explicit_cast=True),
    'atomic_fetch_sub': MetalFunction('atomic_fetch_sub_explicit', 'T', ['atomic_type*', 'T'], needs_explicit_cast=True),
    'atomic_fetch_and': MetalFunction('atomic_fetch_and_explicit', 'T', ['atomic_type*', 'T'], needs_explicit_cast=True),
    'atomic_fetch_or': MetalFunction('atomic_fetch_or_explicit', 'T', ['atomic_type*', 'T'], needs_explicit_cast=True),
    'atomic_fetch_xor': MetalFunction('atomic_fetch_xor_explicit', 'T', ['atomic_type*', 'T'], needs_explicit_cast=True),

    # Synchronization Functions
    'threadgroup_barrier': MetalFunction('threadgroup_barrier', 'void', ['mem_flags']),
    'simd_barrier': MetalFunction('simd_barrier', 'void', []),

    # SIMD Functions
    'simd_sum': MetalFunction('simd_sum', 'T', ['T']),
    'simd_min': MetalFunction('simd_min', 'T', ['T']),
    'simd_max': MetalFunction('simd_max', 'T', ['T']),
    'simd_and': MetalFunction('simd_and', 'T', ['T']),
    'simd_or': MetalFunction('simd_or', 'T', ['T']),
    'simd_xor': MetalFunction('simd_xor', 'T', ['T']),
    'simd_broadcast': MetalFunction('simd_broadcast', 'T', ['T', 'uint']),
    'simd_shuffle': MetalFunction('simd_shuffle', 'T', ['T', 'uint']),
    'simd_shuffle_xor': MetalFunction('simd_shuffle_xor', 'T', ['T', 'uint']),
    'simd_all': MetalFunction('simd_all', 'bool', ['bool']),
    'simd_any': MetalFunction('simd_any', 'bool', ['bool']),
}

# Complete Metal qualifier mappings
METAL_QUALIFIERS = {
    'kernel': 'kernel',
    'device': 'device',
    'constant': 'constant',
    'threadgroup': 'threadgroup',
    'thread': 'thread',
    'inline': 'inline',
    'static': 'static',
    'volatile': 'volatile',
    'restrict': 'restrict',
    'const': 'const',
    'read_write': 'read_write',
    'read': 'read',
    'write': 'write',
}

# Complete Metal attribute mappings
METAL_ATTRIBUTES = {
    # Buffer binding
    'buffer': '[[buffer(%d)]]',
    'texture': '[[texture(%d)]]',
    'sampler': '[[sampler(%d)]]',

    # Thread position
    'thread_position_in_grid': '[[thread_position_in_grid]]',
    'thread_position_in_threadgroup': '[[thread_position_in_threadgroup]]',
    'threadgroup_position_in_grid': '[[threadgroup_position_in_grid]]',
    'threads_per_threadgroup': '[[threads_per_threadgroup]]',
    'threadgroups_per_grid': '[[threadgroups_per_grid]]',
    'thread_index_in_simdgroup': '[[thread_index_in_simdgroup]]',
    'simdgroup_index_in_threadgroup': '[[simdgroup_index_in_threadgroup]]',

    # Function attributes
    'always_inline': '[[always_inline]]',
    'noinline': '[[noinline]]',
    'convergent': '[[convergent]]',

    # Memory attributes
    'packed': '[[packed]]',
    'aligned': '[[aligned(%d)]]',
}

# Memory flag mappings
METAL_MEMORY_FLAGS = {
    'mem_none': 'mem_flags::mem_none',
    'mem_device': 'mem_flags::mem_device',
    'mem_threadgroup': 'mem_flags::mem_threadgroup',
    'mem_texture': 'mem_flags::mem_texture',
}

# Complete Metal texture formats
METAL_TEXTURE_FORMATS = {
    'R8Unorm': {'size': 1, 'components': 1, 'type': 'unorm8'},
    'RG8Unorm': {'size': 2, 'components': 2, 'type': 'unorm8'},
    'RGBA8Unorm': {'size': 4, 'components': 4, 'type': 'unorm8'},
    'R16Float': {'size': 2, 'components': 1, 'type': 'float16'},
    'RG16Float': {'size': 4, 'components': 2, 'type': 'float16'},
    'RGBA16Float': {'size': 8, 'components': 4, 'type': 'float16'},
    'R32Float': {'size': 4, 'components': 1, 'type': 'float32'},
    'RG32Float': {'size': 8, 'components': 2, 'type': 'float32'},
    'RGBA32Float': {'size': 16, 'components': 4, 'type': 'float32'},
    'R8Sint': {'size': 1, 'components': 1, 'type': 'sint8'},
    'RG8Sint': {'size': 2, 'components': 2, 'type': 'sint8'},
    'RGBA8Sint': {'size': 4, 'components': 4, 'type': 'sint8'},
    'R16Sint': {'size': 2, 'components': 1, 'type': 'sint16'},
    'RG16Sint': {'size': 4, 'components': 2, 'type': 'sint16'},
    'RGBA16Sint': {'size': 8, 'components': 4, 'type': 'sint16'},
    'R32Sint': {'size': 4, 'components': 1, 'type': 'sint32'},
    'RG32Sint': {'size': 8, 'components': 2, 'type': 'sint32'},
    'RGBA32Sint': {'size': 16, 'components': 4, 'type': 'sint32'},
}

# Address space mappings
METAL_ADDRESS_SPACES = {
    'default': '',
    'device': 'device',
    'constant': 'constant',
    'threadgroup': 'threadgroup',
    'thread': 'thread',
}
# Address space semantics
METAL_ADDRESS_SPACE_SEMANTICS = {
    'device': {
        'access': 'read_write',
        'scope': 'device',
        'alignment': 16,
        'cache_mode': 'cached',
        'can_alias': True
    },
    'constant': {
        'access': 'read',
        'scope': 'device',
        'alignment': 16,
        'cache_mode': 'cached',
        'can_alias': False
    },
    'threadgroup': {
        'access': 'read_write',
        'scope': 'threadgroup',
        'alignment': 16,
        'cache_mode': 'cached',
        'can_alias': True
    },
    'thread': {
        'access': 'read_write',
        'scope': 'thread',
        'alignment': 16,
        'cache_mode': 'none',
        'can_alias': True
    }
}

# Memory order mappings
METAL_MEMORY_ORDERS = {
    'relaxed': 'memory_order_relaxed',
    'acquire': 'memory_order_acquire',
    'release': 'memory_order_release',
    'acq_rel': 'memory_order_acq_rel',
    'seq_cst': 'memory_order_seq_cst'
}

# Memory scope mappings
METAL_MEMORY_SCOPES = {
    'device': 'memory_scope_device',
    'threadgroup': 'memory_scope_threadgroup',
    'simdgroup': 'memory_scope_simdgroup'
}

# Attribute argument mappings
METAL_ATTRIBUTE_ARGUMENTS = {
    'buffer': lambda idx: f'[[buffer({idx})]]',
    'texture': lambda idx: f'[[texture({idx})]]',
    'sampler': lambda idx: f'[[sampler({idx})]]',
    'thread_position_in_grid': lambda: '[[thread_position_in_grid]]',
    'threadgroup_position_in_grid': lambda: '[[threadgroup_position_in_grid]]',
    'threads_per_threadgroup': lambda: '[[threads_per_threadgroup]]',
    'thread_position_in_threadgroup': lambda: '[[thread_position_in_threadgroup]]',
    'thread_index_in_simdgroup': lambda: '[[thread_index_in_simdgroup]]',
    'simdgroup_index_in_threadgroup': lambda: '[[simdgroup_index_in_threadgroup]]'
}

# Resource binding mappings
METAL_RESOURCE_BINDINGS = {
    'buffer': {
        'max_per_stage': 31,
        'alignment': 256,
        'offset_alignment': 256,
        'min_size': 16,
    },
    'texture': {
        'max_per_stage': 128,
        'max_arrays': 32,
        'alignment': 16,
    },
    'sampler': {
        'max_per_stage': 16,
        'alignment': 8,
    }
}

# Texture access mappings
METAL_TEXTURE_ACCESS = {
    'sample': 'access::sample',
    'read': 'access::read',
    'write': 'access::write',
    'read_write': 'access::read_write'
}

# Sampler state mappings
METAL_SAMPLER_STATES = {
    'address_modes': {
        'clamp_to_edge': 'address::clamp_to_edge',
        'repeat': 'address::repeat',
        'mirrored_repeat': 'address::mirrored_repeat',
        'clamp_to_zero': 'address::clamp_to_zero',
        'clamp_to_border': 'address::clamp_to_border'
    },
    'min_filter': {
        'nearest': 'filter::nearest',
        'linear': 'filter::linear'
    },
    'mag_filter': {
        'nearest': 'filter::nearest',
        'linear': 'filter::linear'
    },
    'mip_filter': {
        'none': 'filter::none',
        'nearest': 'filter::nearest',
        'linear': 'filter::linear'
    },
    'compare_func': {
        'never': 'compare_func::never',
        'less': 'compare_func::less',
        'less_equal': 'compare_func::less_equal',
        'greater': 'compare_func::greater',
        'greater_equal': 'compare_func::greater_equal',
        'equal': 'compare_func::equal',
        'not_equal': 'compare_func::not_equal',
        'always': 'compare_func::always'
    }
}

# Thread mapping details
METAL_THREAD_MAPPING = {
    'simd_width': 32,
    'max_threads_per_threadgroup': 1024,
    'max_threadgroups_per_grid': (2**16 - 1, 2**16 - 1, 2**16 - 1),
    'max_total_threadgroup_memory': 32768,  # 32KB
    'preferred_threadgroup_size_multiple': 32
}

# Builtin function variants
METAL_BUILTIN_VARIANTS = {
    'precise': {
        'prefix': 'metal::',
        'performance': 'high_precision',
        'available': True
    },
    'fast': {
        'prefix': 'metal::fast::',
        'performance': 'high_performance',
        'available': True
    },
    'native': {
        'prefix': 'metal::native::',
        'performance': 'maximum_performance',
        'available': True
    }
}

class MetalMappingRegistry:
    """Registry for Metal mappings with validation and optimization."""

    def __init__(self):
        self._types = METAL_TYPES
        self._functions = METAL_FUNCTIONS
        self._qualifiers = METAL_QUALIFIERS
        self._attributes = METAL_ATTRIBUTES
        self._memory_flags = METAL_MEMORY_FLAGS
        self._texture_formats = METAL_TEXTURE_FORMATS
        self._address_spaces = METAL_ADDRESS_SPACES
        self._sampler_states = METAL_SAMPLER_STATES
        self._thread_mapping = METAL_THREAD_MAPPING
        self._builtin_variants = METAL_BUILTIN_VARIANTS

    def get_metal_type(self, cuda_type: str) -> Optional[MetalType]:
        """Get Metal type equivalent for CUDA type."""
        return self._types.get(cuda_type.lower())

    def get_metal_function(self, cuda_function: str) -> Optional[MetalFunction]:
        """Get Metal function equivalent for CUDA function."""
        return self._functions.get(cuda_function)

    def get_metal_qualifier(self, cuda_qualifier: str) -> Optional[str]:
        """Get Metal qualifier equivalent for CUDA qualifier."""
        return self._qualifiers.get(cuda_qualifier.lower())

    def get_metal_attribute(self, cuda_attribute: str, *args) -> Optional[str]:
        """Get Metal attribute with arguments."""
        attr_template = self._attributes.get(cuda_attribute)
        if not attr_template:
            return None
        try:
            return attr_template % args if args else attr_template
        except TypeError:
            logger.error(f"Invalid arguments for attribute {cuda_attribute}: {args}")
            return None

    def get_texture_format(self, format_name: str) -> Optional[Dict]:
        """Get Metal texture format details."""
        return self._texture_formats.get(format_name)

    def get_address_space(self, cuda_space: str) -> Optional[str]:
        """Get Metal address space equivalent."""
        return self._address_spaces.get(cuda_space.lower())

    def get_sampler_state(self, parameter: str, value: str) -> Optional[str]:
        """Get Metal sampler state equivalent."""
        param_dict = self._sampler_states.get(parameter)
        if param_dict:
            return param_dict.get(value.lower())
        return None

    def get_thread_limit(self, dimension: str) -> Optional[int]:
        """Get Metal thread limits."""
        return self._thread_mapping.get(dimension)

    def get_function_variant(self, function_name: str, variant: str = 'precise') -> Optional[str]:
        """Get Metal function variant."""
        variant_info = self._builtin_variants.get(variant)
        if not variant_info or not variant_info['available']:
            return None
        return f"{variant_info['prefix']}{function_name}"

    def validate_metal_compatibility(self, cuda_type: str) -> bool:
        """Validate if CUDA type has Metal equivalent."""
        return cuda_type.lower() in self._types

    def get_optimal_alignment(self, metal_type: MetalType) -> int:
        """Get optimal alignment for Metal type."""
        if metal_type.texture_format:
            return METAL_RESOURCE_BINDINGS['texture']['alignment']
        if metal_type.sampler_type:
            return METAL_RESOURCE_BINDINGS['sampler']['alignment']
        return max(metal_type.alignment, METAL_RESOURCE_BINDINGS['buffer']['alignment'])

    def get_memory_order(self, cuda_order: str) -> str:
        """Get Metal memory order equivalent."""
        return METAL_MEMORY_ORDERS.get(cuda_order.lower(), 'memory_order_relaxed')

    def get_memory_scope(self, cuda_scope: str) -> str:
        """Get Metal memory scope equivalent."""
        return METAL_MEMORY_SCOPES.get(cuda_scope.lower(), 'memory_scope_device')

logger.info("MetalMappingRegistry initialized with complete mappings")

Class: ('MetalType', '')
--------------------------------------------------------------------------------
  Method: get(cuda_type.lower()
  Method: get(cuda_function)
  Method: get(cuda_qualifier.lower()
  Method: get(cuda_attribute)
  Method: get(format_name)
  Method: get(cuda_space.lower()
  Method: get(parameter)
  Method: get(value.lower()
  Method: get(dimension)
  Method: get(variant)
  Method: get(cuda_order.lower()
  Method: get(cuda_scope.lower()

Class: ('MetalFunction', '')
--------------------------------------------------------------------------------
  Method: get(cuda_type.lower()
  Method: get(cuda_function)
  Method: get(cuda_qualifier.lower()
  Method: get(cuda_attribute)
  Method: get(format_name)
  Method: get(cuda_space.lower()
  Method: get(parameter)
  Method: get(value.lower()
  Method: get(dimension)
  Method: get(variant)
  Method: get(cuda_order.lower()
  Method: get(cuda_scope.lower()

Class: ('MetalMappingRegistry', '')
--------------------------------------------------------------------------------
  Method: get(cuda_type.lower()
  Method: get(cuda_function)
  Method: get(cuda_qualifier.lower()
  Method: get(cuda_attribute)
  Method: get(format_name)
  Method: get(cuda_space.lower()
  Method: get(parameter)
  Method: get(value.lower()
  Method: get(dimension)
  Method: get(variant)
  Method: get(cuda_order.lower()
  Method: get(cuda_scope.lower()


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\utils\metal_equivalents.py

from typing import Dict, Callable, Any, List, Optional
from .cuda_builtin_functions import CudaBuiltinFunction, CUDA_BUILTIN_FUNCTIONS
from .cuda_to_metal_type_mapping import map_cuda_type_to_metal

class MetalEquivalent:
    def __init__(self, cuda_function: str, metal_function: str,
                 argument_transformer: Optional[Callable[[List[str]], List[str]]] = None,
                 return_transformer: Optional[Callable[[str], str]] = None,
                 requires_custom_implementation: bool = False):
        self.cuda_function = cuda_function
        self.metal_function = metal_function
        self.argument_transformer = argument_transformer
        self.return_transformer = return_transformer
        self.requires_custom_implementation = requires_custom_implementation

    def transform_arguments(self, args: List[str]) -> List[str]:
        if self.argument_transformer:
            return self.argument_transformer(args)
        return args

    def transform_return(self, return_value: str) -> str:
        if self.return_transformer:
            return self.return_transformer(return_value)
        return return_value

def threadIdx_transformer(args: List[str]) -> List[str]:
    return ['thread_position_in_threadgroup']

def blockIdx_transformer(args: List[str]) -> List[str]:
    return ['threadgroup_position_in_grid']

def atomicAdd_transformer(args: List[str]) -> List[str]:
    return [f'atomic_fetch_add_explicit({args[0]}, {args[1]}, memory_order_relaxed)']

METAL_EQUIVALENTS: Dict[str, MetalEquivalent] = {
    'threadIdx': MetalEquivalent('threadIdx', 'thread_position_in_threadgroup', threadIdx_transformer),
    'blockIdx': MetalEquivalent('blockIdx', 'threadgroup_position_in_grid', blockIdx_transformer),
    'blockDim': MetalEquivalent('blockDim', 'threadgroup_size'),
    'gridDim': MetalEquivalent('gridDim', 'grid_size'),
    '__syncthreads': MetalEquivalent('__syncthreads', 'threadgroup_barrier(metal::mem_flags::mem_device)'),
    'atomicAdd': MetalEquivalent('atomicAdd', 'atomic_fetch_add_explicit', atomicAdd_transformer),
    'cudaMalloc': MetalEquivalent('cudaMalloc', 'device.makeBuffer', requires_custom_implementation=True),
    'cudaFree': MetalEquivalent('cudaFree', '', requires_custom_implementation=True),  # No direct equivalent, memory management is different
    'cudaMemcpy': MetalEquivalent('cudaMemcpy', 'memcpy', requires_custom_implementation=True),
}

def get_metal_equivalent(cuda_function: str) -> MetalEquivalent:
    if cuda_function in METAL_EQUIVALENTS:
        return METAL_EQUIVALENTS[cuda_function]

    # For CUDA built-in functions not explicitly defined in METAL_EQUIVALENTS
    if cuda_function in CUDA_BUILTIN_FUNCTIONS:
        cuda_builtin = CUDA_BUILTIN_FUNCTIONS[cuda_function]
        return MetalEquivalent(cuda_function, cuda_builtin.metal_equivalent)

    # If no equivalent is found, return the original function name
    return MetalEquivalent(cuda_function, cuda_function)

def translate_cuda_call_to_metal(cuda_function: str, args: List[str]) -> str:
    equivalent = get_metal_equivalent(cuda_function)
    transformed_args = equivalent.transform_arguments(args)

    if equivalent.requires_custom_implementation:
        return f"// TODO: Implement custom Metal equivalent for {cuda_function}\n" \
               f"// {equivalent.metal_function}({', '.join(transformed_args)})"

    return f"{equivalent.metal_function}({', '.join(transformed_args)})"

def get_metal_type(cuda_type: str) -> str:
    return map_cuda_type_to_metal(cuda_type)

def generate_metal_kernel_signature(kernel_name: str, parameters: List[CudaBuiltinFunction]) -> str:
    metal_params = []
    for i, param in enumerate(parameters):
        metal_type = get_metal_type(param.return_type)
        metal_params.append(f"{metal_type} {param.name} [[buffer({i})]]")

    return f"kernel void {kernel_name}({', '.join(metal_params)})"


Class: ('MetalEquivalent', '')
--------------------------------------------------------------------------------


--------------------------------------------------------------------------------

File: C:\Users\PC\Desktop\Megie\CUDAM\CUDAM\utils\__init__.py



--------------------------------------------------------------------------------

