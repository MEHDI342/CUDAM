{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware-Locked CUDA-Metal Validation Framework\n",
    "## Security Classification: RESTRICTED\n",
    "## Hardware Requirements:\n",
    "- NVIDIA GPU with CUDA support\n",
    "- Apple Silicon (M1/M2) hardware\n",
    "- 16GB+ RAM\n",
    "\n",
    "This notebook provides real-time validation of CUDA-Metal kernel conversion with simultaneous execution verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%%bash\n",
    "# Verify system requirements\n",
    "nvidia-smi\n",
    "system_profiler SPHardwareDataType | grep Chip"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "initialization"
    ]
   },
   "source": [
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "import plt\n",
    "import threading\n",
    "import queue\n",
    "import hashlib\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import time\n",
    "import psutil\n",
    "import platform\n",
    "\n",
    "# Attempt to import pyopencl, prompt installation if missing\n",
    "try:\n",
    "    import pyopencl as cl  # For Metal interop\n",
    "except ImportError:\n",
    "    raise ImportError(\n",
    "        \"pyopencl is required for this notebook. Please install it using 'pip install pyopencl' and ensure all system dependencies are met.\"\n",
    "    )\n",
    "\n",
    "# Security verification of environment\n",
    "SECURITY_TOKEN = hashlib.sha256(os.urandom(32)).hexdigest()\n",
    "\n",
    "@dataclass\n",
    "class ValidationConfig:\n",
    "    threads_per_block: int = 256\n",
    "    min_blocks: int = 1\n",
    "    max_blocks: int = 1024\n",
    "    timing_iterations: int = 100\n",
    "    tolerance: float = 1e-6\n",
    "    security_level: str = 'RESTRICTED'\n",
    "\n",
    "# Initialize validation configuration\n",
    "config = ValidationConfig()\n",
    "\n",
    "# Hardware verification\n",
    "def verify_hardware():\n",
    "    requirements = {\n",
    "        'CUDA GPU': False,\n",
    "        'Apple Silicon': False,\n",
    "        'RAM': False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Check CUDA\n",
    "        cp.cuda.runtime.getDeviceCount()\n",
    "        requirements['CUDA GPU'] = True\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    # Check Apple Silicon\n",
    "    if platform.processor().lower().startswith('arm'):\n",
    "        requirements['Apple Silicon'] = True\n",
    "        \n",
    "    # Check RAM\n",
    "    if psutil.virtual_memory().total >= 16 * (1024**3):  # 16GB\n",
    "        requirements['RAM'] = True\n",
    "        \n",
    "    return requirements\n",
    "\n",
    "hw_check = verify_hardware()\n",
    "assert all(hw_check.values()), \"Hardware requirements not met\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "validation_core"
    ]
   },
   "source": [
    "class SimultaneousValidator:\n",
    "    def __init__(self):\n",
    "        self.cuda_queue = queue.Queue()\n",
    "        self.metal_result_queue = queue.Queue()  # Renamed to avoid conflict\n",
    "        self.sync_event = threading.Event()\n",
    "        self.result_lock = threading.Lock()\n",
    "        self.initialize_hardware()\n",
    "        \n",
    "    def initialize_hardware(self):\n",
    "        # Initialize CUDA\n",
    "        self.cuda_device = cp.cuda.Device(0)\n",
    "        \n",
    "        # Initialize Metal\n",
    "        platforms = cl.get_platforms()\n",
    "        self.metal_device = None\n",
    "        for platform in platforms:\n",
    "            if 'Apple' in platform.name:\n",
    "                devices = platform.get_devices()\n",
    "                if devices:\n",
    "                    self.metal_device = devices[0]\n",
    "                break\n",
    "        assert self.metal_device is not None, \"No Metal device found\"\n",
    "        \n",
    "        self.metal_context = cl.Context([self.metal_device])\n",
    "        self.cl_command_queue = cl.CommandQueue(self.metal_context)\n",
    "        \n",
    "    def validate_kernel(self, cuda_kernel, metal_kernel, input_data):\n",
    "        results = {}\n",
    "        \n",
    "        # Create execution threads\n",
    "        cuda_thread = threading.Thread(\n",
    "            target=self._execute_cuda,\n",
    "            args=(cuda_kernel, input_data)\n",
    "        )\n",
    "        \n",
    "        metal_thread = threading.Thread(\n",
    "            target=self._execute_metal,\n",
    "            args=(metal_kernel, input_data)\n",
    "        )\n",
    "        \n",
    "        # Start simultaneous execution\n",
    "        cuda_thread.start()\n",
    "        metal_thread.start()\n",
    "        \n",
    "        # Trigger synchronization event\n",
    "        self.sync_event.set()\n",
    "        \n",
    "        # Wait for both executions to complete\n",
    "        cuda_thread.join()\n",
    "        metal_thread.join()\n",
    "        \n",
    "        # Get results\n",
    "        cuda_result = self.cuda_queue.get()\n",
    "        metal_result = self.metal_result_queue.get()  # Updated\n",
    "        \n",
    "        # Validate results\n",
    "        validation_result = self._validate_results(\n",
    "            cuda_result['output'],\n",
    "            metal_result['output'],\n",
    "            cuda_result['timing'],\n",
    "            metal_result['timing']\n",
    "        )\n",
    "        \n",
    "        return validation_result\n",
    "    \n",
    "    def _execute_cuda(self, kernel_code, input_data):\n",
    "        with self.cuda_device:\n",
    "            # Compile kernel\n",
    "            module = cp.RawModule(code=kernel_code)\n",
    "            kernel = module.get_function('cuda_kernel')\n",
    "            \n",
    "            # Prepare data\n",
    "            if isinstance(input_data, tuple):\n",
    "                input_gpu = [cp.asarray(arg) for arg in input_data[:-1]]\n",
    "                output_gpu = cp.asarray(input_data[-2])\n",
    "                n = cp.int32(input_data[-1])\n",
    "            else:\n",
    "                input_gpu = cp.asarray(input_data)\n",
    "                output_gpu = cp.zeros_like(input_gpu)\n",
    "                n = None\n",
    "            \n",
    "            # Execute with timing\n",
    "            start_event = cp.cuda.Event()\n",
    "            end_event = cp.cuda.Event()\n",
    "            \n",
    "            start_event.record()\n",
    "            if n is not None:\n",
    "                kernel(\n",
    "                    (config.min_blocks,), (config.threads_per_block,),\n",
    "                    (*input_gpu, output_gpu, n)\n",
    "                )\n",
    "            else:\n",
    "                kernel(\n",
    "                    (config.min_blocks,), (config.threads_per_block,),\n",
    "                    (input_gpu, output_gpu)\n",
    "                )\n",
    "            end_event.record()\n",
    "            end_event.synchronize()\n",
    "            \n",
    "            timing = cp.cuda.get_elapsed_time(start_event, end_event)\n",
    "            \n",
    "            # Get result\n",
    "            result = {\n",
    "                'output': cp.asnumpy(output_gpu),\n",
    "                'timing': timing\n",
    "            }\n",
    "            \n",
    "            self.cuda_queue.put(result)\n",
    "    \n",
    "    def _execute_metal(self, kernel_code, input_data):\n",
    "        # Compile Metal kernel\n",
    "        prg = cl.Program(self.metal_context, kernel_code).build()\n",
    "        \n",
    "        # Prepare buffers\n",
    "        mf = cl.mem_flags\n",
    "        if isinstance(input_data, tuple):\n",
    "            input_a = input_data[0]\n",
    "            input_b = input_data[1]\n",
    "            output = input_data[2]\n",
    "            n = input_data[3]\n",
    "            input_buf_a = cl.Buffer(\n",
    "                self.metal_context,\n",
    "                mf.READ_ONLY | mf.COPY_HOST_PTR,\n",
    "                hostbuf=input_a\n",
    "            )\n",
    "            input_buf_b = cl.Buffer(\n",
    "                self.metal_context,\n",
    "                mf.READ_ONLY | mf.COPY_HOST_PTR,\n",
    "                hostbuf=input_b\n",
    "            )\n",
    "            output_buf = cl.Buffer(\n",
    "                self.metal_context,\n",
    "                mf.WRITE_ONLY,\n",
    "                output.nbytes\n",
    "            )\n",
    "            n_buf = cl.Buffer(\n",
    "                self.metal_context,\n",
    "                mf.READ_ONLY | mf.COPY_HOST_PTR,\n",
    "                hostbuf=np.array([n], dtype=np.int32)\n",
    "            )\n",
    "        else:\n",
    "            input_buf = cl.Buffer(\n",
    "                self.metal_context,\n",
    "                mf.READ_ONLY | mf.COPY_HOST_PTR,\n",
    "                hostbuf=input_data\n",
    "            )\n",
    "            output_buf = cl.Buffer(\n",
    "                self.metal_context,\n",
    "                mf.WRITE_ONLY,\n",
    "                input_data.nbytes\n",
    "            )\n",
    "        \n",
    "        # Execute with timing\n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        if isinstance(input_data, tuple):\n",
    "            event = prg.metal_kernel(\n",
    "                self.cl_command_queue,\n",
    "                (input_a.shape[0],),\n",
    "                None,\n",
    "                input_buf_a,\n",
    "                input_buf_b,\n",
    "                output_buf,\n",
    "                n_buf\n",
    "            )\n",
    "        else:\n",
    "            event = prg.metal_kernel(\n",
    "                self.cl_command_queue,\n",
    "                (input_data.shape[0],),\n",
    "                None,\n",
    "                input_buf,\n",
    "                output_buf\n",
    "            )\n",
    "        event.wait()\n",
    "        \n",
    "        end_time = time.perf_counter()\n",
    "        \n",
    "        # Get result\n",
    "        if isinstance(input_data, tuple):\n",
    "            output = np.empty_like(input_data[2])\n",
    "            cl.enqueue_copy(self.cl_command_queue, output, output_buf)\n",
    "        else:\n",
    "            output = np.empty_like(input_data)\n",
    "            cl.enqueue_copy(self.cl_command_queue, output, output_buf)\n",
    "        \n",
    "        result = {\n",
    "            'output': output,\n",
    "            'timing': (end_time - start_time) * 1000  # Convert to ms\n",
    "        }\n",
    "        \n",
    "        self.metal_result_queue.put(result)\n",
    "    \n",
    "    def _validate_results(self, cuda_output, metal_output, cuda_timing, metal_timing):\n",
    "        # Check numerical accuracy\n",
    "        max_diff = np.max(np.abs(cuda_output - metal_output))\n",
    "        outputs_match = max_diff <= config.tolerance\n",
    "        \n",
    "        # Check performance ratio\n",
    "        timing_ratio = cuda_timing / metal_timing\n",
    "        perf_acceptable = 0.5 <= timing_ratio <= 2.0\n",
    "        \n",
    "        return {\n",
    "            'outputs_match': outputs_match,\n",
    "            'max_difference': max_diff,\n",
    "            'cuda_timing_ms': cuda_timing,\n",
    "            'metal_timing_ms': metal_timing,\n",
    "            'timing_ratio': timing_ratio,\n",
    "            'performance_acceptable': perf_acceptable,\n",
    "            'validation_passed': outputs_match and perf_acceptable\n",
    "        }\n",
    "\n",
    "# Initialize validator\n",
    "validator = SimultaneousValidator()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "test_suite"
    ]
   },
   "source": [
    "# Test kernels\n",
    "test_cases = {\n",
    "    'vector_add': {\n",
    "        'cuda': '''\n",
    "        extern \"C\" __global__\n",
    "        void cuda_kernel(const float* a, float* b) {\n",
    "            int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "            b[idx] = a[idx] + a[idx];\n",
    "        }\n",
    "        ''',\n",
    "        'metal': '''\n",
    "        kernel void metal_kernel(\n",
    "            const device float* a [[buffer(0)]],\n",
    "            device float* b [[buffer(1)]],\n",
    "            uint idx [[thread_position_in_grid]]\n",
    "        ) {\n",
    "            b[idx] = a[idx] + a[idx];\n",
    "        }\n",
    "        '''\n",
    "    },\n",
    "    'matrix_mul': {\n",
    "        'cuda': '''\n",
    "        extern \"C\" __global__\n",
    "        void cuda_kernel(const float* a, const float* b, float* c, int n) {\n",
    "            int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
    "            int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "            if (row < n && col < n) {\n",
    "                float sum = 0;\n",
    "                for (int k = 0; k < n; k++) {\n",
    "                    sum += a[row * n + k] * b[k * n + col];\n",
    "                }\n",
    "                c[row * n + col] = sum;\n",
    "            }\n",
    "        }\n",
    "        ''',\n",
    "        'metal': '''\n",
    "        kernel void metal_kernel(\n",
    "            const device float* a [[buffer(0)]],\n",
    "            const device float* b [[buffer(1)]],\n",
    "            device float* c [[buffer(2)]],\n",
    "            constant int& n [[buffer(3)]],\n",
    "            uint2 pos [[thread_position_in_grid]]\n",
    "        ) {\n",
    "            int row = pos.y;\n",
    "            int col = pos.x;\n",
    "            if (row < n && col < n) {\n",
    "                float sum = 0;\n",
    "                for (int k = 0; k < n; k++) {\n",
    "                    sum += a[row * n + k] * b[k * n + col];\n",
    "                }\n",
    "                c[row * n + col] = sum;\n",
    "            }\n",
    "        }\n",
    "        '''\n",
    "    }\n",
    "}\n",
    "\n",
    "# Run validation suite\n",
    "def run_validation_suite():\n",
    "    results = {}\n",
    "    \n",
    "    for name, kernels in test_cases.items():\n",
    "        print(f\"\\nValidating {name}...\")\n",
    "        \n",
    "        # Prepare test data\n",
    "        if name == 'vector_add':\n",
    "            input_a = np.random.randn(1024*1024).astype(np.float32)\n",
    "            input_b = np.random.randn(1024*1024).astype(np.float32)\n",
    "            output = np.zeros_like(input_a)\n",
    "            input_data = (input_a, input_b, output)\n",
    "        elif name == 'matrix_mul':\n",
    "            N = 1024\n",
    "            input_a = np.random.randn(N, N).astype(np.float32)\n",
    "            input_b = np.random.randn(N, N).astype(np.float32)\n",
    "            output = np.zeros((N, N), dtype=np.float32)\n",
    "            input_data = (input_a, input_b, output, N)\n",
    "        \n",
    "        # Run validation\n",
    "        try:\n",
    "            result = validator.validate_kernel(\n",
    "                kernels['cuda'],\n",
    "                kernels['metal'],\n",
    "                input_data\n",
    "            )\n",
    "            \n",
    "            results[name] = result\n",
    "            \n",
    "            # Display results\n",
    "            display(HTML(f'''\n",
    "            <div style=\"background-color: {'#dff0d8' if result['validation_passed'] else '#f2dede'}; padding: 10px; border-radius: 5px;\">\n",
    "                <h4>{name} Validation Results:</h4>\n",
    "                <ul>\n",
    "                    <li>Outputs Match: {'✅' if result['outputs_match'] else '❌'} (Max Diff: {result['max_difference']:.2e})</li>\n",
    "                    <li>CUDA Timing: {result['cuda_timing_ms']:.3f} ms</li>\n",
    "                    <li>Metal Timing: {result['metal_timing_ms']:.3f} ms</li>\n",
    "                    <li>Performance Ratio: {result['timing_ratio']:.2f}</li>\n",
    "                    <li>Overall Status: {'✅ PASSED' if result['validation_passed'] else '❌ FAILED'}</li>\n",
    "                </ul>\n",
    "            </div>\n",
    "            '''))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error validating {name}: {str(e)}\")\n",
    "            results[name] = {'error': str(e)}\n",
    "    \n",
    "    return results\n",
    "\n",
    "validation_results = run_validation_suite()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "analysis"
    ]
   },
   "source": [
    "# Detailed Analysis\n",
    "def analyze_validation_results(results):\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Create performance comparison DataFrame\n",
    "    performance_data = []\n",
    "    for name, result in results.items():\n",
    "        if 'error' not in result and 'cuda_timing_ms' in result:\n",
    "            performance_data.append({\n",
    "                'Test Case': name,\n",
    "                'CUDA Time (ms)': result['cuda_timing_ms'],\n",
    "                'Metal Time (ms)': result['metal_timing_ms'],\n",
    "                'Speedup': result['timing_ratio'],\n",
    "                'Max Error': result['max_difference']\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(performance_data)\n",
    "    \n",
    "    # Plot performance comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    width = 0.35\n",
    "    x = np.arange(len(df))\n",
    "    \n",
    "    plt.bar(x - width/2, df['CUDA Time (ms)'], width, label='CUDA')\n",
    "    plt.bar(x + width/2, df['Metal Time (ms)'], width, label='Metal')\n",
    "    \n",
    "    plt.xlabel('Test Case')\n",
    "    plt.ylabel('Execution Time (ms)')\n",
    "    plt.title('CUDA vs Metal Performance Comparison')\n",
    "    plt.xticks(x, df['Test Case'])\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df\n",
    "\n",
    "analysis_results = analyze_validation_results(validation_results)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "helper_functions"
    ]
   },
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "# Function to convert plot to base64\n",
    "def plot_to_base64():\n",
    "    buf = BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close()\n",
    "    buf.seek(0)\n",
    "    img_base64 = base64.b64encode(buf.read()).decode('utf-8')\n",
    "    return img_base64\n",
    "\n",
    "# Function to generate test case details for the report\n",
    "def generate_test_case_details(name, result):\n",
    "    if 'error' in result:\n",
    "        return f'''\n",
    "        <div style=\"margin-bottom: 20px;\">\n",
    "            <h4>{name}:</h4>\n",
    "            <p style=\"color: red;\"><strong>Error:</strong> {result['error']}</p>\n",
    "        </div>\n",
    "        '''\n",
    "    else:\n",
    "        return f'''\n",
    "        <div style=\"margin-bottom: 20px;\">\n",
    "            <h4>{name}:</h4>\n",
    "            <ul>\n",
    "                <li>Outputs Match: {'✅' if result['outputs_match'] else '❌'} (Max Diff: {result['max_difference']:.2e})</li>\n",
    "                <li>CUDA Timing: {result['cuda_timing_ms']:.3f} ms</li>\n",
    "                <li>Metal Timing: {result['metal_timing_ms']:.3f} ms</li>\n",
    "                <li>Performance Ratio: {result['timing_ratio']:.2f}</li>\n",
    "                <li>Overall Status: {'✅ PASSED' if result['validation_passed'] else '❌ FAILED'}</li>\n",
    "            </ul>\n",
    "        </div>\n",
    "        '''"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "report"
    ]
   },
   "source": [
    "# Generate Validation Report\n",
    "def generate_validation_report(validation_results, analysis_results):\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    report_id = hashlib.sha256(timestamp.encode()).hexdigest()[:8]\n",
    "    \n",
    "    # Safely get CUDA device name\n",
    "    try:\n",
    "        cuda_device_name = cp.cuda.runtime.getDeviceProperties(0)['name'].decode()\n",
    "    except Exception as e:\n",
    "        cuda_device_name = \"Unknown CUDA Device\"\n",
    "        print(f\"Error fetching CUDA device properties: {e}\")\n",
    "    \n",
    "    # Safely get Metal device name\n",
    "    try:\n",
    "        metal_device_name = validator.metal_device.name\n",
    "    except AttributeError:\n",
    "        metal_device_name = \"Unknown Metal Device\"\n",
    "    \n",
    "    html_report = f'''\n",
    "    <div style=\"padding: 20px; font-family: Arial, sans-serif;\">\n",
    "        <h2>CUDA-Metal Validation Report</h2>\n",
    "        <p><strong>Report ID:</strong> {report_id}</p>\n",
    "        <p><strong>Timestamp:</strong> {timestamp}</p>\n",
    "        <p><strong>Security Level:</strong> {config.security_level}</p>\n",
    "        \n",
    "        <h3>Hardware Configuration</h3>\n",
    "        <ul>\n",
    "            <li><strong>CUDA Device:</strong> {cuda_device_name}</li>\n",
    "            <li><strong>Metal Device:</strong> {metal_device_name}</li>\n",
    "        </ul>\n",
    "        \n",
    "        <h3>Validation Summary</h3>\n",
    "        <ul>\n",
    "            <li><strong>Total Tests:</strong> {len(validation_results)}</li>\n",
    "            <li><strong>Passed:</strong> {sum(1 for r in validation_results.values() if 'validation_passed' in r and r['validation_passed'])}</li>\n",
    "            <li><strong>Failed:</strong> {sum(1 for r in validation_results.values() if 'validation_passed' in r and not r['validation_passed'])}</li>\n",
    "            <li><strong>Errors:</strong> {sum(1 for r in validation_results.values() if 'error' in r)}</li>\n",
    "        </ul>\n",
    "        \n",
    "        <h3>Performance Analysis</h3>\n",
    "        <img src=\"data:image/png;base64,{plot_to_base64()}\"/>\n",
    "        \n",
    "        <h3>Validation Details</h3>\n",
    "        {''.join(generate_test_case_details(name, result) for name, result in validation_results.items())}\n",
    "        \n",
    "        <h3>Security Verification</h3>\n",
    "        <p>Report Hash: {hashlib.sha256(str(validation_results).encode()).hexdigest()}</p>\n",
    "    </div>\n",
    "    '''\n",
    "    \n",
    "    # Save report\n",
    "    with open(f'validation_report_{report_id}.html', 'w') as f:\n",
    "        f.write(html_report)\n",
    "    \n",
    "    return HTML(html_report)\n",
    "\n",
    "report = generate_validation_report(validation_results, analysis_results)\n",
    "display(report)"
   ],
   "outputs": []
  }
 ]
}
